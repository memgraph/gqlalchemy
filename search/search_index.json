{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started with GQLAlchemy","text":"<p>GQLAlchemy is an open-source Python library and an Object Graph Mapper (OGM) - a link between graph database objects and Python objects. GQLAlchemy supports Memgraph and Neo4j.</p> <p>An Object Graph Mapper or OGM provides a developer-friendly workflow for writing object-oriented notation to communicate to a graph database. Instead of writing Cypher queries, you can write object-oriented code, which the OGM will automatically translate into Cypher queries.</p>"},{"location":"#quick-start","title":"Quick start","text":""},{"location":"#1-install-gqlalchemy","title":"1. Install GQLAlchemy","text":"<p>Either install GQLAlchemy through pip or build it from source. If you are using Conda for Python environment management, you can install GQLAlchemy through pip.</p> <p>Danger</p> <p>Python 3.11 users: On Windows, GQLAlchemy is not yet compatible with this Python version. Linux users can install GQLAlchemy without the DGL extra (due to its dependencies not supporting Python 3.11 yet). If this is currently a blocker for you, please let us know by opening an issue.</p>"},{"location":"#2-connect-to-memgraph","title":"2. Connect to Memgraph","text":"<p>Check the Python quick start guide to learn how to connect to Memgraph using GQLAlchemy.</p>"},{"location":"#3-learn-how-to-use-gqlalchemy","title":"3. Learn how to use GQLAlchemy","text":"<p>With the help of the How-to guides you can learn how to use GQLAlchemy's features, such as object graph mapper and query builder. </p>"},{"location":"#3-check-the-reference-guide","title":"3. Check the reference guide","text":"<p>Don't forget to check the Reference guide if you want to find out which methods GQLAlchemy has and how to use it. If the reference guide is not clear enough, head over to the GQLAlchemy repository and inspect the source code. While you're there, feel free to give us a star or contribute to this open-source Python library.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v150-september-22-2023","title":"v1.5.0 - September 22, 2023","text":""},{"location":"changelog/#features-and-improvements","title":"Features and improvements","text":"<ul> <li>Added <code>get_or_create()</code> metod for <code>Node</code> and <code>Relationship</code> to simplify merging nodes and relationships (https://github.com/memgraph/gqlalchemy/pull/244)</li> <li>Added spelling fixes (https://github.com/memgraph/gqlalchemy/pull/251)</li> <li>Turned <code>docker</code> into an optional dependency (https://github.com/memgraph/gqlalchemy/pull/279)</li> </ul>"},{"location":"changelog/#bug-fixes","title":"Bug fixes","text":"<ul> <li>Fixed typing for <code>get_triggers</code> method (https://github.com/memgraph/gqlalchemy/pull/260)</li> </ul>"},{"location":"changelog/#updates","title":"Updates","text":"<ul> <li>Added support for Python 3.11 on Linux (https://github.com/memgraph/gqlalchemy/pull/281)</li> <li>Added support for Python 3.10 on Windows (https://github.com/memgraph/gqlalchemy/pull/281)</li> <li>Relaxed <code>neo4j</code> dependency (https://github.com/memgraph/gqlalchemy/pull/263/files)</li> <li>Bumped <code>pydantic</code> to v2 (https://github.com/memgraph/gqlalchemy/pull/278)</li> </ul> <p>Special thanks to all our outside contributors for their efforts! \ud83d\udc4f</p> <p>Note</p> <p>We are hoping to have full support for Python 3.11 soon. Please open an issue if you have any blockers with the current update.</p>"},{"location":"changelog/#v141-april-19-2023","title":"v1.4.1 - April 19, 2023","text":""},{"location":"changelog/#features-and-improvements_1","title":"Features and improvements","text":"<ul> <li>Installing and testing GQLAlchemy is now easier because Apache Arrow, PyTorch Geometric and DGL dependencies have been made optional. #235</li> </ul>"},{"location":"changelog/#bug-fixes_1","title":"Bug fixes","text":"<ul> <li>Removed unnecessary extra argument in the call of the <code>escape_value</code> method and fixed a bug in query creation for the <code>Map</code> property type. #198</li> </ul>"},{"location":"changelog/#v14-march-10-2023","title":"v1.4 - March 10, 2023","text":""},{"location":"changelog/#features-and-improvements_2","title":"Features and improvements","text":"<ul> <li>Data from Memgraph can now be imported from and exported to <code>NetworkX</code>, <code>DGL</code> and <code>PyG</code> graph formats. #215</li> <li>Now you can execute procedures from query modules on a subgraph using the project feature. #210</li> <li>Now you can pass values from Python variables as parameters in Cypher queries. #217</li> <li>Besides BSF, DSF and WSHORTEST, now you can also run the All shortest paths algorithm with GQLAlchemy. #200</li> </ul>"},{"location":"changelog/#v133-dec-15-2022","title":"v1.3.3 - Dec 15, 2022","text":""},{"location":"changelog/#bug-fixes_2","title":"Bug fixes","text":"<ul> <li>Added initial support for NumPy arrays (<code>ndarray</code>) and scalars (<code>generic</code>) #208</li> </ul>"},{"location":"changelog/#v132-sep-15-2022","title":"v1.3.2 - Sep 15, 2022","text":""},{"location":"changelog/#bug-fixes_3","title":"Bug fixes","text":"<ul> <li>Fixed Unicode serialisation #189</li> <li>Fixed <code>GQLAlchemyWaitForConnectionError</code> and <code>GQLAlchemyDatabaseError</code> #188</li> <li>Fixed <code>Datetime</code> serialisation #185</li> </ul>"},{"location":"changelog/#updates_1","title":"Updates","text":"<ul> <li>Bumped <code>pyarrow</code> #193</li> <li>Updated <code>poetry</code> to 1.2.0 and <code>pymgclient</code> to 1.3.1 #191</li> <li>Updated all dependencies #194</li> </ul>"},{"location":"changelog/#v13-jun-14-2022","title":"v1.3 - Jun 14, 2022","text":"<p>!!! warning ### Breaking Changes</p> <pre><code>- Renamed keyword argument `edge_label` to `relationship_type` in `to()` and `from()` methods in the query builder. [#145](https://github.com/memgraph/gqlalchemy/pull/145)\n</code></pre>"},{"location":"changelog/#major-features-and-improvements","title":"Major Features and Improvements","text":"<ul> <li>Added option to suppress warning <code>GQLAlchemySubclassNotFoundWarning</code>. #121</li> <li>Added the possibility to import <code>Field</code> from <code>gqlalchemy.models</code>. #122</li> <li>Added <code>set_()</code> method to the query builder. #128</li> <li>Added wrapper class for query modules. #130</li> <li>Added <code>foreach()</code> method to the query builder. #135</li> <li>Added <code>load_csv()</code> and <code>return()</code> methods from the query builder to base classes list. #139</li> <li>Added new argument types in <code>return_()</code>, <code>yield_()</code> and <code>with_()</code> methods in the query builder. #146</li> <li>Added <code>IntegratedAlgorithm</code> class instance as argument in <code>to()</code> and <code>from()</code> methods in the query builder. #141</li> <li>Extended <code>IntegratedAlgorithm</code> class with the Breadth-first search algorithm. #142</li> <li>Extended <code>IntegratedAlgorithm</code> class with the Weighted shortest path algorithm. #143</li> <li>Extended <code>IntegratedAlgorithm</code> class with the Depth-first search algorithm. #144</li> <li>Removed the usage of <code>sudo</code> from the <code>instance_runner</code> module. #148</li> <li>Added support for Neo4j in the Object-Graph Mapper and the query builder. #149</li> <li>Changed string variables for Blob and S3 keyword arguments. #151</li> <li>Added variable support for node and relationship properties. #154</li> <li>Added <code>Tuple</code> as new argument type in query modules. #155</li> <li>Changed <code>host</code> and <code>port</code> <code>Memgraph</code> properties to readonly. #156</li> <li>Changed <code>Memgraph.new_connection()</code> to be a private method. #157</li> <li>Added <code>push()</code> query modules for Kafka streams and Power BI. #158</li> <li>Added argument <code>lazy</code> for configuring lazy loading in the <code>Memgraph</code> class. #159</li> <li>Added <code>datetime</code> support for property types. #161</li> <li>Added <code>Operator</code> enum which can be used as <code>operator</code> value in <code>set_()</code> and <code>where()</code> methods in the query builder. #165</li> <li>Added an extension to the <code>QueryBuilder</code> class to support and autocomplete integrated and MAGE query modules. #168</li> </ul>"},{"location":"changelog/#bug-fixes_4","title":"Bug fixes","text":"<ul> <li>Fixed the unbound variable error in the return statement of the Cypher query in <code>memgraph.save_relationship_with_id()</code>. #166</li> <li>Fixed checking if <code>None</code> for <code>Optional</code> properties. #167</li> </ul>"},{"location":"changelog/#v12-apr-12-2022","title":"v1.2 - Apr 12, 2022","text":"<p>!!! warning ### Breaking Changes</p> <pre><code>- Ordering query results as in GQLAlchemy older than 1.2 will not be possible.\n- `where()`, `and_where()` and `or_where()` methods can't be used as in\n  GQLAlchemy older than 1.2.\n- Setting up the `bootstrap_servers` argument when creating a stream as in\n  GQLAlchemy older than 1.2 will not be possible.\n</code></pre>"},{"location":"changelog/#major-features-and-improvements_1","title":"Major Features and Improvements","text":"<ul> <li>Improved <code>where()</code>, <code>and_where()</code>, <code>or_where()</code> and <code>xor_where()</code> methods. #114</li> <li>Added <code>where_not()</code>, <code>and_not()</code>, <code>or_not()</code> and <code>xor_not()</code> methods. #114</li> <li>Improved <code>order_by()</code> method from query builder by changing its argument types. #114</li> <li>Added Docker and Binary Memgraph instance runners. #91</li> <li>Added methods for dropping all indexes (<code>drop_all_indexes()</code>) and dropping all triggers (<code>drop_all_triggers()</code>). #100</li> <li>Added table to graph importer and Amazon S3 importer. #100</li> <li>Added Azure Blob and local storage importers. #104</li> <li>Added an option to create a label index. #113</li> <li>Added batch save methods for saving nodes (<code>save_nodes()</code>) and saving relationships (<code>save_relationships()</code>). #106</li> <li>Added label filtering in <code>where()</code> method in query builder. #103</li> <li>Added support for creating a trigger without <code>ON</code> keyword in query builder. #90</li> <li>Added <code>execute()</code> option in query builder. #92</li> <li>Added <code>load_csv()</code> and <code>xor_where()</code> methods to query builder. #90</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"Bug fixes","text":"<ul> <li>Fixed <code>save_node_with_id()</code> signature in the <code>save_node()</code> method. #109</li> <li>Constraints and indexes defined in <code>Field</code> now work correctly. Before, when they were added to the <code>Field</code> of the property, they were always set to <code>True</code>, regardless of their actual value. #90</li> <li>Fixed label inheritance to get all labels of base class. #105</li> <li>Removed extra argument called <code>optional</code> from the <code>Merge</code> class. #118</li> <li>Removed unnecessary quotes from the <code>bootstraps_servers</code> argument when creating a stream. #98</li> </ul>"},{"location":"changelog/#v11-jan-19-2022","title":"v1.1 - Jan 19, 2022","text":""},{"location":"changelog/#major-features-and-improvements_2","title":"Major Features and Improvements","text":"<ul> <li>Added graph schema definition and validation.</li> <li>Added new methods to the query builder: <code>merge()</code>, <code>create()</code>,   <code>unwind()</code>,<code>with_()</code>, <code>return_()</code>, <code>yield_()</code>, <code>order_by()</code>, <code>limit()</code>,   <code>skip()</code>, <code>call()</code>, <code>delete()</code> and <code>remove()</code>.</li> <li>Added on-disk storage for large properties that don't need to be stored in the   graph database.</li> <li>Added support for managing streams and database triggers.</li> </ul>"},{"location":"import-data/","title":"Import data","text":"<p>You can import data in the following formats:</p> <ul> <li>CSV</li> <li>JSON</li> <li>Parquet, ORC or IPC/Feather/Arrow</li> <li>Python graphs - NetworkX, PyG or DGL graph</li> <li>Kafka, RedPanda or Pulsar data stream</li> </ul> <p>Besides that, you can create data directly from code using the object graph mapper or query builder.</p> <p>Tip</p> <p>The fastest way to import data into Memgraph is by using the LOAD CSV clause. It's recommended to first create indexes using the <code>CREATE INDEX</code> clause. You can create them by executing the Cypher query or using object graph mapper.</p>"},{"location":"import-data/#csv","title":"CSV","text":"<p>To import CSV file into Memgraph via GQLAlchemy, you can use the <code>LOAD CSV</code> clause. That clause can be used by executing the Cypher query or by building the query with the query builder. Another way of importing CSV data into Memgraph is by translating it into a graph.</p>"},{"location":"import-data/#json","title":"JSON","text":"<p>To import JSON files into Memgraph via GQLAlchemy, you can call procedures from the <code>json_util</code> module available in MAGE library. If the JSON data is formatted in a particular style, you can call the <code>import_util.json()</code> procedure from MAGE. The procedures can be called by executing Cypher queries or using the query builder.</p>"},{"location":"import-data/#parquet-orc-or-ipcfeatherarrow","title":"Parquet, ORC or IPC/Feather/Arrow","text":"<p>To import Parquet, ORC or IPC/Feather/Arrow file into Memgraph via GQLAlchemy, transform table data from a file into a graph. </p> <p>Note</p> <p>If you want to read from a file system not currently supported by GQLAlchemy, or use a file type currently not readable, you can implement your own by making a custom file system importer.</p>"},{"location":"import-data/#python-graphs-networkx-pyg-or-dgl-graph","title":"Python graphs - NetworkX, PyG or DGL graph","text":"<p>To import NetworkX, PyG or DGL graph into Memgraph via GQLAlchemy, transform the source graph into Memgraph graph.</p>"},{"location":"import-data/#kafka-redpanda-or-pulsar-data-stream","title":"Kafka, RedPanda or Pulsar data stream","text":"<p>To consume Kafka, RedPanda or Pulsar data stream, you can write a appropriate Cypher queries and execute them, or use GQLAlchemy stream manager for Kafka, RedPanda or Pulsar streams.</p>"},{"location":"import-data/#learn-more","title":"Learn more","text":"<p>To learn how to utilize the GQLAlchemy library with Memgraph, check out the how-to guides or sign up for the Getting started with Memgraph and Python course.</p>"},{"location":"installation/","title":"How to install GQLAlchemy","text":"<p>There are two main ways of installing GQLAlchemy: with package managers such as pip and Poetry, and by building it from source.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>To install GQLAlchemy, you will need the following:</p> <ul> <li>Python 3.8 - 3.11</li> <li><code>pymgclient</code> build prerequisites: GQLAlchemy is built on top of Memgraph's low-level Python client <code>pymgclient</code></li> </ul> <p>Danger</p> <p>Python 3.11 users: On Windows, GQLAlchemy is not yet compatible with this Python version. Linux users can install GQLAlchemy without the DGL extra (due to its dependencies not supporting Python 3.11 yet). If this is currently a blocker for you, please let us know by opening an issue.</p>"},{"location":"installation/#install-with-pip","title":"Install with pip","text":"<p>After you\u2019ve installed the prerequisites, run the following command to install GQLAlchemy:</p> <pre><code>pip install gqlalchemy\n</code></pre> <p>With the above command, you get the default GQLAlchemy installation which doesn\u2019t include import/export support for certain formats (see below). To get additional import/export capabilities, use one of the following install options:</p> <pre><code>pip install gqlalchemy[arrow] # Support for the CSV, Parquet, ORC and IPC/Feather/Arrow formats\npip install gqlalchemy[dgl] # DGL support (also includes torch)\npip install gqlalchemy[docker] # Docker support\n\npip install gqlalchemy[all] # All of the above\n</code></pre> <p>Note</p> <p>If you are using the zsh terminal, surround <code>gqlalchemy[$extras)]</code> with quotes:</p> <pre><code>```bash\npip install 'gqlalchemy[arrow]'\n```\n</code></pre> <p>If you intend to use GQLAlchemy with PyTorch Geometric support, that library must be installed manually:</p> <pre><code>pip install gqlalchemy[torch_pyg] # prerequisite\npip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html\"\n</code></pre>"},{"location":"installation/#build-from-source","title":"Build from source","text":"<p>Clone or download the GQLAlchemy source code locally and run the following command to build it from source with Poetry:</p> <pre><code>poetry install --all-extras\n</code></pre> <p>The <code>poetry install --all-extras</code> command installs GQLAlchemy with all extras (optional dependencies). Alternatively, you can use the <code>-E</code> option to define what extras to install:</p> <pre><code>poetry install # No extras\n\npoetry install -E arrow # Support for the CSV, Parquet, ORC and IPC/Feather/Arrow formats\npoetry install -E dgl # DGL support (also includes torch)\npoetry install -E docker # Docker support\n</code></pre> <p>To run the tests, make sure you have an active Memgraph instance, and execute one of the following commands:</p> <pre><code>poetry run pytest . -k \"not slow\" # If all extras installed\n\npoetry run pytest . -k \"not slow and not extras\" # Otherwise\n</code></pre> <p>If you\u2019ve installed only certain extras, it\u2019s also possible to run their associated tests:</p> <pre><code>poetry run pytest . -k \"arrow\"\npoetry run pytest . -k \"dgl\"\npoetry run pytest . -k \"docker\"\n</code></pre>"},{"location":"how-to-guides/ogm/","title":"How to use object graph mapper","text":"<p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre> <p>Through this guide, you will learn how to use the GQLAlchemy object graph mapper to:</p> <ul> <li>Map nodes and relationships</li> <li>Save nodes and relationships</li> <li>Load nodes and relationships<ul> <li>Find node properties</li> <li>Create relationship between existing nodes</li> <li>Merge nodes and relationships</li> </ul> </li> <li>Create indexes</li> <li>Create constraints</li> </ul> <p>Hopefully, this guide will teach you how to properly use GQLAlchemy object graph mapper. If you have any more questions, join our community and ping us on Discord.</p> <p>Info</p> <p>To test the above features, you must install GQLAlchemy and have a running Memgraph instance. If you're unsure how to run Memgraph, check out the Memgraph Quick start).</p>"},{"location":"how-to-guides/ogm/#map-nodes-and-relationships","title":"Map nodes and relationships","text":"<p>First, we need to import all the necessary classes from GQLAlchemy:</p> <pre><code>from gqlalchemy import Memgraph, Node, Relationship\n</code></pre> <p>After that, instantiate Memgraph and create classes representing nodes.</p> <pre><code>db = Memgraph()\n\nclass User(Node):\n    id: str\n    username: str\n\nclass Streamer(User):\n    id: str\n    username: str\n    followers: int\n\nclass Language(Node):\n    name: str\n</code></pre> <p></p> <p><code>Node</code> is a Python class which maps to a graph object in Memgraph. <code>User</code>, <code>Streamer</code> and <code>Language</code> are classes which inherit from <code>Node</code> and they map to a label in a graph database. Class <code>User</code> maps to a single <code>:User</code> label with properties <code>id</code> and <code>username</code>, class <code>Streamer</code> maps to multiple labels <code>:Streamer:User</code> with properties <code>id</code>, <code>username</code> and <code>followers</code>, and class Language maps to a single <code>:Language</code> label with <code>name</code> property.</p> <p>In a similar way, you can create relationship classes:</p> <pre><code>class ChatsWith(Relationship, type=\"CHATS_WITH\"):\n    last_chatted: str\n\nclass Speaks(Relationship):\n    since: str\n</code></pre> <p>The code above maps to a relationship of type <code>CHATS_WITH</code> with the string property <code>last_chatted</code> and to a relationship of type <code>SPEAKS</code> with the string property since. There was no need to add type argument to <code>Speaks</code> class, since the label it maps to will automatically be set to uppercase class name in a graph database. </p> <p>If you want to create a node class without any properties, use <code>pass</code> statement:</p> <pre><code>class User(Node):\n    pass\n</code></pre> <p>For relationships without any properties also use <code>pass</code> statement:</p> <pre><code>class ChatsWith(Relationship, type=\"CHATS_WITH\"):\n    pass\n</code></pre> <p>Info</p> <p>Objects are modeled using GQLAlchemy\u2019s Object Graph Mapper (OGM) which provides schema validation, so you can be sure that the data inside Memgraph is accurate. If you tried saving data that is not following the defined schema, you will get a <code>ValidationError</code>. </p> <p>To use the above classes, you need to save or load data first. </p>"},{"location":"how-to-guides/ogm/#save-nodes-and-relationships","title":"Save nodes and relationships","text":"<p>In order to save a node using the object graph mapper, first define node classes:</p> <pre><code>from gqlalchemy import Memgraph, Node, Relationship\n\ndb = Memgraph()\n\nclass User(Node):\n    id: str \n    username: str\n\nclass Language(Node):\n    name: str\n</code></pre> <p>The above classes map to <code>User</code> and <code>Language</code> nodes in the database. <code>User</code> nodes have properties <code>id</code> and <code>username</code> and <code>Language</code> nodes have property <code>name</code>. </p> <p></p> <p>To create and save node objects use the following code:</p> <pre><code>john = User(id=\"1\", username=\"John\").save(db)\njane = Streamer(id=\"2\", username=\"janedoe\", followers=111).save(db)\nlanguage = Language(name=\"en\").save(db)\n</code></pre> <p>There is another way of creating and saving node objects:</p> <pre><code>john = User(id=\"1\", username=\"John\")\ndb.save_node(john)\n\njane = Streamer(id=\"2\", username=\"janedoe\", followers=111)\ndb.save_node(jane)\n\nlanguage = Language(name=\"en\")\ndb.save_node(language)\n</code></pre> <p>Danger</p> <p>The <code>save()</code> and <code>save_node()</code> procedures will save nodes in Memgraph even if they already exist. This means that if you run the above code twice, you will have duplicate nodes in the database. To avoid that, add constraints for properties or first load the node from the database to check if it already exists.</p> <p>To save relationships using the object graph mapper, first define relationship classes:</p> <pre><code>class ChatsWith(Relationship, type=\"CHATS_WITH\"):\n    last_chatted: str\n\nclass Speaks(Relationship):\n    since: str\n</code></pre> <p>The code above maps to a relationship of type <code>CHATS_WITH</code> with the string property <code>last_chatted</code> and to a relationship of type <code>SPEAKS</code> with the string property since. There was no need to add type argument to <code>Speaks</code> class, since the label it maps to will automatically be set to uppercase class name in a graph database. </p> <p>To save relationships, create them with appropriate start and end nodes and then use the <code>save()</code> procedure:</p> <pre><code>ChatsWith(\n    _start_node_id=john._id, _end_node_id=jane._id, last_chatted=\"2023-02-14\"\n).save(db)\n\nSpeaks(_start_node_id=john._id, _end_node_id=language._id, since=\"2023-02-14\").save(db)\n</code></pre> <p>The property <code>_id</code> is an internal Memgraph id - an id given to each node upon saving to the database. This means that you have to first load nodes from the database or save them to variables in order to create a relationship between them.</p> <p>Info</p> <p>Objects are modeled using GQLAlchemy\u2019s Object Graph Mapper (OGM) which provides schema validation, so you can be sure that the data inside Memgraph is accurate. If you tried saving data that is not following the defined schema, you will get <code>ValidationError</code>. </p> <p>Another way of saving relationships is by using the <code>save_relationship()</code> procedure:</p> <pre><code>db.save_relationship(\n    ChatsWith(_start_node_id=john._id, _end_node_id=jane._id, last_chatted=\"2023-02-14\")\n)\n\ndb.save_relationship(\n    Speaks(_start_node_id=user._id, _end_node_id=language._id, since=\"2023-02-14\")\n)\n</code></pre> <p>Danger</p> <p>The <code>save()</code> and <code>save_relationship()</code> procedures will save relationships in Memgraph even if they already exist. This means that if you run the above code twice, you will have duplicate relationships in the database. To avoid that, first load the relationship from the database to check if it already exists.</p>"},{"location":"how-to-guides/ogm/#load-nodes-and-relationships","title":"Load nodes and relationships","text":"<p>Let's continue with the previously defined classes:</p> <pre><code>class User(Node):\n    id: str\n    username: str\n\n\nclass Streamer(User):\n    id: str\n    username: str\n    followers: int\n\n\nclass Language(Node):\n    name: str\n\n\nclass ChatsWith(Relationship, type=\"CHATS_WITH\"):\n    last_chatted: str\n\n\nclass Speaks(Relationship, type=\"SPEAKS\"):\n    since: str\n</code></pre> <p>For this example, we will also use previously saved nodes:</p> <pre><code>jane = Streamer(id=\"2\", username=\"janedoe\", followers=111).save(db)\nlanguage = Language(name=\"en\").save(db)\n</code></pre> <p>There are many examples of when loading a node from the database may come in handy, but let's cover the two most common. </p>"},{"location":"how-to-guides/ogm/#find-node-properties","title":"Find node properties","text":"<p>Suppose you just have the <code>id</code> of the streamer and you want to know the streamer's name. You have to load that node from the database to check its <code>name</code> property. If you try running the following code: </p> <pre><code>loaded_streamer = Streamer(id=\"2\").load(db=db)\n</code></pre> <p>you will get a <code>ValidationError</code>. This happens because the schema you defined expects <code>username</code> and <code>followers</code> properties for the <code>Streamer</code> instance. To avoid that, define Streamer class like this:</p> <pre><code>class Streamer(User):\n    id: str\n    username: Optional[str]\n    followers: Optional[str]\n</code></pre> <p>The above class definition is not ideal, since it is not enforcing schema as before. To do that, add constraints.</p> <p>If you try loading the node again, the following code:</p> <pre><code>loaded_streamer = Streamer(id=\"2\").load(db=db)\n</code></pre> <p>will print out the username of the streamer whose <code>id</code> equals <code>\"2\"</code>, that is, <code>\"janedoe\"</code>. </p>"},{"location":"how-to-guides/ogm/#create-relationship-between-existing-nodes","title":"Create relationship between existing nodes","text":"<p>To create a new relationship of type <code>SPEAKS</code>, between already saved streamer and language you need to first load those nodes:</p> <pre><code>loaded_streamer = Streamer(id=\"2\").load(db=db)\nloaded_language = Language(name=\"en\").load(db=db)\n</code></pre> <p>The load() method returns one result above, since it matches unique database objects. When the matching object is not unique, the <code>load()</code> method will return a list of matching results. </p> <p>To create a relationship between <code>loaded_streamer</code> and <code>loaded_language</code> nodes run:</p> <pre><code>Speaks(\n    _start_node_id=loaded_streamer._id,\n    _end_node_id=loaded_language._id,\n    since=\"2023-02-15\",\n).save(db)\n</code></pre> <p>In the above example, the relationship will be created even if it existed before. To avoid that, check merging nodes and relationships section.</p> <p>To load a relationship from the database based on its start and end node, first mark its property as optional:</p> <pre><code>class Speaks(Relationship, type=\"SPEAKS\"):\n    since: Optional[str]\n</code></pre> <p>The above class definition is not ideal, since it is not enforcing schema as before. To do that, add constraints.</p> <p>To load the relationship, run the following: </p> <pre><code>loaded_speaks = Speaks(\n        _start_node_id=streamer._id,\n        _end_node_id=language._id\n    ).load(db)\n</code></pre> <p>It's easy to get its <code>since</code> property:</p> <p><pre><code>print(loaded_speaks.since)\n</code></pre> The output of the above print is <code>2023-02-15</code>.</p>"},{"location":"how-to-guides/ogm/#merge-nodes-and-relationships","title":"Merge nodes and relationships","text":"<p>To merge nodes, first try loading them from the database to see if they exist, and if not, save them:</p> <pre><code>try:\n    streamer = Streamer(id=\"3\").load(db=db)\nexcept:\n    print(\"Creating new Streamer node in the database.\")\n    streamer = Streamer(id=\"3\", username=\"anne\", followers=222).save(db=db)\n</code></pre> <p>To merge relationships first try loading them from the database to see if they exist, and if not, save them:</p> <pre><code>try:\n    speaks = Speaks(_start_node_id=streamer._id, _end_node_id=language._id).load(db)\nexcept:\n    print(\"Creating new Speaks relationship in the database.\")\n    speaks = Speaks(\n        _start_node_id=streamer._id,\n        _end_node_id=language._id,\n        since=\"2023-02-20\",\n    ).save(db)\n</code></pre>"},{"location":"how-to-guides/ogm/#create-indexes","title":"Create indexes","text":"<p>To create indexes you need to do one additional import:</p> <pre><code>from gqlalchemy import Field\n</code></pre> <p>The <code>Field</code> class originates from <code>pydantic</code>, a Python library data validation and settings management. Here is the example of how <code>Field</code> class helps in creating label and label-property indexes:</p> <pre><code>class User(Node):\n    id: str = Field(index=True, db=db)\n    username: str\n\nclass Language(Node, index=True, db=db):\n    name: str\n</code></pre> <p>The indexes will be set on class definition, before instantiation. This ensures that the index creation is run only once for each index type. To check which indexes were created, run:</p> <pre><code>print(db.get_indexes())\n</code></pre> <p>The other way to create indexes is by creating an instance of <code>MemgraphIndex</code> class. For example, to create label index <code>NodeOne</code> and label-property index <code>NodeOne(name)</code>, run the following code:</p> <pre><code>from gqlalchemy import Memgraph\nfrom gqlalchemy.models import MemgraphIndex\n\ndb = Memgraph()\n\nindex1 = MemgraphIndex(\"NodeOne\")\nindex2 = MemgraphIndex(\"NodeOne\", \"name\")\n\ndb.create_index(index1)\ndb.create_index(index2)\n</code></pre> <p>To learn more about indexes, head over to the indexing reference guide.</p>"},{"location":"how-to-guides/ogm/#create-constraints","title":"Create constraints","text":"<p>Uniqueness constraint enforces that each <code>label</code>, <code>property_set</code> pair is unique. Here is how you can enforce uniqueness constraint with GQLAlchemy's OGM:</p> <pre><code>class Language(Node):\n    name: str = Field(unique=True, db=db)\n</code></pre> <p>The above is the same as running the Cypher query:</p> <pre><code>CREATE CONSTRAINT ON (n:Language) ASSERT n.name IS UNIQUE;\n</code></pre> <p>Read more about it at uniqueness constraint how-to guide.</p> <p>Existence constraint enforces that each vertex that has a specific label also must have the specified property.  Here is how you can enforce existence constraint with GQLAlchemy's OGM:</p> <pre><code>class Streamer(User):\n    id: str\n    username: Optional[str] = Field(exists=True, db=db)\n    followers: Optional[str]\n</code></pre> <p>The above is the same as running the Cypher query:</p> <pre><code>CREATE CONSTRAINT ON (n:Streamer) ASSERT EXISTS (n.username);\n</code></pre> <p>Read more about it at existence constraint how-to guide.</p> <p>To check which constraints have been created, run: </p> <pre><code>print(db.get_constraints())\n</code></pre>"},{"location":"how-to-guides/ogm/#full-code-example","title":"Full code example","text":"<p>The above mentioned examples can be merged into a working code example which you can run. Here is the code:</p> <pre><code>from gqlalchemy import Memgraph, Node, Relationship, Field\nfrom typing import Optional\n\ndb = Memgraph()\n\nclass User(Node):\n    id: str = Field(index=True, db=db)\n    username: str = Field(exists=True, db=db)\n\nclass Streamer(User):\n    id: str\n    username: Optional[str] = Field(exists=True, db=db)\n    followers: Optional[str]\n\nclass Language(Node, index=True, db=db):\n    name: str = Field(unique=True, db=db)\n\nclass ChatsWith(Relationship, type=\"CHATS_WITH\"):\n    last_chatted: str\n\nclass Speaks(Relationship, type=\"SPEAKS\"):\n    since: Optional[str]\n\njohn = User(id=\"1\", username=\"John\").save(db)\njane = Streamer(id=\"2\", username=\"janedoe\", followers=111).save(db)\nlanguage = Language(name=\"en\").save(db)\n\nChatsWith(\n    _start_node_id=john._id, _end_node_id=jane._id, last_chatted=\"2023-02-14\"\n).save(db)\n\nSpeaks(_start_node_id=john._id, _end_node_id=language._id, since=\"2023-02-14\").save(db)\n\nstreamer = Streamer(id=\"2\").load(db=db)\nlanguage = Language(name=\"en\").load(db=db)\n\nspeaks = Speaks(\n    _start_node_id=streamer._id,\n    _end_node_id=language._id,\n    since=\"2023-02-20\",\n).save(db)\n\nspeaks = Speaks(_start_node_id=streamer._id, _end_node_id=language._id).load(db)\nprint(speaks.since)\n\ntry:\n    streamer = Streamer(id=\"3\").load(db=db)\nexcept:\n    print(\"Creating new Streamer node in the database.\")\n    streamer = Streamer(id=\"3\", username=\"anne\", followers=222).save(db=db)\n\ntry:\n    speaks = Speaks(_start_node_id=streamer._id, _end_node_id=language._id).load(db)\nexcept:\n    print(\"Creating new Speaks relationship in the database.\")\n    speaks = Speaks(\n        _start_node_id=streamer._id,\n        _end_node_id=language._id,\n        since=\"2023-02-20\",\n    ).save(db)\n\nprint(db.get_indexes())\nprint(db.get_constraints())\n</code></pre> <p>Hopefully, this guide has taught you how to properly use GQLAlchemy object graph mapper. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/overview/","title":"How-to guides overview","text":"<p>This section will teach you how to use object graph mapper (OGM) and query builder from the GQLAlchemy. Here you will find step-by-step guides for the most common usage of OGM and query builder, depending on the current GQLAlchemy capabilities. If you are a Python developer not that familiar with Cypher query language, you will find the how-to guides very useful.</p>"},{"location":"how-to-guides/overview/#object-graph-mapper","title":"Object graph mapper","text":"<p>Object graph mapper (OGM) in GQLAlchemy maps Python classes to nodes and relationships in graph database and converts function calls to Cypher queries. To learn more about how to use OGM, take at OGM how-to guide.</p>"},{"location":"how-to-guides/overview/#query-builder","title":"Query builder","text":"<p>When working with GQLAlchemy, you can connect to the database and execute Cypher queries using the query builder. To learn more about how to create a query using query builder, check out the query builder how-to guide.</p>"},{"location":"how-to-guides/overview/#stream-trigger-support","title":"Stream &amp; trigger support","text":"<p>You can create streams and database triggers directly from GQLAlchemy. Check out the following guides:</p> <ul> <li>Kafka streams</li> <li>Pulsar streams</li> <li>Triggers</li> </ul>"},{"location":"how-to-guides/overview/#import-data-from-different-sources","title":"Import data from different sources","text":"<p>Info</p> <p>The features below aren\u2019t included in the default GQLAlchemy installation. To use them, make sure to install GQLAlchemy with the relevant extras.</p> <p>You can translate table data from a file to graph data and import it to Memgraph. Currently, we support reading of CSV, Parquet, ORC and IPC/Feather/Arrow file formats via the PyArrow package.</p> <p>You can use <code>loaders.py</code> which implements loading data from the local file system, as well as Azure Blob and Amazon S3 remote file systems:</p> <ul> <li>Import table data to a graph   database</li> </ul> <p>The other way to import data is to implement a custom file system importer:</p> <ul> <li>Implement a custom file system   importer</li> </ul>"},{"location":"how-to-guides/overview/#instance-runner","title":"Instance runner","text":"<p>There are two ways of managing a Memgraph instance with the <code>instance_runner</code> module:</p> <ul> <li>Manage a Memgraph instance with Docker</li> <li>Manage a Memgraph instance from a   binary</li> </ul>"},{"location":"how-to-guides/overview/#on-disk-storage","title":"On-disk storage","text":"<p>Since Memgraph is an in-memory graph database, the GQLAlchemy library provides an on-disk storage solution for large properties that don\u2019t need to be used in any of the graph algorithms. Learn how to use on-disk storage in the following guide:</p> <ul> <li>On-disk storage</li> </ul>"},{"location":"how-to-guides/overview/#graph-projections","title":"Graph projections","text":"<p>As subgraphs are mainly used with Memgraph's query modules (graph algorithms), QueryBuilder's <code>call()</code> method enables specifying the subgraph to use with a certain algorithm.</p> <ul> <li>Create a graph projection</li> </ul>"},{"location":"how-to-guides/overview/#transform-python-graphs-into-memgraph-graphs","title":"Transform Python graphs into Memgraph graphs","text":"<p>GQLAlchemy holds transformations that can transform NetworkX, PyG and DGL graphs into Memgraph graphs. These transformations take the source graph object and translate it to the appropriate Cypher queries. The Cypher queries are then executed to create a graph inside Memgraph.</p> <ul> <li>Import NetworkX graph into Memgraph</li> <li>Import PyG graph into Memgraph</li> <li>Import DGL graph into Memgraph</li> </ul>"},{"location":"how-to-guides/query-builder/","title":"How to use query builder","text":"<p>import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem';</p> <p>Through this guide, you will learn how to use the GQLAlchemy query builder to:</p> <ul> <li>Create nodes and relationships<ul> <li>Create a node</li> <li>Create a relationship</li> </ul> </li> <li>Merge nodes and relationships<ul> <li>Merge a node</li> <li>Merge a relationship</li> </ul> </li> <li>Set or update properties and labels<ul> <li>Set a property</li> <li>Set a label</li> <li>Replace all properties</li> <li>Update all properties</li> </ul> </li> <li>Filter data<ul> <li>Filter data by property comparison</li> <li>Filter data by property value</li> <li>Filter data by label</li> </ul> </li> <li>Return results<ul> <li>Return all variables from a query</li> <li>Return specific variables from a query</li> <li>Limit the number of returned results</li> <li>Order the returned results</li> <li>Order by a list of values</li> </ul> </li> <li>Delete and remove objects<ul> <li>Delete a node</li> <li>Delete a relationship</li> <li>Remove properties</li> </ul> </li> <li>Call procedures<ul> <li>Call procedure with no arguments</li> <li>Call procedure with arguments</li> </ul> </li> <li>Load CSV file</li> </ul> <p>Hopefully, this guide will teach you how to properly use GQLAlchemy query builder. If you have any more questions, join our community and ping us on Discord.</p> <p>Info</p> <p>To test the above features, you must install GQLAlchemy and have a running Memgraph instance. If you're unsure how to run Memgraph, check out the Memgraph Quick start).</p>"},{"location":"how-to-guides/query-builder/#create-nodes-and-relationships","title":"Create nodes and relationships","text":"<p>Methods <code>create()</code>, <code>merge()</code>, <code>match()</code>, <code>node()</code>, <code>to()</code> and <code>from_()</code> are most often used when building a query to create or merge nodes and relationships.</p>"},{"location":"how-to-guides/query-builder/#create-a-node","title":"Create a node","text":"<p>To create a node with label <code>Person</code> and a property <code>name</code> of value \"Ron\", run the following code:</p> <p> <pre><code>from gqlalchemy import create\n\nquery = create().node(labels=\"Person\", name=\"Ron\").execute()\n</code></pre> <p> <pre><code>CREATE (:Person {name: 'Ron'});\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#create-a-relationship","title":"Create a relationship","text":"<p>To create a relationship of type <code>FRIENDS_WITH</code> with property <code>since</code> from one <code>Person</code> node to another, run the following code:</p> <p> <p><pre><code>from gqlalchemy import create\n\nquery = (\n    create()\n    .node(labels=\"Person\", name=\"Leslie\")\n    .to(relationship_type=\"FRIENDS_WITH\", since=\"2023-02-16\")\n    .node(labels=\"Person\", name=\"Ron\")\n    .execute()\n)\n</code></pre> <pre><code>CREATE (:Person {name: 'Leslie'})-[:FRIENDS_WITH {since: '2023-02-16'}]-&gt;(:Person {name: 'Ron'});\n</code></pre> <p> </p> <p>Since you are creating a relationship between two nodes, without first matching the existing nodes or merging the relationships, the nodes will be created too.</p> <p>To create a relationship of type <code>FRIENDS_WITH</code> from one <code>Person</code> node to another in an opposite direction, run the following code:</p> <p> <p><pre><code>from gqlalchemy import create\n\nquery = (\n    create()\n    .node(labels=\"Person\", name=\"Leslie\")\n    .from(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", name=\"Ron\")\n    .execute()\n)\n</code></pre> <pre><code>CREATE (:Person {name: 'Leslie'})&lt;-[:FRIENDS_WITH]-(:Person {name: 'Ron'});\n</code></pre> <p> </p> <p>Again, since you are creating a relationship between two nodes, without first matching the existing nodes or merging the relationships, the nodes will be created too.</p> <p>To create a relationship between existing nodes, first match the existing nodes and then create a relationship by running the following code:</p> <p> <p><pre><code>from gqlalchemy import create, match\n\nquery = (\n    match()\n    .node(labels=\"Person\", name=\"Leslie\", variable=\"leslie\")\n    .match()\n    .node(labels=\"Person\", name=\"Ron\", variable=\"ron\")\n    create()\n    .node(variable=\"leslie\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(variable=\"ron\")\n    .execute()\n)\n</code></pre> <pre><code>MATCH (leslie:Person {name: 'Leslie'})\nMATCH (ron:Person {name: 'Ron'})\nCREATE (leslie)-[:FRIENDS_WITH]-&gt;(ron);\n</code></pre> <p> </p> <p>Read more about <code>CREATE</code> clause in the Cypher manual.</p>"},{"location":"how-to-guides/query-builder/#merge-nodes-and-relationships","title":"Merge nodes and relationships","text":""},{"location":"how-to-guides/query-builder/#merge-a-node","title":"Merge a node","text":"<p>To merge a node, run the following code:</p> <p> <pre><code>from gqlalchemy import merge\n\nquery = merge().node(labels=\"Person\", name=\"Leslie\").execute()\n</code></pre> <p> <pre><code>MERGE (:Person {name: 'Leslie'});\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#merge-a-relationship","title":"Merge a relationship","text":"<p>To merge a relationship, first match the existing nodes and then merge the relationship by running the following code:</p> <p> <p><pre><code>from gqlalchemy import match, merge\n\nquery = (\n    match()\n    .node(labels=\"Person\", name=\"Leslie\", variable=\"leslie\")\n    .match()\n    .node(labels=\"Person\", name=\"Ron\", variable=\"ron\")\n    .merge()\n    .node(variable=\"leslie\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(variable=\"ron\")\n    .execute()\n)\n</code></pre> <pre><code>MATCH (leslie:Person {name: 'Leslie'})\nMATCH (ron:Person {name: 'Ron'})\nMERGE (leslie)-[:FRIENDS_WITH]-&gt;(ron);\n</code></pre> <p> </p> <p>Read more about <code>MERGE</code> clause in the Cypher manual.</p>"},{"location":"how-to-guides/query-builder/#set-or-update-properties-and-labels","title":"Set or update properties and labels","text":"<p>The <code>set_()</code> method is used to set labels on nodes, and properties on nodes and relationships. When being set, labels and properties can be updated or created, depending on the operator used as the argument of <code>set_()</code> method.</p>"},{"location":"how-to-guides/query-builder/#set-a-property","title":"Set a property","text":"<p>To set a property of a graph object use the assignment operator from the query builder or a simple equals sign as a string - <code>\"=\"</code>.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nquery = (\n    create()\n    .node(labels=\"Country\", variable=\"c\", name=\"Germany\")\n    .set_(item=\"c.population\", operator=Operator.ASSIGNMENT, literal=83000001)\n    .execute()\n)\n</code></pre> <p> <pre><code>CREATE (c:Country {name: 'Germany'}) SET c.population = 83000001;\n</code></pre> <p> </p> <p>Info</p> <p><code>Operator</code> is an enumeration class defined in the <code>declarative_base.py</code>. It can be imported from <code>gqlalchemy.query_builders.memgraph_query_builder</code>. </p> <p>If you don't want to import it, you can use strings <code>\"=\"</code>, <code>\"&gt;=\"</code>, <code>\"&gt;\"</code>, <code>\"&lt;&gt;\"</code>, <code>\":\"</code>, <code>\"&lt;\"</code>, <code>\"&lt;=\"</code>, <code>\"!=\"</code> or <code>\"+=\"</code> instead.</p> <p>To set a property of already existing node, first match the node and then set its property. </p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nquery = (\n    match()\n    .node(labels=\"Country\", variable=\"c\", name=\"Germany\")\n    .set_(item=\"c.population\", operator=Operator.ASSIGNMENT, literal=10000)\n    .execute()\n)\n</code></pre> <p> <pre><code>MATCH (c:Country {name: 'Germany'}) SET c.population = 10000;\n</code></pre> <p> </p> <p>To set multiple properties of a node, run the following code:</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nquery = (\n    match()\n    .node(variable=\"n\")\n    .where(item=\"n.name\", operator=\"=\", literal=\"Germany\")\n    .set_(item=\"n.population\", operator=Operator.ASSIGNMENT, literal=83000001)\n    .set_(item=\"n.capital\", operator=Operator.ASSIGNMENT, literal=\"Berlin\")\n    .execute()\n)\n</code></pre> <p> <pre><code>MATCH (n) WHERE n.name = 'Germany' SET n.population = 83000001 SET n.capital = 'Berlin';\n</code></pre> <p> </p> <p>If a node already has the properties we are setting, they will be updated to a new value. Otherwise, the properties will be created and their value will be set.</p>"},{"location":"how-to-guides/query-builder/#set-a-label","title":"Set a label","text":"<p>To set a label of a node, run the following code:</p> <p> <pre><code>from gqlalchemy import Match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nquery = Match()\n        .node(variable=\"c\", name=\"Germany\")\n        .set_(item=\"c\", operator=Operator.LABEL_FILTER, expression=\"Land\")\n        .return_()\n        .execute()\n</code></pre> <p> <pre><code>MATCH (c {name: 'Germany'}) SET c:Land RETURN *;\n</code></pre> <p> </p> <p>If a node already has a label, then it will have both old and new label. </p>"},{"location":"how-to-guides/query-builder/#replace-all-properties","title":"Replace all properties","text":"<p>With Cypher, it is possible to replace all properties using a map within a <code>SET</code> clause. Here is how to do it with query builder:</p> <p> <p><pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nquery = (\n    match()\n    .node(variable=\"c\", labels=\"Country\")\n    .where(item=\"c.name\", operator=\"=\", literal=\"Germany\")\n    .set_(\n        item=\"c\",\n        operator=Operator.ASSIGNMENT,\n        literal={\"country_name\": \"Germany\", \"population\": 85000000},\n    )\n    .execute()\n)\n</code></pre> <pre><code>MATCH (c:Country) WHERE c.name = 'Germany' SET c = {country_name: 'Germany', population: 85000000};\n</code></pre> <p> </p> <p>The properties that are not a part of the graph objects, but are in the map, will be set. The properties that are not in the map, but are a part of the graph objects, will be removed. If a property is both in map and a graph object property, it will be updated to a new value set in map.</p>"},{"location":"how-to-guides/query-builder/#update-all-properties","title":"Update all properties","text":"<p>With Cypher, it is also possible to update all properties using a map within a <code>SET</code> clause by  using the increment operator (<code>+=</code>). Here is how to do it with query builder:</p> <p> <p><pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nquery = (\n    match()\n    .node(variable=\"c\", labels=\"Country\")\n    .where(item=\"c.country_name\", operator=\"=\", literal=\"Germany\")\n    .set_(\n        item=\"c\",\n        operator=Operator.INCREMENT,\n        literal={\"population\": \"85000000\"},\n    )\n    .execute()\n)\n</code></pre> <pre><code>MATCH (c:Country) WHERE c.country_name = 'Germany' SET c += {population: '85000000'};\n</code></pre> <p> </p> <p>All the properties in the map (value of the <code>literal</code> argument) that are on a graph object will be updated. The properties that are not on a graph object but are in the map will be added. Properties that are not present in the map will be left as is.</p>"},{"location":"how-to-guides/query-builder/#filter-data","title":"Filter data","text":"<p>You can use the methods <code>where()</code>, <code>where_not()</code>, <code>or_where()</code>, <code>or_where_not()</code>, <code>and_where()</code>, <code>and_where_not()</code>, <code>xor_where()</code> and <code>xor_where_not()</code> to construct queries that will filter data.</p>"},{"location":"how-to-guides/query-builder/#filter-data-by-property-comparison","title":"Filter data by property comparison","text":"<p>To filter data by comparing properties of two nodes, run the following code:</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", variable=\"p2\")\n    .where(item=\"p1.name\", operator=Operator.LESS_THAN, expression=\"p2.name\")\n    .return_()\n    .execute()\n)\n\nprint(results)\n</code></pre> <p> <pre><code>MATCH (p1:Person)-[:FRIENDS_WITH]-&gt;(p2:Person) WHERE p1.name &lt; p2.name RETURN *;\n</code></pre> <p> </p> <p>Keyword arguments that can be used in filtering methods are <code>literal</code> and <code>expression</code>. Usually we use <code>literal</code> for property values and <code>expression</code> for property names and labels. That is because property names and labels shouldn't be quoted in Cypher statements. </p> <p>Info</p> <p>You will probably see the <code>GQLAlchemySubclassNotFoundWarning</code> warning. This happens if you did not define a Python class which maps to a graph object in the database. To do that, check the object graph mapper how-to guide. To ignore such warnings, you can do the following before query execution:</p> <pre><code>from gqlalchemy import models\n\nmodels.IGNORE_SUBCLASSNOTFOUNDWARNING = True\n</code></pre> <p>Standard boolean operators like <code>NOT</code>, <code>AND</code>, <code>OR</code> and <code>XOR</code> are used in the Cypher query language. To have <code>NOT</code> within <code>WHERE</code> clause, you need to use <code>where_not()</code> method.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", variable=\"p2\")\n    .where_not(item=\"p1.name\", operator=Operator.LESS_THAN, expression=\"p2.name\")\n    .return_()\n    .execute()\n)\n\nprint(results)\n</code></pre> <p> <pre><code>MATCH (p1:Person)-[:FRIENDS_WITH]-&gt;(p2:Person) WHERE NOT p1.name &lt; p2.name RETURN *;\n</code></pre> <p> </p> <p>In a similar way, you can use <code>AND</code> and <code>AND NOT</code> clauses which correspond to the methods <code>and_where()</code> and <code>and_not_where()</code>. Using the query below you can find all persons with the same <code>address</code> and <code>last_name</code>, but different <code>name</code>.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", variable=\"p2\")\n    .where(item=\"p1.address\", operator=Operator.EQUAL, expression=\"p2.address\")\n    .and_where(item=\"p1.last_name\", operator=Operator.EQUAL, expression=\"p2.last_name\")\n    .and_not_where(item=\"p1.name\", operator=Operator.EQUAL, expression=\"p2.name\")\n    .return_()\n    .execute()\n)\n\nprint(results)\n</code></pre> <p> <pre><code>MATCH (p1:Person)-[:FRIENDS_WITH]-&gt;(p2:Person)\nWHERE p1.address = p2.address\nAND p1.last_name = p2.last_name\nAND NOT p1.name = p2.name\nRETURN *;\n</code></pre> <p> </p> <p>The same goes for the <code>OR</code>, <code>OR NOT</code>, <code>XOR</code> and <code>XOR NOT</code> clauses, which correspond to the methods <code>or_where()</code>, <code>or_not_where()</code>, <code>xor_where()</code> and <code>xor_not_where()</code>.</p>"},{"location":"how-to-guides/query-builder/#filter-data-by-property-value","title":"Filter data by property value","text":"<p>You can filter data by comparing the property of a graph object to some value (a literal). Below you can see how to compare <code>age</code> property of a node to the integer.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p\")\n    .where(item=\"p.age\", operator=Operator.GREATER_THAN, literal=18)\n    .return_()\n    .execute()\n)\n</code></pre> <p> <pre><code>MATCH (p:Person) WHERE p.age &gt; 18 RETURN *;\n</code></pre> <p> </p> <p>The third keyword argument is <code>literal</code> since we wanted the property <code>age</code> to be saved as an integer. If we used <code>expression</code> keyword argument instead of <code>literal</code>, then the <code>age</code> property would be a string (it would be quoted in Cypher query). Instead of <code>Operator.GREATER_THAN</code>, a simple string of value <code>\"&gt;\"</code> can be used.</p> <p>Just like in property comparison, it is possible to use different boolean operators to further filter the data.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p\")\n    .where(item=\"p.age\", operator=Operator.GREATER_THAN, literal=18)\n    .or_where(item=\"p.name\", operator=Operator.EQUAL, literal=\"John\")\n    .return_()\n    .execute()\n)\n</code></pre> <p> <pre><code>MATCH (p:Person) WHERE p.age &gt; 18 OR p.name = \"John\" RETURN *;\n</code></pre> <p> </p> <p>The <code>literal</code> keyword is used again since you want <code>John</code> to be quoted in the Cypher query (to be saved as a string in the database).</p>"},{"location":"how-to-guides/query-builder/#filter-data-by-label","title":"Filter data by label","text":"<p>Nodes can be filtered by their label using the <code>WHERE</code> clause instead of specifying it directly in the <code>MATCH</code> clause. You have to use <code>expression</code> as the third keyword argument again since you don't want the quotes surrounding the label in the Cypher clause.</p> <p>To filter data by label use the following code:</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator\n\nresults = list(\n    match()\n    .node(variable=\"p\")\n    .where(item=\"p\", operator=Operator.LABEL_FILTER, expression=\"Person\")\n    .return_()\n    .execute()\n)\n\nprint(results)\n</code></pre> <p> <pre><code>MATCH (p) WHERE p:Person RETURN *;\n</code></pre> <p> </p> <p>Just like in property comparison, it is possible to use different boolean operators to further filter the data.</p>"},{"location":"how-to-guides/query-builder/#return-results","title":"Return results","text":"<p>You can use the methods <code>return_()</code>, <code>limit()</code>, <code>skip()</code> and <code>order_by()</code> to construct queries that will return data from the database.</p>"},{"location":"how-to-guides/query-builder/#return-all-variables-from-a-query","title":"Return all variables from a query","text":"<p>To return all the variables from a query, use the <code>return_()</code> method at the end of the query:</p> <p> <pre><code>from gqlalchemy import match\n\nresults = list(match().node(labels=\"Person\", variable=\"p\").return_().execute())\nprint(results)\n</code></pre> <p> <pre><code>MATCH (p:Person) RETURN *;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#return-specific-variables-from-a-query","title":"Return specific variables from a query","text":"<p>To return only a subset of variables from a query, specify them in the <code>return_()</code> method:</p> <p> <pre><code>from gqlalchemy import match\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to()\n    .node(labels=\"Person\", variable=\"p2\")\n    .return_(results=[(\"p1\", \"first\"), \"p2\"])\n    .execute()\n)\n\nfor result in results:\n    print(\"Here is one pair:\")\n    print(result[\"first\"])\n    print(result[\"p2\"])\n</code></pre> <p> <pre><code>MATCH (p1:Person)-[]-&gt;(p2:Person) RETURN p1 AS first, p2;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#limit-the-number-of-returned-results","title":"Limit the number of returned results","text":"<p>To limit the number of returned results, use the <code>limit()</code> method after the <code>return_()</code> method:</p> <p> <pre><code>from gqlalchemy import match\n\nresults = list(match().node(labels=\"Person\", variable=\"p\").return_().limit(3).execute())\nprint(results)\n</code></pre> <p> <pre><code>MATCH (p:Person) RETURN * LIMIT 3;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#order-the-returned-results","title":"Order the returned results","text":"<p>The default ordering in the Cypher query language is ascending (<code>ASC</code> or <code>ASCENDING</code>), and if you want the descending order, you need to add the <code>DESC</code> or <code>DESCENDING</code> keyword to the <code>ORDER BY</code> clause.</p> <p>To order the return results by one value, use the <code>order_by(properties)</code> method, where <code>properties</code> can be a string (a property) or a tuple of two strings (a property and an order).</p> <p>The following query will order the results in an ascending (default) order by the property <code>name</code> of a node.</p> <p> <pre><code>from gqlalchemy import match\n\nresults = list(\n    match().node(variable=\"n\").return_().order_by(properties=\"n.name\").execute()\n)\nprint(results)\n</code></pre> <p> <pre><code>MATCH (n) RETURN * ORDER BY n.name;\n</code></pre> <p> </p> <p>You can also emphasize that you want an ascending order:</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Order\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(properties=(\"n.name\", Order.ASC))\n    .execute()\n)\nprint(results)\n</code></pre> <p> <pre><code>MATCH (n) RETURN * ORDER BY n.name ASC;\n</code></pre> <p> </p> <p>The same can be done with the keyword <code>ASCENDING</code>:</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Order\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(properties=(\"n.name\", Order.ASCENDING))\n    .execute()\n)\nprint(results)\n</code></pre> <p> <pre><code>MATCH (n) RETURN * ORDER BY n.name ASCENDING;\n</code></pre> <p> </p> <p>Info</p> <p><code>Order</code> is an enumeration class defined in the <code>declarative_base.py</code>. It can be imported from <code>gqlalchemy.query_builders.memgraph_query_builder</code>. </p> <p>If you don't want to import it, you can use strings <code>\"ASC\"</code>, <code>\"ASCENDING\"</code>, <code>\"DESC\"</code> or <code>\"DESCENDING\"</code> instead.</p> <p>To order the query results in descending order, you need to specify the <code>DESC</code> or <code>DESCENDING</code> keyword. Hence, the argument of the <code>order_by()</code> method must be a tuple.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Order\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(properties=(\"n.name\", Order.DESC))\n    .execute()\n)\n\nprint(results)\n</code></pre> <p> <pre><code>MATCH (n) RETURN * ORDER BY n.name DESC;\n</code></pre> <p> </p> <p>Similarly, you can use <code>Order.DESCENDING</code> to get <code>DESCENDING</code> keyword in <code>ORDER BY</code> clause.</p>"},{"location":"how-to-guides/query-builder/#order-by-a-list-of-values","title":"Order by a list of values","text":"<p>To order the returned results by more than one value, use the <code>order_by(properties)</code> method, where <code>properties</code> can be a list of strings or tuples of strings (list of properties with or without order).</p> <p>The following query will order the results in ascending order by the property <code>id</code>, then again in ascending (default) order by the property <code>name</code> of a node. After that, it will order the results in descending order by the property <code>last_name</code>, then in ascending order by the property <code>age</code> of a node. Lastly, the query will order the results in descending order by the node property <code>middle_name</code>.</p> <p> <pre><code>from gqlalchemy import match\nfrom gqlalchemy.query_builders.memgraph_query_builder import Order\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(\n        properties=[\n            (\"n.id\", Order.ASC),\n            \"n.name\",\n            (\"n.last_name\", Order.DESC),\n            (\"n.age\", Order.ASCENDING),\n            (\"n.middle_name\", Order.DESCENDING),\n        ]\n    )\n    .execute()\n)\n\nprint(results)\n</code></pre> <p> <pre><code>MATCH (n) RETURN * ORDER BY n.id ASC, n.name, n.last_name DESC, n.age ASCENDING, n.middle_name DESCENDING;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#delete-and-remove-objects","title":"Delete and remove objects","text":"<p>You can use the methods <code>delete()</code> and <code>remove()</code> to construct queries that will remove nodes and relationships or properties and labels.</p>"},{"location":"how-to-guides/query-builder/#delete-a-node","title":"Delete a node","text":"<p>To delete a node from the database, use the <code>delete()</code> method:</p> <p> <pre><code>from gqlalchemy import match\n\nmatch().node(labels=\"Person\", name=\"Harry\", variable=\"p\").delete(\n    variable_expressions=\"p\"\n).execute()\n</code></pre> <p> <pre><code>MATCH (p:Person {name: 'Harry'}) DELETE p;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#delete-a-relationship","title":"Delete a relationship","text":"<p>To delete a relationship from the database, use the <code>delete()</code> method:</p> <p> <pre><code>from gqlalchemy import match\n\nmatch().node(labels=\"Person\", name=\"Leslie\").to(\n    relationship_type=\"FRIENDS_WITH\", variable=\"f\"\n).node(labels=\"Person\").delete(variable_expressions=\"f\").execute()\n</code></pre> <p> <pre><code>MATCH (:Person {name: 'Leslie'})-[f:FRIENDS_WITH]-&gt;(:Person) DELETE f;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#remove-properties","title":"Remove properties","text":"<p>To remove a property (or properties) from the database, use the <code>remove()</code> method:</p> <p> <pre><code>from gqlalchemy import match\n\nmatch().node(labels=\"Person\", name=\"Jane\", variable=\"p\").remove(\n    items=[\"p.name\", \"p.last_name\"]\n).execute()\n</code></pre> <p> <pre><code>MATCH (p:Person {name: 'Jane'}) REMOVE p.name, p.last_name;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#call-procedures","title":"Call procedures","text":"<p>You can use the methods <code>call()</code> and <code>yield_()</code> to construct queries that will call procedure and return results from them.</p>"},{"location":"how-to-guides/query-builder/#call-procedure-with-no-arguments","title":"Call procedure with no arguments","text":"<p>To call a procedure with no arguments, don't specify the arguments in the <code>call()</code> method:</p> <p> <pre><code>from gqlalchemy import call\n\nresults = list(call(\"pagerank.get\").yield_().return_().execute())\nprint(results)\n</code></pre> <p> <pre><code>CALL pagerank.get() YIELD * RETURN *;\n</code></pre> <p> </p>"},{"location":"how-to-guides/query-builder/#call-procedure-with-arguments","title":"Call procedure with arguments","text":"<p>To call a procedure with arguments, specify the arguments as a string in the <code>call()</code> method:</p> <p> <pre><code>from gqlalchemy import call\n\nresults = list(\n    call(\n        \"json_util.load_from_url\",\n        \"'https://download.memgraph.com/asset/mage/data.json'\",\n    )\n    .yield_(\"objects\")\n    .return_(results=\"objects\")\n    .execute()\n)\n\nprint(\"Load from URL with argument:\", results, \"\\n\")\n</code></pre> <p> <pre><code>CALL json_util.load_from_url('https://download.memgraph.com/asset/mage/data.json') \nYIELD objects RETURN objects;\n</code></pre> <p> </p> Code example using all of the above mentioned queries <pre><code>from gqlalchemy import create, merge, Memgraph, match, models, call\nfrom gqlalchemy.query_builders.memgraph_query_builder import Operator, Order\n\n\ndb = Memgraph()\n# clean database\ndb.drop_database()\n\n# create nodes and a relationship between them\n\ncreate().node(labels=\"Person\", name=\"Leslie\").to(relationship_type=\"FRIENDS_WITH\").node(\n    labels=\"Person\", name=\"Ron\"\n).execute()\n\n\n# merge a node\nmerge().node(labels=\"Person\", name=\"Leslie\").execute()\n\n# create nodes and a relationship between them\ncreate().node(\n    labels=\"Person\", name=\"Jane\", last_name=\"James\", address=\"street\", age=19\n).from_(relationship_type=\"FRIENDS_WITH\", since=\"2023-02-16\").node(\n    labels=\"Person\", name=\"John\", last_name=\"James\", address=\"street\", age=8\n).execute()\n\n\n# merge a relationship between existing nodes\n\nmatch().node(labels=\"Person\", name=\"Leslie\", variable=\"leslie\").match().node(\n    labels=\"Person\", name=\"Ron\", variable=\"ron\"\n).merge().node(variable=\"leslie\").to(relationship_type=\"FRIENDS_WITH\").node(\n    variable=\"ron\"\n).execute()\n\n\n# set a property\ncreate().node(labels=\"Country\", variable=\"c\", name=\"Germany\").set_(\n    item=\"c.population\", operator=Operator.ASSIGNMENT, literal=83000001\n).execute()\n\n# update a property\nmatch().node(labels=\"Country\", variable=\"c\", name=\"Germany\").set_(\n    item=\"c.population\", operator=Operator.ASSIGNMENT, literal=10000\n).execute()\n\n\n# update multiple properties\nmatch().node(variable=\"n\").where(item=\"n.name\", operator=\"=\", literal=\"Germany\").set_(\n    item=\"n.population\", operator=Operator.ASSIGNMENT, literal=83000001\n).set_(item=\"n.capital\", operator=Operator.ASSIGNMENT, literal=\"Berlin\").execute()\n\n\n# replace all properties\nmatch().node(variable=\"c\", labels=\"Country\").where(\n    item=\"c.name\", operator=\"=\", literal=\"Germany\"\n).set_(\n    item=\"c\",\n    operator=Operator.ASSIGNMENT,\n    literal={\"country_name\": \"Germany\", \"population\": 85000000},\n).execute()\n\n\n# update multiple properties\n\nmatch().node(variable=\"c\", labels=\"Country\").where(\n    item=\"c.country_name\", operator=\"=\", literal=\"Germany\"\n).set_(\n    item=\"c\",\n    operator=Operator.INCREMENT,\n    literal={\"population\": \"85000000\"},\n).execute()\n\n\nmodels.IGNORE_SUBCLASSNOTFOUNDWARNING = True\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", variable=\"p2\")\n    .where(item=\"p1.name\", operator=Operator.LESS_THAN, expression=\"p2.name\")\n    .return_()\n    .execute()\n)\n\nprint(\"Filter by property comparison:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", variable=\"p2\")\n    .where_not(item=\"p1.name\", operator=Operator.LESS_THAN, expression=\"p2.name\")\n    .return_()\n    .execute()\n)\n\nprint(\"Filter by property comparison (negation):\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to(relationship_type=\"FRIENDS_WITH\")\n    .node(labels=\"Person\", variable=\"p2\")\n    .where(item=\"p1.address\", operator=Operator.EQUAL, expression=\"p2.address\")\n    .and_where(item=\"p1.last_name\", operator=Operator.EQUAL, expression=\"p2.last_name\")\n    .and_not_where(item=\"p1.name\", operator=Operator.EQUAL, expression=\"p2.name\")\n    .return_()\n    .execute()\n)\n\nprint(\"Filter by property comparison + logical operators:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p\")\n    .where(item=\"p.age\", operator=Operator.GREATER_THAN, literal=18)\n    .return_()\n    .execute()\n)\n\nprint(\"Filter by property value:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p\")\n    .where(item=\"p.age\", operator=Operator.GREATER_THAN, literal=18)\n    .or_where(item=\"p.name\", operator=Operator.EQUAL, literal=\"John\")\n    .return_()\n    .execute()\n)\n\nprint(\"Filter by property value + logical operators:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(variable=\"p\")\n    .where(item=\"p\", operator=Operator.LABEL_FILTER, expression=\"Person\")\n    .return_()\n    .execute()\n)\n\nprint(\"Filter by label:\", results, \"\\n\")\n\n\nresults = list(match().node(labels=\"Person\", variable=\"p\").return_().execute())\nprint(\"Return all:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(labels=\"Person\", variable=\"p1\")\n    .to()\n    .node(labels=\"Person\", variable=\"p2\")\n    .return_(results=[(\"p1\", \"first\"), \"p2\"])\n    .execute()\n)\n\nfor result in results:\n    print(\"Here is one pair:\")\n    print(result[\"first\"])\n    print(result[\"p2\"])\n\nprint()\n\nresults = list(match().node(labels=\"Person\", variable=\"p\").return_().limit(3).execute())\nprint(\"Limit results:\", results, \"\\n\")\n\n\nresults = list(\n    match().node(variable=\"n\").return_().order_by(properties=\"n.name\").execute()\n)\nprint(\"Order descending:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(properties=(\"n.name\", Order.ASCENDING))\n    .execute()\n)\nprint(\"Order ascending:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(properties=(\"n.name\", Order.DESC))\n    .execute()\n)\n\nprint(\"Order descending with ordering:\", results, \"\\n\")\n\nresults = list(\n    match()\n    .node(variable=\"n\")\n    .return_()\n    .order_by(\n        properties=[\n            (\"n.id\", Order.ASC),\n            \"n.name\",\n            (\"n.last_name\", Order.DESC),\n            (\"n.age\", Order.ASCENDING),\n            (\"n.middle_name\", Order.DESCENDING),\n        ]\n    )\n    .execute()\n)\n\nprint(\"Mix of ordering:\", results, \"\\n\")\n\n\n# create a node to delete\ncreate().node(labels=\"Person\", name=\"Harry\").execute()\n\n# delete a node\nmatch().node(labels=\"Person\", name=\"Harry\", variable=\"p\").delete(\n    variable_expressions=\"p\"\n).execute()\n\n# delete a relationship between Leslie and her friends\nmatch().node(labels=\"Person\", name=\"Leslie\").to(\n    relationship_type=\"FRIENDS_WITH\", variable=\"f\"\n).node(labels=\"Person\").delete(variable_expressions=\"f\").execute()\n\n# remove name and last_name properties from Jane\nmatch().node(labels=\"Person\", name=\"Jane\", variable=\"p\").remove(\n    items=[\"p.name\", \"p.last_name\"]\n).execute()\n\n# calculate PageRank\nresults = list(call(\"pagerank.get\").yield_().return_().execute())\nprint(\"PageRank:\", results, \"\\n\")\n\n# Load JSON from URL with arguments\nresults = list(\n    call(\n        \"json_util.load_from_url\",\n        \"'https://download.memgraph.com/asset/mage/data.json'\",\n    )\n    .yield_(\"objects\")\n    .return_(results=\"objects\")\n    .execute()\n)\n\nprint(\"Load from URL with argument:\", results, \"\\n\")\n</code></pre>"},{"location":"how-to-guides/query-builder/#load-csv-file","title":"Load CSV file","text":"<p>To load a CSV file using query builder, use the <code>load_csv()</code> procedure. Here is an example CSV file: <pre><code>id,name,age,city\n100,Daniel,30,London\n101,Alex,15,Paris\n102,Sarah,17,London\n103,Mia,25,Zagreb\n104,Lucy,21,Paris\n</code></pre></p> <p>To load it, run the following code:</p> <pre><code>from gqlalchemy import load_csv, Memgraph\nfrom gqlalchemy.utilities import CypherVariable\n\ndb = Memgraph()\n\nload_csv(\n      path=\"/path-to/people_nodes.csv\", header=True, row=\"row\"\n  )\n  .create()\n  .node(\n      variable=\"n\",\n      labels=\"Person\",\n      id=CypherVariable(name=\"row.id\"),\n      name=CypherVariable(name=\"row.name\"),\n      age=CypherVariable(name=\"ToInteger(row.age)\"),\n      city=CypherVariable(name=\"row.city\"),\n  )\n  .execute()\n</code></pre> <p>Hopefully, this guide has taught you how to properly use GQLAlchemy query builder. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/instance-runner/memgraph-binary-instance/","title":"How to manage Memgraph binary instances in Python","text":"<p>Through this guide, you will learn how to start, stop, connect to and monitor Memgraph instances with GQLAlchemy.</p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre> <p>First, perform all the necessary imports:</p> <pre><code>from gqlalchemy.instance_runner import MemgraphInstanceBinary\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-binary-instance/#start-the-memgraph-instance","title":"Start the Memgraph instance","text":"<p>Warning</p> <p>In order to start a Memgraph instance that you installed using <code>dpkg</code>, you need to run the binary file as user <code>memgraph</code>. Otherwise, the process won't have the right access rights to the needed directories and files.</p> <p>The following code will create a Memgraph instance, start it and return a connection object:</p> <pre><code>memgraph_instance = MemgraphInstanceBinary(\n    host=\"0.0.0.0\", port=7698, binary_path=\"/usr/lib/memgraph/memgraph\", user=\"memgraph\"\n)\nmemgraph = memgraph_instance.start_and_connect(restart=False)\n</code></pre> <p>We used the default values for the arguments:</p> <ul> <li><code>host=\"0.0.0.0\"</code>: This is the wildcard address which indicates that the   instance should accept connections from all interfaces.</li> <li><code>port=7687</code>: This is the default port Memgraph listens to.</li> <li><code>binary_path=\"/usr/lib/memgraph/memgraph\"</code>: The default location of the   Memgraph binary file on Ubuntu.</li> <li><code>user=\"memgraph\"</code>: The user that will start the Memgraph process.</li> <li><code>restart=False</code>: If the instance is already running, it won't be stopped and   started again.</li> </ul> <p>After we have created the connection, we can start querying the database:</p> <pre><code>memgraph.execute_and_fetch(\"RETURN 'Memgraph is running' AS result\"))[0][\"result\"]\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-binary-instance/#pass-configuration-flags","title":"Pass configuration flags","text":"<p>You can pass configuration flags using a dictionary:</p> <pre><code>config={\"--log-level\": \"TRACE\"}\nmemgraph_instance = MemgraphInstanceBinary(config=config)\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-binary-instance/#stop-the-memgraph-instance","title":"Stop the Memgraph instance","text":"<p>To stop a Memgraph instance, call the <code>stop()</code> method:</p> <pre><code>memgraph_instance.stop()\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-binary-instance/#check-if-a-memgraph-instance-is-running","title":"Check if a Memgraph instance is running","text":"<p>To check if a Memgraph instance is running, call the <code>is_running()</code> method:</p> <pre><code>memgraph_instance.is_running()\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-binary-instance/#where-to-next","title":"Where to next?","text":"<p>Hopefully, this guide has taught you how to manage Memgraph binary instances. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/","title":"Manage Memgraph Docker instances","text":"<p>Info</p> <p>The features below aren\u2019t included in the default GQLAlchemy installation. To use them, make sure to install GQLAlchemy with the <code>docker</code> extra.</p>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/#how-to-manage-memgraph-docker-instances-in-python","title":"How to manage Memgraph Docker instances in Python","text":"<p>Through this guide, you will learn how to start, stop, connect to and monitor Memgraph instances with GQLAlchemy.</p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre> <p>First, perform all the necessary imports:</p> <pre><code>from gqlalchemy.instance_runner import (\n    DockerImage,\n    MemgraphInstanceDocker\n)\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/#start-the-memgraph-instance","title":"Start the Memgraph instance","text":"<p>The following code will create a Memgraph instance, start it and return a connection object:</p> <pre><code>memgraph_instance = MemgraphInstanceDocker(\n    docker_image=DockerImage.MEMGRAPH, docker_image_tag=\"latest\", host=\"0.0.0.0\", port=7687\n)\nmemgraph = memgraph_instance.start_and_connect(restart=False)\n</code></pre> <p>We used the default values for the arguments:</p> <ul> <li><code>docker_image=DockerImage.MEMGRAPH</code>: This will start the <code>memgraph/memgraph</code>   Docker image.</li> <li><code>docker_image_tag=\"latest\"</code>: We use the <code>latest</code> tag to start the most recent   version of Memgraph.</li> <li><code>host=\"0.0.0.0\"</code>: This is the wildcard address which indicates that the   instance should accept connections from all interfaces.</li> <li><code>port=7687</code>: This is the default port Memgraph listens to.</li> <li><code>restart=False</code>: If the instance is already running, it won't be stopped and   started again.</li> </ul> <p>After we have created the connection, we can start querying the database:</p> <pre><code>memgraph.execute_and_fetch(\"RETURN 'Memgraph is running' AS result\"))[0][\"result\"]\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/#pass-configuration-flags","title":"Pass configuration flags","text":"<p>You can pass configuration flags using a dictionary:</p> <pre><code>config={\"--log-level\": \"TRACE\"}\nmemgraph_instance = MemgraphInstanceDocker(config=config)\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/#stop-the-memgraph-instance","title":"Stop the Memgraph instance","text":"<p>To stop a Memgraph instance, call the <code>stop()</code> method:</p> <pre><code>memgraph_instance.stop()\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/#check-if-a-memgraph-instance-is-running","title":"Check if a Memgraph instance is running","text":"<p>To check if a Memgraph instance is running, call the <code>is_running()</code> method:</p> <pre><code>memgraph_instance.is_running()\n</code></pre>"},{"location":"how-to-guides/instance-runner/memgraph-docker-instance/#where-to-next","title":"Where to next?","text":"<p>Hopefully, this guide has taught you how to manage Memgraph Docker instances. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/loaders/import-table-data-to-graph-database/","title":"How to import table data to a graph database","text":"<p>This guide will show you how to use <code>loaders.py</code> to translate table data from a file to graph data and import it to Memgraph. Currently, we support reading of CSV, Parquet, ORC and IPC/Feather/Arrow file formats via the PyArrow package.</p> <p>Make sure you have a running Memgraph instance. If you're not sure how to run Memgraph, check out the Memgraph Quick start.</p> <p>The <code>loaders.py</code> module implements loading data from the local file system, as well as Azure Blob and Amazon S3 remote file systems. Depending on where your data is located, here are two guides on how to import it to Memgraph:</p> <ul> <li>Loading a CSV file from the local file   system</li> <li>Using a cloud storage solution</li> </ul> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre> <p>Info</p> <p>The features below aren\u2019t included in the default GQLAlchemy installation. To use them, make sure to install GQLAlchemy with the relevant extras.</p>"},{"location":"how-to-guides/loaders/import-table-data-to-graph-database/#loading-a-csv-file-from-the-local-file-system","title":"Loading a CSV file from the local file system","text":"<p>Let's say you have a simple table data in a CSV file stored at <code>/home/user/table_data</code>:</p> <pre><code>name,surname,grade\nIvan,Horvat,4\nMarko,Andric,5\nLuka,Lukic,3\n</code></pre> <p>To create a translation from table to graph data, you need to define a data configuration object. This can be done inside your code by defining a dictionary, but it is recommended to use a YAML file structured like this:</p> <pre><code>indices:    # indices to be created for each table\nindividuals:    # name of table containing individuals with ind_id\n- ind_id\naddress:\n- add_id\n\n\nname_mappings:    # how we want to name node labels\nindividuals:\nlabel: INDIVIDUAL    # nodes made from individuals table will have INDIVIDUAL label\naddress:\nlabel: ADDRESS\ncolumn_names_mapping: {\"current_column_name\": \"mapped_name\"}    # (optional) map column names\n\n\none_to_many_relations:\naddress: []        # currently needed, leave [] if no relations to define\nindividuals:\n- foreign_key: # foreign key used for mapping;\ncolumn_name: add_id         # specifies its column\nreference_table: address    # name of table from which the foreign key is taken\nreference_key: add_id       # column name in reference table from which the foreign key is taken\nlabel: LIVES_IN        # label applied to relationship created\nfrom_entity: False     # (optional) define direction of relationship created\n\n\nmany_to_many_relations:       # intended to be used in case of associative tables\nexample:\nforeign_key_from:        # describes the source of the relationship\ncolumn_name:\nreference_table:\nreference_key:\nforeign_key_to:          # describes the destination of the relationship\ncolumn_name:\nreference_table:\nreference_key:\nlabel:\n</code></pre> <p>For this example, you don't need all of those fields. You only need to define <code>indices</code> and <code>one_to_many_relations</code>. Hence, you have the following YAML file:</p> <pre><code>indices:\nexample:\n- name\n\nname_mappings:\nexample:\nlabel: PERSON\n\none_to_many_relations:\nexample: []\n</code></pre> <p>In order to read the data configuration from the YAML file, run:</p> <pre><code>with open(\"./example.yaml\", \"r\") as stream:\n    try:\n        parsed_yaml = yaml.load(stream, Loader=SafeLoader)\n    except yaml.YAMLError as exc:\n        print(exc)\n</code></pre> <p>Having defined the data configuration for the translation, all you need to do is make an instance of an <code>Importer</code> and call <code>translate()</code>.</p> <pre><code>importer = CSVLocalFileSystemImporter(\n    data_configuration=parsed_yaml,\n    path=\"/home/user/table_data\",\n)\n\nimporter.translate(drop_database_on_start=True)\n</code></pre>"},{"location":"how-to-guides/loaders/import-table-data-to-graph-database/#using-a-cloud-storage-solution","title":"Using a cloud storage solution","text":"<p>To connect to Azure Blob, simply change the Importer object you are using. Like above, first, define a data configuration object and then simply call:</p> <pre><code>importer = ParquetAzureBlobFileSystemImporter(\n    container_name=\"test\",\n    data_configuration=parsed_yaml,\n    account_name=\"your_account_name\",\n    account_key=\"your_account_key\",\n)\n</code></pre> <p>Hopefully, this guide has taught you how to import table data into Memgraph. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/loaders/make-a-custom-file-system-importer/","title":"How to make a custom file system importer","text":"<p>To learn how to import table data from a file to the Memgraph database, head over to the How to import table data guide.</p> <p>If you want to read from a file system not currently supported by GQLAlchemy, or use a file type currently not readable, you can implement your own by extending abstract classes <code>FileSystemHandler</code> and <code>DataLoader</code>, respectively.</p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre> <p>Info</p> <p>The features below aren\u2019t included in the default GQLAlchemy installation. To use them, make sure to install GQLAlchemy with the relevant extras.</p>"},{"location":"how-to-guides/loaders/make-a-custom-file-system-importer/#implementing-a-new-filesystemhandler","title":"Implementing a new <code>FileSystemHandler</code>","text":"<p>For this guide, you will use the existing <code>PyArrowDataLoader</code> capable of reading CSV, Parquet, ORC and IPC/Feather/Arrow file formats. The PyArrow loader class supports fsspec-compatible file systems, so to implement an Azure Blob file system, you need to follow these steps.</p>"},{"location":"how-to-guides/loaders/make-a-custom-file-system-importer/#1-extend-the-filesystemhandler-class","title":"1. Extend the <code>FileSystemHandler</code> class","text":"<p>This class holds the connection to the file system service and handles the path from which the <code>DataLoader</code> object reads files. To get a fsspec-compatible instance of an Azure Blob connection, you can use the adlfs package. We are going to pass <code>adlfs</code>-specific parameters such as <code>account_name</code> and <code>account_key</code> via kwargs. All that's left to do is to override the <code>get_path</code> method.</p> <pre><code>import adlfs\n\nclass AzureBlobFileSystemHandler(FileSystemHandler):\n\n    def __init__(self, container_name: str, **kwargs) -&gt; None:\n\"\"\"Initializes connection and data container.\"\"\"\n        super().__init__(fs=adlfs.AzureBlobFileSystem(**kwargs))\n        self._container_name = container_name\n\n    def get_path(self, collection_name: str) -&gt; str:\n\"\"\"Get file path in file system.\"\"\"\n        return f\"{self._container_name}/{collection_name}\"\n</code></pre>"},{"location":"how-to-guides/loaders/make-a-custom-file-system-importer/#2-wrap-the-tabletographimporter","title":"2. Wrap the <code>TableToGraphImporter</code>","text":"<p>Next, you are going to wrap the <code>TableToGraphImporter</code> class. This is optional since you can use the class directly, but it will be easier to use if we extend it with our custom importer class. Since we will be using PyArrow for data loading, you can extend the <code>PyArrowImporter</code> class (which extends the <code>TableToGraphImporter</code>) and make your own <code>PyArrowAzureBlobImporter</code>. This class should initialize the <code>AzureBlobFileSystemHandler</code> and leave the rest to the <code>PyArrowImporter</code> class. It should also receive a <code>file_extension_enum</code> argument, which defines the file type that you are going to be reading.</p> <pre><code>class PyArrowAzureBlobImporter(PyArrowImporter):\n\"\"\"PyArrowImporter wrapper for use with Azure Blob File System.\"\"\"\n\n    def __init__(\n        self,\n        container_name: str,\n        file_extension_enum: PyArrowFileTypeEnum,\n        data_configuration: Dict[str, Any],\n        memgraph: Optional[Memgraph] = None,\n        **kwargs,\n    ) -&gt; None:\n        super().__init__(\n            file_system_handler=AzureBlobFileSystemHandler(        \n                container_name=container_name, **kwargs\n            ),\n            file_extension_enum=file_extension_enum,\n            data_configuration=data_configuration,\n            memgraph=memgraph,\n        )\n</code></pre>"},{"location":"how-to-guides/loaders/make-a-custom-file-system-importer/#3-call-translate","title":"3. Call <code>translate()</code>","text":"<p>Finally, to use your custom file system, initialize the Importer class and call <code>translate()</code></p> <pre><code>importer = PyArrowAzureBlobImporter(\n    container_name=\"test\"\n    file_extension_enum=PyArrowFileTypeEnum.Parquet,\n    data_configuration=parsed_yaml,\n    account_name=\"your_account_name\",\n    account_key=\"your_account_key\",\n)\n\nimporter.translate(drop_database_on_start=True)\n</code></pre> <p>If you want to see the full implementation of the <code>AzureBlobFileSystem</code> and other loader components, have a look at the code. Feel free to create a PR on the GQLAlchemy repository if you think of a new feature we could use. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/on-disk-storage/on-disk-storage/","title":"How to use on-disk storage","text":"<p>Since Memgraph is an in-memory graph database, the GQLAlchemy library provides an on-disk storage solution for large properties not used in graph algorithms. This is useful when nodes or relationships have metadata that doesn\u2019t need to be used in any of the graph algorithms that need to be carried out in Memgraph, but can be fetched after. In this how-to guide, you'll learn how to use an SQL database to store node properties seamlessly as if they were being stored in Memgraph.</p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre>"},{"location":"how-to-guides/on-disk-storage/on-disk-storage/#connect-to-memgraph-and-an-sql-database","title":"Connect to Memgraph and an SQL database","text":"<p>First you need to do all necessary imports and connect to the running Memgraph and SQL database instance:</p> <pre><code>from gqlalchemy import Memgraph, SQLitePropertyDatabase, Node, Field\nfrom typing import Optional\n\ngraphdb = Memgraph()\nSQLitePropertyDatabase('path-to-my-db.db', graphdb)\n</code></pre> <p>The <code>graphdb</code> creates a connection to an in-memory graph database and <code>SQLitePropertyDatabase</code> attaches to <code>graphdb</code> in its constructor.</p>"},{"location":"how-to-guides/on-disk-storage/on-disk-storage/#define-schema","title":"Define schema","text":"<p>For example, you can create the class <code>User</code> which maps to a node object in the graph database.</p> <pre><code>class User(Node):\n    id: int = Field(unique=True, exists=True, index=True, db=graphdb)\n    huge_string: Optional[str] = Field(on_disk=True)\n</code></pre> <p>Here the property <code>id</code> is a required <code>int</code> that creates uniqueness and existence constraints inside Memgraph. You can notice that the property <code>id</code> is also indexed on label <code>User</code>. The <code>huge_string</code> property is optional, and because the <code>on_disk</code> argument is set to <code>True</code>, it will be saved into the SQLite database.</p>"},{"location":"how-to-guides/on-disk-storage/on-disk-storage/#create-data","title":"Create data","text":"<p>Next, you can create some huge string, which won't be saved into the graph database, but rather into the SQLite databse.</p> <pre><code>my_secret = \"I LOVE DUCKS\" * 1000\njohn = User(id=5, huge_string=my_secret).save(db)\njohn2 = User(id=5).load(db)\nprint(john2.huge_string)  # prints I LOVE DUCKS, a 1000 times\n</code></pre> <p>Hopefully this guide has taught you how to use on-disk storage along with the in-memory graph database. If you have any more questions, join our community and ping us on Discord.</p>"},{"location":"how-to-guides/query-builder/graph-projection/","title":"How to create a graph projection","text":"<p>As subgraphs are mainly used with Memgraph's query modules (graph algorithms),  <code>QueryBuilder</code>'s <code>call()</code> method enables specifying the subgraph to use with a certain algorithm.</p> <p>To call a procedure named <code>test_query_module</code> with argument <code>\"arg\"</code>, and run it on a subgraph containing only nodes with label <code>:LABEL</code> and their mutual  relationships build the following query:</p> <pre><code>from gqlalchemy import QueryBuilder\n\nlabel = \"LABEL\"\n\nquery_builder = QueryBuilder().call(procedure=\"test_query_module\",\n                                    arguments=(\"arg\"), node_labels=label)\n\nquery_builder.execute()\n</code></pre> <p>The above code executes the following Cypher query: <pre><code>MATCH p=(a)--&gt;(b)\nWHERE (a:LABEL)\nAND (b:LABEL)\nWITH project(p) AS graph\nCALL test_query_module(graph, 'arg')\n</code></pre></p> <p><code>WHERE</code> and <code>AND</code> clauses are used to allow for more generalization. To expand on this code you can use multiple relationship types and node labels. Node labels and relationship types can be passed as a single string, in which case that string is used for all labels or types. To specify different labels and types for entities on a path, you need to pass a list of lists, containing a list of labels for every node on a path, and likewise for relationships. You can use this as following:</p> <pre><code>node_labels = [[\"COMP\", \"DEVICE\"], [\"USER\"], [\"SERVICE\", \"GATEWAY\"]]\nrelationship_types = [[\"OWNER\", \"RENTEE\"], [\"USES\", \"MAKES\"]]\nrelationship_directions = [RelationshipDirection.LEFT, RelationshipDirection.RIGHT]\narguments = (\"arg0\", 5)\n\nquery_builder = QueryBuilder().call(procedure=\"test_query_module\",\n                                    arguments = arguments,\n                                    node_labels=node_labels,\n                                    relationship_types=relationship_types,\n                                    relationship_directions=relationship_directions)\n\nquery_builder.execute()\n</code></pre> <p>The above code executes the following Cypher query: <pre><code>MATCH p=(a)&lt;-[:OWNER | :RENTEE]-(b)-[:USES | :MAKES]-&gt;(c)\nWHERE (a:COMP or a:DEVICE)\nAND (b:USER)\nAND (c:SERVICE or c:GATEWAY)\nWITH project(p) AS graph\nCALL test_query_module(graph, \"arg0\", 5)\n</code></pre></p> <p>This query calls <code>test_query_module</code> on a subgraph containing all nodes labeled <code>USER</code> that have an outgoing relationship of types either <code>OWNER</code> or <code>RENTEE</code> towards nodes labeled <code>COMP</code> or <code>DEVICE</code> and also a relationship of type <code>USES</code> or <code>MAKES</code> towards nodes labeled <code>SERVICE</code> or <code>GATEWAY</code>.</p>"},{"location":"how-to-guides/streams/kafka-streams/","title":"How to manage Kafka streams","text":"<p>The stream functionality enables Memgraph to connect to a Kafka, Pulsar or Redpanda cluster and run graph analytics on the data stream.</p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre>"},{"location":"how-to-guides/streams/kafka-streams/#1-create-a-kafka-stream-in-memgraph","title":"1. Create a Kafka stream in Memgraph","text":"<p>To set up the streams, first, create a <code>MemgraphKafkaStream</code> object with all the required arguments:</p> <ul> <li><code>name: str</code> \u27a1 The name of the stream.</li> <li><code>topics: List[str]</code> \u27a1 List of topic names.</li> <li><code>transform: str</code> \u27a1 The transformation procedure for mapping incoming messages   to Cypher queries.</li> <li><code>consumer_group: str</code> \u27a1 Name of the consumer group in Memgraph.</li> <li><code>batch_interval: str = None</code> \u27a1 Maximum wait time in milliseconds for consuming   messages before calling the transform procedure.</li> <li><code>batch_size: str = None</code> \u27a1 Maximum number of messages to wait for before   calling the transform procedure.</li> <li><code>bootstrap_servers: str = None</code> \u27a1 Comma-separated list of bootstrap servers.</li> </ul> <p>Now you just have to call the <code>create_stream()</code> method with the newly created <code>MemgraphKafkaStream</code> object:</p> <pre><code>from gqlalchemy import MemgraphKafkaStream\n\nstream = MemgraphKafkaStream(name=\"ratings_stream\", topics=[\"ratings\"], transform=\"movielens.rating\", bootstrap_servers=\"localhost:9093\")\ndb.create_stream(stream)\n</code></pre>"},{"location":"how-to-guides/streams/kafka-streams/#2-start-the-stream","title":"2. Start the stream","text":"<p>To start the stream, just call the <code>start_stream()</code> method:</p> <pre><code>db.start_stream(stream)\n</code></pre>"},{"location":"how-to-guides/streams/kafka-streams/#3-check-the-status-of-the-stream","title":"3. Check the status of the stream","text":"<p>To check the status of the stream in Memgraph, just run the following command:</p> <pre><code>check = db.get_streams()\n</code></pre>"},{"location":"how-to-guides/streams/kafka-streams/#4-delete-the-stream","title":"4. Delete the stream","text":"<p>You can use the <code>drop_stream()</code> method to delete a stream:</p> <pre><code>check = db.drop_stream(stream)\n</code></pre>"},{"location":"how-to-guides/streams/pulsar-streams/","title":"How to manage Pulsar streams","text":"<p>The stream functionality enables Memgraph to connect to a Kafka, Pulsar or Redpanda cluster and run graph analytics on the data stream.</p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre>"},{"location":"how-to-guides/streams/pulsar-streams/#1-create-a-pulsar-stream-in-memgraph","title":"1. Create a Pulsar stream in Memgraph","text":"<p>To set up the streams, first, create a <code>MemgraphPulsarStream</code> object with all the required arguments:</p> <ul> <li><code>name: str</code> \u27a1 The name of the stream.</li> <li><code>topics: List[str]</code> \u27a1 List of topic names.</li> <li><code>transform: str</code> \u27a1 The transformation procedure for mapping incoming messages   to Cypher queries.</li> <li><code>batch_interval: str = None</code> \u27a1 Maximum wait time in milliseconds for consuming   messages before calling the transform procedure.</li> <li><code>batch_size: str = None</code> \u27a1 Maximum number of messages to wait for before   calling the transform procedure.</li> <li><code>service_url: str = None</code> \u27a1 URL to the running Pulsar cluster.</li> </ul> <p>Now you just have to call the <code>create_stream()</code> method with the newly created <code>MemgraphPulsarStream</code> object:</p> <pre><code>from gqlalchemy import MemgraphPulsarStream\n\nstream = MemgraphPulsarStream(name=\"ratings_stream\", topics=[\"ratings\"], transform=\"movielens.rating\", service_url=\"localhost:6650\")\ndb.create_stream(stream)\n</code></pre>"},{"location":"how-to-guides/streams/pulsar-streams/#2-start-the-stream","title":"2. Start the stream","text":"<p>To start the stream, just call the <code>start_stream()</code> method:</p> <pre><code>db.start_stream(stream)\n</code></pre>"},{"location":"how-to-guides/streams/pulsar-streams/#3-check-the-status-of-the-stream","title":"3. Check the status of the stream","text":"<p>To check the status of the stream in Memgraph, just run the following command:</p> <pre><code>check = db.get_streams()\n</code></pre>"},{"location":"how-to-guides/streams/pulsar-streams/#4-delete-the-stream","title":"4. Delete the stream","text":"<p>You can use the <code>drop_stream()</code> method to delete a stream:</p> <pre><code>check = db.drop_stream(stream)\n</code></pre>"},{"location":"how-to-guides/translators/export-python-graphs/","title":"How to export data from Memgraph into Python graphs","text":"<p>GQLAlchemy holds translators that can export Memgraph graphs into Python graphs (NetworkX, PyG or DGL graphs). These translators create a Python graph instance from the graph stored in Memgraph. </p> <p> </p> <p>In this guide you will learn how to:</p> <ul> <li>Export data from Memgraph into NetworkX graph</li> <li>Export data from Memgraph into PyG graph</li> <li>Export data from Memgraph into DGL graph</li> </ul>"},{"location":"how-to-guides/translators/export-python-graphs/#general-prerequisites","title":"General prerequisites","text":"<p>You need a running Memgraph Platform instance, which includes both the MAGE library and Memgraph Lab, a visual interface. To run the image, open a command-line interpreter and run the following Docker command:</p> <pre><code>docker run -it -p 7687:7687 -p 7444:7444 -p 3000:3000 memgraph/memgraph-platform:latest\n</code></pre> To export data from Memgraph, you first have to create a graph in Memgraph. To do that, expand this section and run the given Python script. <pre><code>from gqlalchemy import Memgraph\n\nmemgraph = Memgraph()\nmemgraph.drop_database()\n\nqueries = []\nqueries.append(f\"CREATE (m:Node {{id: 1, num: 80, edem: 30, lst: [2, 3, 3, 2]}})\")\nqueries.append(f\"CREATE (m:Node {{id: 2, num: 91, edem: 32, lst: [2, 2, 3, 3]}})\")\nqueries.append(\n    f\"CREATE (m:Node {{id: 3, num: 100, edem: 34, lst: [3, 2, 2, 3, 4, 4]}})\"\n)\nqueries.append(f\"CREATE (m:Node {{id: 4, num: 12, edem: 34, lst: [2, 2, 2, 3, 5, 5]}})\")\nqueries.append(\n    f\"MATCH (n:Node {{id: 1}}), (m:Node {{id: 2}}) CREATE (n)-[r:CONNECTION {{edge_id: 1, edge_num: 99, edge_edem: 12, edge_lst: [0, 1, 0, 1, 0, 1, 0, 1]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 2}}), (m:Node {{id: 3}}) CREATE (n)-[r:CONNECTION {{edge_id: 2, edge_num: 99, edge_edem: 12, edge_lst: [0, 1, 0, 1]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 3}}), (m:Node {{id: 4}}) CREATE (n)-[r:CONNECTION {{edge_id: 3, edge_num: 99, edge_edem: 12, edge_lst: [1, 0, 1, 0, 1, 0, 1]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 4}}), (m:Node {{id: 1}}) CREATE (n)-[r:CONNECTION {{edge_id: 4, edge_num: 99, edge_edem: 12, edge_lst: [0, 1, 0, 1]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 1}}), (m:Node {{id: 3}}) CREATE (n)-[r:CONNECTION {{edge_id: 5, edge_num: 99, edge_edem: 12, edge_lst: [0, 1, 0, 1]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 2}}), (m:Node {{id: 4}}) CREATE (n)-[r:CONNECTION {{edge_id: 6, edge_num: 99, edge_edem: 12, edge_lst: [0, 1, 0, 1, 0, 0]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 4}}), (m:Node {{id: 2}}) CREATE (n)-[r:CONNECTION {{edge_id: 7, edge_num: 99, edge_edem: 12, edge_lst: [1, 1, 0, 0, 1, 1, 0, 1]}}]-&gt;(m)\"\n)\nqueries.append(\n    f\"MATCH (n:Node {{id: 3}}), (m:Node {{id: 1}}) CREATE (n)-[r:CONNECTION {{edge_id: 8, edge_num: 99, edge_edem: 12, edge_lst: [0, 1, 0, 1]}}]-&gt;(m)\"\n)\n\nfor query in queries:\n    memgraph.execute(query)\n</code></pre>"},{"location":"how-to-guides/translators/export-python-graphs/#export-data-from-memgraph-into-networkx-graph","title":"Export data from Memgraph into NetworkX graph","text":""},{"location":"how-to-guides/translators/export-python-graphs/#prerequisites","title":"Prerequisites","text":"<p>Except for the general prerequisites, you also need to install NetworkX Python library.</p>"},{"location":"how-to-guides/translators/export-python-graphs/#create-and-run-a-python-script","title":"Create and run a Python script","text":"<p>Create a new Python script <code>memgraph-to-nx.py</code>, in the code editor of your choice, with the following code:</p> <pre><code>from gqlalchemy.transformations.translators.nx_translator import NxTranslator\n\ntranslator = NxTranslator()\ngraph = translator.get_instance()\n\nprint(graph.number_of_edges())\nprint(graph.number_of_nodes())\n</code></pre> <p>To run it, open a command-line interpreter and run the following command:</p> <pre><code>python3 memgraph-to-nx.py\n</code></pre> <p>You will get the following output: <pre><code>8\n4\n</code></pre></p> <p>This means that the NetworkX graph has the correct number of nodes and edges. You can explore it more to see if it has all the required features.</p>"},{"location":"how-to-guides/translators/export-python-graphs/#export-data-from-memgraph-into-pyg-graph","title":"Export data from Memgraph into PyG graph","text":""},{"location":"how-to-guides/translators/export-python-graphs/#prerequisites_1","title":"Prerequisites","text":"<p>Except for the general prerequisites, you also need to install Pytorch Geometric Python library.</p>"},{"location":"how-to-guides/translators/export-python-graphs/#create-and-run-a-python-script_1","title":"Create and run a Python script","text":"<p>Create a new Python script <code>memgraph-to-pyg.py</code>, in the code editor of your choice, with the following code:</p> <pre><code>from gqlalchemy.transformations.translators.pyg_translator import PyGTranslator\n\ntranslator = PyGTranslator()\ngraph = translator.get_instance()\n\nprint(len(graph.edge_types))\nprint(len(graph.node_types))\n\nsource_node_label, edge_type, dest_node_label = (\"Node\", \"CONNECTION\", \"Node\")\ncan_etype = (source_node_label, edge_type, dest_node_label)\nprint(graph[source_node_label].num_nodes)\nprint(graph[can_etype].num_edges)\n</code></pre> <p>To run it, open a command-line interpreter and run the following command:</p> <pre><code>python3 memgraph-to-pyg.py\n</code></pre> <p>You will get the following output: <pre><code>1\n1\n4\n8\n</code></pre></p> <p>This means that the PyG graph has the correct number of node and edge types, as well as correct total number of nodes and edges. You can explore it more to see if it has all the required features.</p>"},{"location":"how-to-guides/translators/export-python-graphs/#export-data-from-memgraph-into-dgl-graph","title":"Export data from Memgraph into DGL graph","text":""},{"location":"how-to-guides/translators/export-python-graphs/#prerequisites_2","title":"Prerequisites","text":"<p>Except for the general prerequisites, you also need to install Deep Graph Library.</p>"},{"location":"how-to-guides/translators/export-python-graphs/#create-and-run-a-python-script_2","title":"Create and run a Python script","text":"<p>Create a new Python script <code>memgraph-to-dgl.py</code>, in the code editor of your choice, with the following code:</p> <pre><code>from gqlalchemy.transformations.translators.dgl_translator import DGLTranslator\n\ntranslator = DGLTranslator()\ngraph = translator.get_instance()\n\nprint(len(graph.canonical_etypes))\nprint(len(graph.ntypes))\n\nsource_node_label, edge_type, dest_node_label = (\"Node\", \"CONNECTION\", \"Node\")\ncan_etype = (source_node_label, edge_type, dest_node_label)\nprint(graph[can_etype].number_of_nodes())\nprint(graph[can_etype].number_of_edges())\nprint(len(graph.nodes[source_node_label].data.keys()))\nprint(len(graph.edges[(source_node_label, edge_type, dest_node_label)].data.keys()))\n</code></pre> <p>To run it, open a command-line interpreter and run the following command:</p> <pre><code>python3 memgraph-to-dgl.py\n</code></pre> <p>You will get the following output: <pre><code>1\n1\n4\n8\n3\n3\n</code></pre></p> <p>This means that the DGL graph has the correct number of node and edge types, total number of nodes and edges, as well as node and edge features. You can explore it more to see if it has all the required features.</p>"},{"location":"how-to-guides/translators/export-python-graphs/#learn-more","title":"Learn more","text":"<p>Head over to the Under the hood section to read about implementation details. If you want to learn more about using NetworkX with Memgraph with interesting resources and courses, head over to the Memgraph for NetworkX developers website. If you have any questions or want to connect with the Memgraph community, join our Discord server.</p>"},{"location":"how-to-guides/translators/import-python-graphs/","title":"How to import Python graphs into Memgraph","text":"<p>GQLAlchemy holds translators that can import Python graphs (NetworkX, PyG or DGL graphs) into Memgraph. These translators take the Python graph object and translate it to the appropriate Cypher queries. The Cypher queries are then executed to create a graph inside Memgraph. </p> <p> </p> <p>In this guide you will learn how to:</p> <ul> <li>Import NetworkX graph into Memgraph</li> <li>Import PyG graph into Memgraph</li> <li>Import DGL graph into Memgraph</li> </ul>"},{"location":"how-to-guides/translators/import-python-graphs/#general-prerequisites","title":"General prerequisites","text":"<p>You need a running Memgraph Platform instance, which includes both the MAGE library and Memgraph Lab, a visual interface. To run the image, open a command-line interpreter and run the following Docker command:</p> <pre><code>docker run -it -p 7687:7687 -p 7444:7444 -p 3000:3000 memgraph/memgraph-platform:latest\n</code></pre>"},{"location":"how-to-guides/translators/import-python-graphs/#import-networkx-graph-into-memgraph","title":"Import NetworkX graph into Memgraph","text":""},{"location":"how-to-guides/translators/import-python-graphs/#prerequisites","title":"Prerequisites","text":"<p>Except for the general prerequisites, you also need to install NetworkX Python library.</p>"},{"location":"how-to-guides/translators/import-python-graphs/#create-and-run-a-python-script","title":"Create and run a Python script","text":"<p>Create a new Python script <code>networkx-graph.py</code> in the code editor of your choice, with the following code:</p> <pre><code>import networkx as nx\nfrom gqlalchemy import Memgraph\nfrom gqlalchemy.transformations.translators.nx_translator import NxTranslator\n\nmemgraph = Memgraph()\nmemgraph.drop_database()\n\ngraph = nx.Graph()\ngraph.add_nodes_from([(1, {\"labels\": \"First\"}), (2, {\"name\": \"Kata\"}), 3])\ngraph.add_edges_from([(1, 2, {\"type\": \"EDGE_TYPE\", \"date\": \"today\"}), (1, 3)])\n\ntranslator = NxTranslator()\n\nfor query in list(translator.to_cypher_queries(graph)):\n    memgraph.execute(query)\n</code></pre> <p>First, connect to a running Memgraph instance. Next, drop the database to be sure that it's empty. After that, create a simple NetworkX graph and add nodes and edges to it. In the end, call <code>to_cypher_queries</code> procedure on <code>NxTranslator</code> instance to transform the NetworkX graph to Cypher queries which will be executed in Memgraph.</p> <p>To run it, open a command-line interpreter and run the following command:</p> <pre><code>python3 networkx-graph.py\n</code></pre>"},{"location":"how-to-guides/translators/import-python-graphs/#explore-the-graph","title":"Explore the graph","text":"<p>Connect to Memgraph via Memgraph Lab which is running at <code>localhost:3000</code>. Open the Query Execution section and write the following query:</p> <pre><code>MATCH (n)-[r]-&gt;(m)\nRETURN n, r, m;\n</code></pre> <p>Click Run Query button to see the results.</p> <p></p> <p>The NetworkX node identification number maps to the <code>id</code> node property in Memgraph. The <code>labels</code> key is reserved for the node label in Memgraph, while the edge <code>type</code> key is reserved for the relationship type in Memgraph. If no <code>type</code> is defined, then the relationship will be of type <code>TO</code> in Memgraph. You can notice that the node with the property <code>name</code> Kata and property <code>id</code> 2 doesn't have a label. This happened because the node property key <code>labels</code> was not defined. </p>"},{"location":"how-to-guides/translators/import-python-graphs/#import-pyg-graph-into-memgraph","title":"Import PyG graph into Memgraph","text":""},{"location":"how-to-guides/translators/import-python-graphs/#prerequisites_1","title":"Prerequisites","text":"<p>Except for the general prerequisites, you also need to install Pytorch Geometric Python library.</p>"},{"location":"how-to-guides/translators/import-python-graphs/#create-and-run-a-python-script_1","title":"Create and run a Python script","text":"<p>Create a new Python script <code>pyg-graph.py</code> in the code editor of your choice, with the following code:</p> <pre><code>import torch\nfrom gqlalchemy import Memgraph\nfrom gqlalchemy.transformations.translators.pyg_translator import PyGTranslator\nfrom torch_geometric.data import HeteroData\n\n\nmemgraph = Memgraph()\nmemgraph.drop_database()\n\ngraph = HeteroData()\n\ngraph[(\"user\", \"PLUS\", \"movie\")].edge_index = torch.tensor(\n    [[0, 0, 1], [0, 1, 0]], dtype=torch.int32\n)\ngraph[(\"user\", \"MINUS\", \"movie\")].edge_index = torch.tensor(\n    [[2], [1]], dtype=torch.int32\n)\n# Set node features\ngraph[\"user\"].prop1 = torch.randn(size=(3, 1))\ngraph[\"user\"].prop2 = torch.randn(size=(3, 1))\ngraph[\"movie\"].prop1 = torch.randn(size=(2, 1))\ngraph[\"movie\"].prop2 = torch.randn(size=(2, 1))\ngraph[\"movie\"].prop3 = torch.randn(size=(2, 1))\ngraph[\"movie\"].x = torch.randn(size=(2, 1))\ngraph[\"movie\"].y = torch.randn(size=(2, 1))\n# Set edge features\ngraph[(\"user\", \"PLUS\", \"movie\")].edge_prop1 = torch.randn(size=(3, 1))\ngraph[(\"user\", \"PLUS\", \"movie\")].edge_prop2 = torch.randn(size=(3, 1))\ngraph[(\"user\", \"MINUS\", \"movie\")].edge_prop1 = torch.randn(size=(1, 1))\n\ntranslator = PyGTranslator()\n\nfor query in list(translator.to_cypher_queries(graph)):\n    memgraph.execute(query)\n</code></pre> <p>First, connect to a running Memgraph instance. Next, drop the database to be sure that it's empty. After that, create a simple PyG heterogeneous graph and add nodes and edges along with their features to it. The graph consist of three <code>user</code> nodes and two <code>movie</code> nodes, as well as two types of edges - <code>PLUS</code> and <code>MINUS</code>. The <code>edge_index</code> of a graph determines which nodes are connected by which edges. Provide a tensor, that is a multi-dimensional matrix, as a value of <code>edge_index</code>, to define edges. Each tensor element maps to one graph node - first row of matrix maps to <code>user</code>, while the second one to the <code>movie</code> nodes. Hence, <code>user</code> node 0 is connected to the <code>movie</code> node 0, <code>user</code> node 0 is connected to the <code>movie</code> node 1, and <code>user</code> node 1 is connected to the <code>movie</code> node 0, with edge of type <code>PLUS</code>. These integers are mapping to the values of the <code>pyg_id</code> nodes' property in Memgraph. Similarly, the edge of type <code>MINUS</code> is created between <code>user</code> node 2 and <code>movie</code> node 1. In the end, call <code>to_cypher_queries</code> procedure on <code>PyGTranslator</code> instance to transform the PysG graph to Cypher queries which will be executed in Memgraph.</p> <p>To run it, open a command-line interpreter and run the following command:</p> <pre><code>python3 pyg-graph.py\n</code></pre>"},{"location":"how-to-guides/translators/import-python-graphs/#explore-the-graph_1","title":"Explore the graph","text":"<p>Connect to Memgraph via Memgraph Lab which is running at <code>localhost:3000</code>. Open the Query Execution section and write the following query:</p> <pre><code>MATCH (n)-[r]-&gt;(m)\nRETURN n, r, m;\n</code></pre> <p>Click Run Query button to see the results.</p> <p></p> <p>You can notice that we have nodes labeled with <code>user</code> and <code>movie</code> and relationships of type <code>PLUS</code> and <code>MINUS</code>. Besides that, nodes and relationships have randomized array properties as well as <code>pyg_id</code> property.</p>"},{"location":"how-to-guides/translators/import-python-graphs/#import-dgl-graph-into-memgraph","title":"Import DGL graph into Memgraph","text":""},{"location":"how-to-guides/translators/import-python-graphs/#prerequisites_2","title":"Prerequisites","text":"<p>Except for the general prerequisites, you also need to install Deep Graph Library.</p>"},{"location":"how-to-guides/translators/import-python-graphs/#create-and-run-a-python-script_2","title":"Create and run a Python script","text":"<p>Create a new Python script <code>dgl-graph.py</code> in the code editor of your choice, with the following code:</p> <pre><code>import numpy as np\nimport dgl\nimport torch\nfrom gqlalchemy import Memgraph\nfrom gqlalchemy.transformations.translators.dgl_translator import DGLTranslator\n\nmemgraph = Memgraph()\nmemgraph.drop_database()\n\ngraph = dgl.heterograph(\n    {\n        (\"user\", \"PLUS\", \"movie\"): (np.array([0, 0, 1]), np.array([0, 1, 0])),\n        (\"user\", \"MINUS\", \"movie\"): (np.array([2]), np.array([1])),\n    }\n)\n# Set node features\ngraph.nodes[\"user\"].data[\"prop1\"] = torch.randn(size=(3, 1))\ngraph.nodes[\"user\"].data[\"prop2\"] = torch.randn(size=(3, 1))\ngraph.nodes[\"movie\"].data[\"prop1\"] = torch.randn(size=(2, 1))\ngraph.nodes[\"movie\"].data[\"prop2\"] = torch.randn(size=(2, 1))\ngraph.nodes[\"movie\"].data[\"prop3\"] = torch.randn(size=(2, 1))\n# Set edge features\ngraph.edges[(\"user\", \"PLUS\", \"movie\")].data[\"edge_prop1\"] = torch.randn(size=(3, 1))\ngraph.edges[(\"user\", \"PLUS\", \"movie\")].data[\"edge_prop2\"] = torch.randn(size=(3, 1))\ngraph.edges[(\"user\", \"MINUS\", \"movie\")].data[\"edge_prop1\"] = torch.randn(size=(1, 1))\n\ntranslator = DGLTranslator()\n\nfor query in list(translator.to_cypher_queries(graph)):\n    memgraph.execute(query)\n</code></pre> <p>First, connect to a running Memgraph instance. Next, drop the database to be sure that it's is empty. After that, create a simple DGL heterogeneous graph and add nodes and edges along with their features to it. The graph consist of three <code>user</code> nodes and two <code>movie</code> nodes, as well as two types of edges - <code>PLUS</code> and <code>MINUS</code>. To define nodes and edge between them we are providing appropriate NumPy arrays. Hence, <code>user</code> node 0 is connected to the <code>movie</code> node 0, <code>user</code> node 0 is connected to the <code>movie</code> node 1, and <code>user</code> node 1 is connected to the <code>movie</code> node 0, with edge of type <code>PLUS</code>. These integers are mapping to the values of the <code>dgl_id</code> properties in Memgraph. Similarly, the edge of type <code>MINUS</code> is created between <code>user</code> node 2 and <code>movie</code> node 1. In the end, call <code>to_cypher_queries</code> procedure on <code>DGLTranslator</code> instance to transform the DGL graph to Cypher queries which will be executed in Memgraph.</p> <p>To run it, open a command-line interpreter and run the following command:</p> <pre><code>python3 dgl-graph.py\n</code></pre>"},{"location":"how-to-guides/translators/import-python-graphs/#3-explore-the-graph","title":"3. Explore the graph","text":"<p>Connect to Memgraph via Memgraph Lab which is running at <code>localhost:3000</code>. Open the Query Execution section and write the following query:</p> <pre><code>MATCH (n)-[r]-&gt;(m)\nRETURN n, r, m;\n</code></pre> <p>Click Run Query button to see the results.</p> <p></p> <p>You can notice that we have nodes labeled with <code>user</code> and <code>movie</code> and relationships of type <code>PLUS</code> and <code>MINUS</code>. Besides that, nodes and relationships have randomized array properties ad well as <code>dgl_id</code> property.</p>"},{"location":"how-to-guides/translators/import-python-graphs/#learn-more","title":"Learn more","text":"<p>Head over to the Under the hood section to read about implementation details. If you want to learn more about using NetworkX with Memgraph with interesting resources and courses, head over to the Memgraph for NetworkX developers website. If you have any questions or want to connect with the Memgraph community, join our Discord server.</p>"},{"location":"how-to-guides/triggers/triggers/","title":"How to manage database triggers","text":"<p>Because Memgraph supports database triggers on <code>CREATE</code>, <code>UPDATE</code> and <code>DELETE</code> operations, GQLAlchemy also implements a simple interface for maintaining these triggers. </p> <p>Info</p> <p>You can also use this feature with Neo4j:</p> <pre><code>db = Neo4j(host=\"localhost\", port=\"7687\", username=\"neo4j\", password=\"test\")\n</code></pre>"},{"location":"how-to-guides/triggers/triggers/#1-create-the-trigger","title":"1. Create the trigger","text":"<p>To set up the trigger, first, create a <code>MemgraphTrigger</code> object with all the required arguments:</p> <ul> <li><code>name: str</code> \u27a1 The name of the trigger.</li> <li><code>event_type: TriggerEventType</code> \u27a1 The type of event that will trigger the   execution. The options are: <code>TriggerEventType.CREATE</code>,   <code>TriggerEventType.UPDATE</code> and <code>TriggerEventType.DELETE</code>.</li> <li><code>event_object: TriggerEventObject</code> \u27a1 The objects that are affected with the   <code>event_type</code>. The options are: <code>`TriggerEventObject.ALL,</code>TriggerEventObject.NODE<code>and</code>TriggerEventObject.RELATIONSHIP`.</li> <li><code>execution_phase: TriggerExecutionPhase</code> \u27a1 The phase when the trigger should   be executed in regard to the transaction commit. The options are: <code>BEFORE</code> and   <code>AFTER</code>.</li> <li><code>statement: str</code> \u27a1 The Cypher query that should be executed when the trigger   fires.</li> </ul> <p>Now, let's create a trigger in GQLAlchemy:</p> <pre><code>from gqlalchemy import Memgraph, MemgraphTrigger\nfrom gqlalchemy.models import (\n    TriggerEventType,\n    TriggerEventObject,\n    TriggerExecutionPhase,\n)\n\ndb = Memgraph()\n\ntrigger = MemgraphTrigger(\n    name=\"ratings_trigger\",\n    event_type=TriggerEventType.CREATE,\n    event_object=TriggerEventObject.NODE,\n    execution_phase=TriggerExecutionPhase.AFTER,\n    statement=\"UNWIND createdVertices AS node SET node.created_at = LocalDateTime()\",\n)\n\ndb.create_trigger(trigger)\n</code></pre> <p>The trigger names <code>ratings_trigger</code> will be executed every time a node is created in the database. After the transaction that created the node in question finishes, the Cypher query <code>statement</code> will execute, and in this case, it will set the property <code>created_at</code> of the newly created node to the current date and time. </p>"},{"location":"how-to-guides/triggers/triggers/#2-check-the-status-of-a-trigger","title":"2. Check the status of a trigger","text":"<p>You can return all of the triggers from the database with the <code>get_Triggers()</code> method:</p> <pre><code>triggers = db.get_triggers()\nprint(triggers)\n</code></pre>"},{"location":"how-to-guides/triggers/triggers/#3-delete-the-trigger","title":"3. Delete the trigger","text":"<p>You can use the <code>drop_trigger()</code> method to delete a trigger:</p> <pre><code>db.drop_trigger(trigger)\n</code></pre>"},{"location":"reference/gqlalchemy/connection/","title":"connection","text":""},{"location":"reference/gqlalchemy/connection/#connection-objects","title":"Connection Objects","text":"<pre><code>class Connection(ABC)\n</code></pre>"},{"location":"reference/gqlalchemy/connection/#execute","title":"execute","text":"<pre><code>@abstractmethod\ndef execute(query: str, parameters: Dict[str, Any] = {}) -&gt; None\n</code></pre> <p>Executes Cypher query without returning any results.</p>"},{"location":"reference/gqlalchemy/connection/#execute_and_fetch","title":"execute_and_fetch","text":"<pre><code>@abstractmethod\ndef execute_and_fetch(\n        query: str,\n        parameters: Dict[str, Any] = {}) -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Executes Cypher query and returns iterator of results.</p>"},{"location":"reference/gqlalchemy/connection/#is_active","title":"is_active","text":"<pre><code>@abstractmethod\ndef is_active() -&gt; bool\n</code></pre> <p>Returns True if connection is active and can be used.</p>"},{"location":"reference/gqlalchemy/connection/#memgraphconnection-objects","title":"MemgraphConnection Objects","text":"<pre><code>class MemgraphConnection(Connection)\n</code></pre>"},{"location":"reference/gqlalchemy/connection/#execute_1","title":"execute","text":"<pre><code>@database_error_handler\ndef execute(query: str, parameters: Dict[str, Any] = {}) -&gt; None\n</code></pre> <p>Executes Cypher query without returning any results.</p>"},{"location":"reference/gqlalchemy/connection/#execute_and_fetch_1","title":"execute_and_fetch","text":"<pre><code>@database_error_handler\ndef execute_and_fetch(\n        query: str,\n        parameters: Dict[str, Any] = {}) -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Executes Cypher query and returns iterator of results.</p>"},{"location":"reference/gqlalchemy/connection/#is_active_1","title":"is_active","text":"<pre><code>def is_active() -&gt; bool\n</code></pre> <p>Returns True if connection is active and can be used.</p>"},{"location":"reference/gqlalchemy/connection/#neo4jconnection-objects","title":"Neo4jConnection Objects","text":"<pre><code>class Neo4jConnection(Connection)\n</code></pre>"},{"location":"reference/gqlalchemy/connection/#execute_2","title":"execute","text":"<pre><code>def execute(query: str, parameters: Dict[str, Any] = {}) -&gt; None\n</code></pre> <p>Executes Cypher query without returning any results.</p>"},{"location":"reference/gqlalchemy/connection/#execute_and_fetch_2","title":"execute_and_fetch","text":"<pre><code>def execute_and_fetch(\n        query: str,\n        parameters: Dict[str, Any] = {}) -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Executes Cypher query and returns iterator of results.</p>"},{"location":"reference/gqlalchemy/connection/#is_active_2","title":"is_active","text":"<pre><code>def is_active() -&gt; bool\n</code></pre> <p>Returns True if connection is active and can be used.</p>"},{"location":"reference/gqlalchemy/disk_storage/","title":"disk_storage","text":""},{"location":"reference/gqlalchemy/disk_storage/#ondiskpropertydatabase-objects","title":"OnDiskPropertyDatabase Objects","text":"<pre><code>class OnDiskPropertyDatabase(ABC)\n</code></pre> <p>An abstract class for implementing on-disk storage features with specific databases.</p>"},{"location":"reference/gqlalchemy/disk_storage/#save_node_property","title":"save_node_property","text":"<pre><code>def save_node_property(node_id: int, property_name: str,\n                       property_value: str) -&gt; None\n</code></pre> <p>Saves a node property to an on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#load_node_property","title":"load_node_property","text":"<pre><code>def load_node_property(node_id: int, property_name: str,\n                       property_value: str) -&gt; Optional[str]\n</code></pre> <p>Loads a node property from an on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#delete_node_property","title":"delete_node_property","text":"<pre><code>def delete_node_property(node_id: int, property_name: str,\n                         property_value: str) -&gt; None\n</code></pre> <p>Deletes a node property from an on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#save_relationship_property","title":"save_relationship_property","text":"<pre><code>def save_relationship_property(relationship_id: int, property_name: str,\n                               property_value: str) -&gt; None\n</code></pre> <p>Saves a relationship property to an on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#load_relationship_property","title":"load_relationship_property","text":"<pre><code>def load_relationship_property(relationship_id: int, property_name: str,\n                               property_value: str) -&gt; Optional[str]\n</code></pre> <p>Loads a relationship property from an on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#delete_relationship_property","title":"delete_relationship_property","text":"<pre><code>def delete_relationship_property(node_id: int, property_name: str,\n                                 property_value: str) -&gt; None\n</code></pre> <p>Deletes a node property from an on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#drop_database","title":"drop_database","text":"<pre><code>def drop_database() -&gt; None\n</code></pre> <p>Deletes all entries from the on disk database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#sqlitepropertydatabase-objects","title":"SQLitePropertyDatabase Objects","text":"<pre><code>class SQLitePropertyDatabase(OnDiskPropertyDatabase)\n</code></pre>"},{"location":"reference/gqlalchemy/disk_storage/#execute_query","title":"execute_query","text":"<pre><code>def execute_query(query: str) -&gt; List[str]\n</code></pre> <p>Executes an SQL query on the on disk property database.</p> <p>Arguments:</p> <ul> <li><code>query</code> - A string representing an SQL query.</li> </ul> <p>Returns:</p> <p>A list of strings representing the results of the query.</p>"},{"location":"reference/gqlalchemy/disk_storage/#drop_database_1","title":"drop_database","text":"<pre><code>def drop_database() -&gt; None\n</code></pre> <p>Deletes all properties in the database.</p>"},{"location":"reference/gqlalchemy/disk_storage/#save_node_property_1","title":"save_node_property","text":"<pre><code>def save_node_property(node_id: int, property_name: str,\n                       property_value: str) -&gt; None\n</code></pre> <p>Saves a node property to an on disk database.</p> <p>Arguments:</p> <ul> <li><code>node_id</code> - An integer representing the internal id of the node.</li> <li><code>property_name</code> - A string representing the name of the property.</li> <li><code>property_value</code> - A string representing the value of the property.</li> </ul>"},{"location":"reference/gqlalchemy/disk_storage/#load_node_property_1","title":"load_node_property","text":"<pre><code>def load_node_property(node_id: int, property_name: str) -&gt; Optional[str]\n</code></pre> <p>Loads a node property from an on disk database.</p> <p>Arguments:</p> <ul> <li><code>node_id</code> - An integer representing the internal id of the node.</li> <li><code>property_name</code> - A string representing the name of the property.</li> </ul> <p>Returns:</p> <p>An optional string representing the property value.</p>"},{"location":"reference/gqlalchemy/disk_storage/#delete_node_property_1","title":"delete_node_property","text":"<pre><code>def delete_node_property(node_id: int, property_name: str) -&gt; None\n</code></pre> <p>Deletes a node property from an on disk database.</p> <p>Arguments:</p> <ul> <li><code>node_id</code> - An integer representing the internal id of the node.</li> <li><code>property_name</code> - A string representing the name of the property.</li> </ul>"},{"location":"reference/gqlalchemy/disk_storage/#save_relationship_property_1","title":"save_relationship_property","text":"<pre><code>def save_relationship_property(relationship_id: int, property_name: str,\n                               property_value: str) -&gt; None\n</code></pre> <p>Saves a relationship property to an on disk database.</p> <p>Arguments:</p> <ul> <li><code>relationship_id</code> - An integer representing the internal id of the relationship.</li> <li><code>property_name</code> - A string representing the name of the property.</li> <li><code>property_value</code> - A string representing the value of the property.</li> </ul>"},{"location":"reference/gqlalchemy/disk_storage/#load_relationship_property_1","title":"load_relationship_property","text":"<pre><code>def load_relationship_property(relationship_id: int,\n                               property_name: str) -&gt; Optional[str]\n</code></pre> <p>Loads a relationship property from an on disk database.</p> <p>Arguments:</p> <ul> <li><code>relationship_id</code> - An integer representing the internal id of the relationship.</li> <li><code>property_name</code> - A string representing the name of the property.</li> </ul> <p>Returns:</p> <p>An optional string representing the property value.</p>"},{"location":"reference/gqlalchemy/disk_storage/#delete_relationship_property_1","title":"delete_relationship_property","text":"<pre><code>def delete_relationship_property(relationship_id: int,\n                                 property_name: str) -&gt; None\n</code></pre> <p>Deletes a node property from an on disk database.</p> <p>Arguments:</p> <ul> <li><code>relationship_id</code> - An integer representing the internal id of the relationship.</li> <li><code>property_name</code> - A string representing the name of the property.</li> </ul>"},{"location":"reference/gqlalchemy/exceptions/","title":"exceptions","text":""},{"location":"reference/gqlalchemy/exceptions/#connection_handler","title":"connection_handler","text":"<pre><code>def connection_handler(func,\n                       delay: float = 0.01,\n                       timeout: float = 5.0,\n                       backoff: int = 2)\n</code></pre> <p>Wrapper for a wait on the connection.</p> <p>Arguments:</p> <ul> <li><code>func</code> - A function that tries to create the connection</li> <li><code>delay</code> - A float that defines how long to wait between retries.</li> <li><code>timeout</code> - A float that defines how long to wait for the port.</li> <li><code>backoff</code> - An integer used for multiplying the delay.</li> </ul> <p>Raises:</p> <ul> <li><code>GQLAlchemyWaitForConnectionError</code> - Raises an error   after the timeout period has passed.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/","title":"instance_runner","text":""},{"location":"reference/gqlalchemy/instance_runner/#wait_for_port","title":"wait_for_port","text":"<pre><code>def wait_for_port(host: str = LOOPBACK_ADDRESS,\n                  port: int = MEMGRAPH_DEFAULT_PORT,\n                  delay: float = 0.01,\n                  timeout: float = 5.0,\n                  backoff: int = 2) -&gt; None\n</code></pre> <p>Wait for a TCP port to become available.</p> <p>Arguments:</p> <ul> <li><code>host</code> - A string representing the IP address that is being checked.</li> <li><code>port</code> - A string representing the port that is being checked.</li> <li><code>delay</code> - A float that defines how long to wait between retries.</li> <li><code>timeout</code> - A float that defines how long to wait for the port.</li> <li><code>backoff</code> - An integer used for multiplying the delay.</li> </ul> <p>Raises:</p> <ul> <li><code>TimeoutError</code> - Raises an error when the host and port are not accepting   connections after the timeout period has passed.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/#wait_for_docker_container","title":"wait_for_docker_container","text":"<pre><code>def wait_for_docker_container(container: \"docker.Container\",\n                              delay: float = 0.01,\n                              timeout: float = 5.0,\n                              backoff: int = 2) -&gt; None\n</code></pre> <p>Wait for a Docker container to enter the status <code>running</code>.</p> <p>Arguments:</p> <ul> <li><code>container</code> - The Docker container to wait for.</li> <li><code>delay</code> - A float that defines how long to wait between retries.</li> <li><code>timeout</code> - A float that defines how long to wait for the status.</li> <li><code>backoff</code> - An integer used for multiplying the delay.</li> </ul> <p>Raises:</p> <ul> <li><code>TimeoutError</code> - Raises an error when the container isn't running after the   timeout period has passed.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/#memgraphinstance-objects","title":"MemgraphInstance Objects","text":"<pre><code>class MemgraphInstance(ABC)\n</code></pre>"},{"location":"reference/gqlalchemy/instance_runner/#start_and_connect","title":"start_and_connect","text":"<pre><code>def start_and_connect(restart: bool = False) -&gt; \"Memgraph\"\n</code></pre> <p>Start the Memgraph instance and return the connection object.</p> <p>Attributes:</p> <ul> <li><code>restart</code> - A bool indicating if the instance should be   restarted if it's already running.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/#start","title":"start","text":"<pre><code>def start(restart: bool = False) -&gt; None\n</code></pre> <p>Start the Memgraph instance.</p> <p>Attributes:</p> <ul> <li><code>restart</code> - A bool indicating if the instance should be   restarted if it's already running.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/#stop","title":"stop","text":"<pre><code>def stop() -&gt; Any\n</code></pre> <p>Stop the Memgraph instance.</p>"},{"location":"reference/gqlalchemy/instance_runner/#memgraphinstancebinary-objects","title":"MemgraphInstanceBinary Objects","text":"<pre><code>class MemgraphInstanceBinary(MemgraphInstance)\n</code></pre> <p>A class for managing Memgraph instances started from binary files on Unix systems.</p> <p>Attributes:</p> <ul> <li><code>binary_path</code> - A string representing the path to a Memgraph binary   file.</li> <li><code>user</code> - A string representing the user that should start the Memgraph   process.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/#is_running","title":"is_running","text":"<pre><code>def is_running() -&gt; bool\n</code></pre> <p>Check if the Memgraph instance is still running.</p>"},{"location":"reference/gqlalchemy/instance_runner/#memgraphinstancedocker-objects","title":"MemgraphInstanceDocker Objects","text":"<pre><code>class MemgraphInstanceDocker(MemgraphInstance)\n</code></pre> <p>A class for managing Memgraph instances started in Docker containers.</p> <p>Attributes:</p> <ul> <li><code>docker_image</code> - An enum representing the Docker image. Values:   <code>DockerImage.MEMGRAPH</code> and <code>DockerImage.MAGE</code>.</li> <li><code>docker_image_tag</code> - A string representing the tag of the Docker image.</li> </ul>"},{"location":"reference/gqlalchemy/instance_runner/#is_running_1","title":"is_running","text":"<pre><code>def is_running() -&gt; bool\n</code></pre> <p>Check if the Memgraph instance is still running.</p>"},{"location":"reference/gqlalchemy/models/","title":"models","text":""},{"location":"reference/gqlalchemy/models/#triggereventtype-objects","title":"TriggerEventType Objects","text":"<pre><code>class TriggerEventType()\n</code></pre> <p>An enum representing types of trigger events.</p>"},{"location":"reference/gqlalchemy/models/#triggereventobject-objects","title":"TriggerEventObject Objects","text":"<pre><code>class TriggerEventObject()\n</code></pre> <p>An enum representing types of trigger objects.</p> <p>NODE -&gt; <code>()</code> RELATIONSHIP -&gt; <code>--&amp;gt;</code></p>"},{"location":"reference/gqlalchemy/models/#triggerexecutionphase-objects","title":"TriggerExecutionPhase Objects","text":"<pre><code>class TriggerExecutionPhase()\n</code></pre> <p>An enum representing types of trigger objects.</p> <p>Enum:     BEFORE     AFTER</p>"},{"location":"reference/gqlalchemy/models/#memgraphkafkastream-objects","title":"MemgraphKafkaStream Objects","text":"<pre><code>class MemgraphKafkaStream(MemgraphStream)\n</code></pre> <p>A class for creating and managing Kafka streams in Memgraph.</p> <p>Arguments:</p> <ul> <li><code>name</code> - A string representing the stream name.</li> <li><code>topics</code> - A list of strings representing the stream topics.</li> <li><code>transform</code> - A string representing the name of the transformation procedure.</li> <li><code>consumer_group</code> - A string representing the consumer group.</li> <li><code>name</code> - A string representing the batch interval.</li> <li><code>name</code> - A string representing the batch size.</li> <li><code>name</code> - A string or list of strings representing bootstrap server addresses.</li> </ul>"},{"location":"reference/gqlalchemy/models/#to_cypher","title":"to_cypher","text":"<pre><code>def to_cypher() -&gt; str\n</code></pre> <p>Converts Kafka stream to a Cypher clause.</p>"},{"location":"reference/gqlalchemy/models/#memgraphpulsarstream-objects","title":"MemgraphPulsarStream Objects","text":"<pre><code>class MemgraphPulsarStream(MemgraphStream)\n</code></pre> <p>A class for creating and managing Pulsar streams in Memgraph.</p> <p>Arguments:</p> <ul> <li><code>name</code> - A string representing the stream name.</li> <li><code>topics</code> - A list of strings representing the stream topics.</li> <li><code>transform</code> - A string representing the name of the transformation procedure.</li> <li><code>consumer_group</code> - A string representing the consumer group.</li> <li><code>name</code> - A string representing the batch interval.</li> <li><code>name</code> - A string representing the batch size.</li> <li><code>name</code> - A string or list of strings representing bootstrap server addresses.</li> </ul>"},{"location":"reference/gqlalchemy/models/#to_cypher_1","title":"to_cypher","text":"<pre><code>def to_cypher() -&gt; str\n</code></pre> <p>Converts Pulsar stream to a Cypher clause.</p>"},{"location":"reference/gqlalchemy/models/#memgraphtrigger-objects","title":"MemgraphTrigger Objects","text":"<pre><code>@dataclass(frozen=True, eq=True)\nclass MemgraphTrigger()\n</code></pre>"},{"location":"reference/gqlalchemy/models/#to_cypher_2","title":"to_cypher","text":"<pre><code>def to_cypher() -&gt; str\n</code></pre> <p>Converts a Trigger to a cypher clause.</p>"},{"location":"reference/gqlalchemy/models/#graphobject-objects","title":"GraphObject Objects","text":"<pre><code>class GraphObject(BaseModel)\n</code></pre>"},{"location":"reference/gqlalchemy/models/#__init_subclass__","title":"__init_subclass__","text":"<pre><code>def __init_subclass__(cls,\n                      type=None,\n                      label=None,\n                      labels=None,\n                      index=None,\n                      db=None)\n</code></pre> <p>Stores the subclass by type if type is specified, or by class name when instantiating a subclass.</p>"},{"location":"reference/gqlalchemy/models/#_convert_to_real_type_","title":"_convert_to_real_type_","text":"<pre><code>@classmethod\ndef _convert_to_real_type_(cls, data)\n</code></pre> <p>Converts the GraphObject class into the appropriate subclass. This is used when deserialising a json representation of the class, or the object returned from the GraphDatabase.</p>"},{"location":"reference/gqlalchemy/models/#parse_obj","title":"parse_obj","text":"<pre><code>@classmethod\ndef parse_obj(cls, obj)\n</code></pre> <p>Used to convert a dictionary object into the appropriate GraphObject.</p>"},{"location":"reference/gqlalchemy/models/#nodemetaclass-objects","title":"NodeMetaclass Objects","text":"<pre><code>class NodeMetaclass(BaseModel.__class__)\n</code></pre>"},{"location":"reference/gqlalchemy/models/#__new__","title":"__new__","text":"<pre><code>def __new__(mcs, name, bases, namespace, **kwargs)\n</code></pre> <p>This creates the class <code>Node</code>. It also creates all subclasses of <code>Node</code>. Whenever a class is defined as a subclass of <code>Node</code>, <code>MyMeta.__new__</code> is called.</p>"},{"location":"reference/gqlalchemy/models/#node-objects","title":"Node Objects","text":"<pre><code>class Node(UniqueGraphObject, metaclass=NodeMetaclass)\n</code></pre>"},{"location":"reference/gqlalchemy/models/#has_unique_fields","title":"has_unique_fields","text":"<pre><code>def has_unique_fields() -&gt; bool\n</code></pre> <p>Returns True if the Node has any unique fields.</p>"},{"location":"reference/gqlalchemy/models/#save","title":"save","text":"<pre><code>def save(db: \"Database\") -&gt; \"Node\"\n</code></pre> <p>Saves node to Memgraph. If the node._id is not None it fetches the node with the same id from Memgraph and updates it's fields. If the node has unique fields it fetches the nodes with the same unique fields from Memgraph and updates it's fields. Otherwise it creates a new node with the same properties. Null properties are ignored.</p>"},{"location":"reference/gqlalchemy/models/#load","title":"load","text":"<pre><code>def load(db: \"Database\") -&gt; \"Node\"\n</code></pre> <p>Loads a node from Memgraph. If the node._id is not None it fetches the node from Memgraph with that internal id. If the node has unique fields it fetches the node from Memgraph with those unique fields set. Otherwise it tries to find any node in Memgraph that has all properties set to exactly the same values. If no node is found or no properties are set it raises a GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/models/#get_or_create","title":"get_or_create","text":"<pre><code>def get_or_create(db: \"Database\") -&gt; Tuple[\"Node\", bool]\n</code></pre> <p>Return the node and a flag for whether it was created in the database.</p> <p>Arguments:</p> <ul> <li><code>db</code> - The database instance to operate on.</li> </ul> <p>Returns:</p> <p>A tuple with the first component being the created graph node,   and the second being a boolean that is True if the node   was created in the database, and False if it was loaded instead.</p>"},{"location":"reference/gqlalchemy/models/#relationshipmetaclass-objects","title":"RelationshipMetaclass Objects","text":"<pre><code>class RelationshipMetaclass(BaseModel.__class__)\n</code></pre>"},{"location":"reference/gqlalchemy/models/#__new___1","title":"__new__","text":"<pre><code>def __new__(mcs, name, bases, namespace, **kwargs)\n</code></pre> <p>This creates the class <code>Relationship</code>. It also creates all subclasses of <code>Relationship</code>. Whenever a class is defined as a subclass of <code>Relationship</code>, <code>self.__new__</code> is called.</p>"},{"location":"reference/gqlalchemy/models/#relationship-objects","title":"Relationship Objects","text":"<pre><code>class Relationship(UniqueGraphObject, metaclass=RelationshipMetaclass)\n</code></pre>"},{"location":"reference/gqlalchemy/models/#save_1","title":"save","text":"<pre><code>def save(db: \"Database\") -&gt; \"Relationship\"\n</code></pre> <p>Saves a relationship to Memgraph. If relationship._id is not None it finds the relationship in Memgraph and updates it's properties with the values in <code>relationship</code>. If relationship._id is None, it creates a new relationship. If you want to set a relationship._id instead of creating a new relationship, use <code>load_relationship</code> first.</p>"},{"location":"reference/gqlalchemy/models/#load_1","title":"load","text":"<pre><code>def load(db: \"Database\") -&gt; \"Relationship\"\n</code></pre> <p>Returns a relationship loaded from Memgraph. If the relationship._id is not None it fetches the relationship from Memgraph that has the same internal id. Otherwise it returns the relationship whose relationship._start_node_id and relationship._end_node_id and all relationship properties that are not None match the relationship in Memgraph. If there is no relationship like that in Memgraph, or if there are multiple relationships like that in Memgraph, throws GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/models/#get_or_create_1","title":"get_or_create","text":"<pre><code>def get_or_create(db: \"Database\") -&gt; Tuple[\"Relationship\", bool]\n</code></pre> <p>Return the relationship and a flag for whether it was created in the database.</p> <p>Arguments:</p> <ul> <li><code>db</code> - The database instance to operate on.</li> </ul> <p>Returns:</p> <p>A tuple with the first component being the created graph relationship,   and the second being a boolean that is True if the relationship   was created in the database, and False if it was loaded instead.</p>"},{"location":"reference/gqlalchemy/overview/","title":"GQLAlchemy Reference","text":"<p>This are the topics covered in the GQLAlchemy Reference:</p> <ul> <li>Connection</li> <li>Disk Storage</li> <li>Exceptions</li> <li>Instance Runner</li> <li>Loaders</li> <li>Models</li> <li>Transformations</li> <li>Utilities</li> <li>Graph Algorithms</li> <li>Integrated Algorithms</li> <li>Query Builder</li> <li>Query Modules</li> <li>Query Builders</li> <li>Declarative Base</li> <li>Memgraph Query Builder</li> <li>Transformations</li> <li>Export<ul> <li>Graph Transporter</li> <li>Transporter</li> </ul> </li> <li>Importing<ul> <li>Graph Importer</li> <li>Loaders</li> </ul> </li> <li>Translators<ul> <li>DGL Translator</li> <li>NX Translator</li> <li>PyG Translator</li> <li>Translator</li> </ul> </li> <li>Vendors</li> <li>Database Client</li> <li>Memgraph</li> <li>Neo4j</li> </ul>"},{"location":"reference/gqlalchemy/utilities/","title":"utilities","text":""},{"location":"reference/gqlalchemy/utilities/#to_cypher_value","title":"to_cypher_value","text":"<pre><code>def to_cypher_value(value: Any, config: NetworkXCypherConfig = None) -&gt; str\n</code></pre> <p>Converts value to a valid Cypher type.</p>"},{"location":"reference/gqlalchemy/utilities/#to_cypher_properties","title":"to_cypher_properties","text":"<pre><code>def to_cypher_properties(properties: Optional[Dict[str, Any]] = None,\n                         config=None) -&gt; str\n</code></pre> <p>Converts properties to a Cypher key-value properties.</p>"},{"location":"reference/gqlalchemy/utilities/#to_cypher_labels","title":"to_cypher_labels","text":"<pre><code>def to_cypher_labels(labels: Union[str, List[str], None]) -&gt; str\n</code></pre> <p>Converts labels to a Cypher label definition.</p>"},{"location":"reference/gqlalchemy/utilities/#to_cypher_qm_arguments","title":"to_cypher_qm_arguments","text":"<pre><code>def to_cypher_qm_arguments(\n        arguments: Optional[Union[str, Tuple[Union[str, int, float]]]]) -&gt; str\n</code></pre> <p>Converts query module arguments to a valid Cypher string of query module arguments.</p>"},{"location":"reference/gqlalchemy/utilities/#cypherobject-objects","title":"CypherObject Objects","text":"<pre><code>class CypherObject(ABC)\n</code></pre> <p>Abstract method representing an object in cypher syntax, such as nodes and relationships.</p>"},{"location":"reference/gqlalchemy/utilities/#cyphernode-objects","title":"CypherNode Objects","text":"<pre><code>class CypherNode(CypherObject)\n</code></pre> <p>Represents a node in Cypher syntax.</p>"},{"location":"reference/gqlalchemy/utilities/#relationshipdirection-objects","title":"RelationshipDirection Objects","text":"<pre><code>class RelationshipDirection(Enum)\n</code></pre> <p>Defines the direction of CypherRelationship object.</p>"},{"location":"reference/gqlalchemy/utilities/#cypherrelationship-objects","title":"CypherRelationship Objects","text":"<pre><code>class CypherRelationship(CypherObject)\n</code></pre> <p>Represents a relationship in Cypher syntax. Multiple types can not be set on a relationship, only queried.</p>"},{"location":"reference/gqlalchemy/utilities/#cyphervariable-objects","title":"CypherVariable Objects","text":"<pre><code>class CypherVariable()\n</code></pre> <p>Class for support of using a variable as value in Cypher. Used to avoid the quotes given to property values and query module arguments.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/","title":"integrated_algorithms","text":""},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#integratedalgorithm-objects","title":"IntegratedAlgorithm Objects","text":"<pre><code>class IntegratedAlgorithm(ABC)\n</code></pre> <p>Abstract class modeling Memgraph's built-in graph algorithms.</p> <p>These algorithms are integrated into Memgraph's codebase and are called within a relationship part of a query. For instance: MATCH p = (:City {name: \"Paris\"})       -[:Road * bfs (r, n | r.length &lt;= 200 AND n.name != \"Metz\")]-&gt;       (:City {name: \"Berlin\"})</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__str__","title":"__str__","text":"<pre><code>@abstractmethod\ndef __str__() -&gt; str\n</code></pre> <p>Instance of IntegratedAlgorithm subclass is used as a string</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#to_cypher_lambda","title":"to_cypher_lambda","text":"<pre><code>@staticmethod\ndef to_cypher_lambda(expression: str) -&gt; str\n</code></pre> <p>Method for creating a general lambda expression.</p> <p>Variables <code>r</code> and <code>n</code> stand for relationship and node. The expression is used e.g. for a filter lambda, to use only relationships of length less than 200: expression=\"r.length &lt; 200\" with the filter lambda being: (r, n | r.length &lt; 200)</p> <p>Arguments:</p> <ul> <li><code>expression</code> - Lambda conditions or statements.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#breadthfirstsearch-objects","title":"BreadthFirstSearch Objects","text":"<pre><code>class BreadthFirstSearch(IntegratedAlgorithm)\n</code></pre> <p>Build a BFS call for a Cypher query.</p> <p>The Breadth-first search can be called in Memgraph with Cypher queries such as: <code>MATCH (a {id: 723})-[*BFS ..10 (r, n | r.x &amp;gt; 12 AND n.y &amp;lt; 3)]-() RETURN *;</code> It is called inside the relationship clause, <code>*BFS</code> naming the algorithm, <code>..10</code> specifying depth bounds, and <code>(r, n | &amp;lt;expression&amp;gt;)</code> is a filter lambda.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__init__","title":"__init__","text":"<pre><code>def __init__(lower_bound: int = None,\n             upper_bound: int = None,\n             condition: str = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>lower_bound</code> - Lower bound for path depth.</li> <li><code>upper_bound</code> - Upper bound for path depth.</li> <li><code>condition</code> - Filter through nodes and relationships that pass this   condition.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__str___1","title":"__str__","text":"<pre><code>def __str__() -&gt; str\n</code></pre> <p>Get a Cypher query string for this algorithm.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#to_cypher_bounds","title":"to_cypher_bounds","text":"<pre><code>def to_cypher_bounds() -&gt; str\n</code></pre> <p>If bounds are specified, returns them in grammar-defined form.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#depthfirstsearch-objects","title":"DepthFirstSearch Objects","text":"<pre><code>class DepthFirstSearch(IntegratedAlgorithm)\n</code></pre> <p>Build a DFS call for a Cypher query. The Depth-First Search can be called in Memgraph with Cypher queries such as: MATCH (a {id: 723})-[ ..10 (r, n | r.x &gt; 12 AND n.y &lt; 3)]-() RETURN ; It is called inside the relationship clause, \"\" naming the algorithm (\"\" without \"DFS\" because it is defined like such in openCypher), \"..10\" specifying depth bounds, and \"(r, n | &lt;expression&gt;)\" is a filter lambda.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__init___1","title":"__init__","text":"<pre><code>def __init__(lower_bound: int = None,\n             upper_bound: int = None,\n             condition: str = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>lower_bound</code> - Lower bound for path depth.</li> <li><code>upper_bound</code> - Upper bound for path depth.</li> <li><code>condition</code> - Filter through nodes and relationships that pass this   condition.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__str___2","title":"__str__","text":"<pre><code>def __str__() -&gt; str\n</code></pre> <p>get Cypher query string for this algorithm.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#to_cypher_bounds_1","title":"to_cypher_bounds","text":"<pre><code>def to_cypher_bounds() -&gt; str\n</code></pre> <p>If bounds are specified, returns them in grammar-defined form.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#weightedshortestpath-objects","title":"WeightedShortestPath Objects","text":"<pre><code>class WeightedShortestPath(IntegratedAlgorithm)\n</code></pre> <p>Build a Dijkstra shortest path call for a Cypher query.</p> <p>The weighted shortest path algorithm can be called in Memgraph with Cypher queries such as: \" MATCH (a {id: 723})-[r WSHORTEST 10 (r, n | r.weight) weight_sum         (r, n | r.x &gt; 12 AND r.y &lt; 3)]-(b {id: 882}) RETURN * \" It is called inside the relationship clause, \"WSHORTEST\" naming the algorithm, \"10\" specifying search depth bounds, and \"(r, n | &lt;expression&gt;)\" is a filter lambda, used to filter which relationships and nodes to use.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__init___2","title":"__init__","text":"<pre><code>def __init__(upper_bound: int = None,\n             condition: str = None,\n             total_weight_var: str = DEFAULT_TOTAL_WEIGHT,\n             weight_property: str = DEFAULT_WEIGHT_PROPERTY) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>upper_bound</code> - Upper bound for path depth.</li> <li><code>condition</code> - Filter through nodes and relationships that pass this   condition.</li> <li><code>total_weight_var</code> - Variable defined as the sum of all weights on   path being returned.</li> <li><code>weight_property</code> - property being used as weight.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#allshortestpath-objects","title":"AllShortestPath Objects","text":"<pre><code>class AllShortestPath(IntegratedAlgorithm)\n</code></pre> <p>Build a Dijkstra shortest path call for a Cypher query.</p> <p>The weighted shortest path algorithm can be called in Memgraph with Cypher queries such as: \" MATCH (a {id: 723})-[r ALLSHORTEST 10 (r, n | r.weight) total_weight         (r, n | r.x &gt; 12 AND r.y &lt; 3)]-(b {id: 882}) RETURN * \" It is called inside the relationship clause, \"ALLSHORTEST\" naming the algorithm, \"10\" specifying search depth bounds, and \"(r, n | &lt;expression&gt;)\" is a filter lambda, used to filter which relationships and nodes to use.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/integrated_algorithms/#__init___3","title":"__init__","text":"<pre><code>def __init__(upper_bound: int = None,\n             condition: str = None,\n             total_weight_var: str = DEFAULT_TOTAL_WEIGHT,\n             weight_property: str = DEFAULT_WEIGHT_PROPERTY) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>upper_bound</code> - Upper bound for path depth.</li> <li><code>condition</code> - Filter through nodes and relationships that pass this   condition.</li> <li><code>total_weight_var</code> - Variable defined as the sum of all weights on   path being returned.</li> <li><code>weight_property</code> - Property being used as weight.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/query_builder/","title":"query_builder","text":""},{"location":"reference/gqlalchemy/graph_algorithms/query_builder/#memgraphquerybuilder-objects","title":"MemgraphQueryBuilder Objects","text":"<pre><code>class MemgraphQueryBuilder(QueryBuilder)\n</code></pre> <p>This query builder extends the usual Cypher query builder capabilities with Memgraph's query modules. User gets with this module autocomplete features of graph algorithms. Documentation on the methods can be found on Memgraph's web page.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/query_builder/#magequerybuilder-objects","title":"MageQueryBuilder Objects","text":"<pre><code>class MageQueryBuilder(MemgraphQueryBuilder)\n</code></pre> <p>This query builder extends the Memgraph query builder with Memgraph MAGE graph algorithm Cypher options. User gets with this module autocomplete features of graph algorithms written in MAGE library. Documentation on the methods can be found on Memgraph's web page.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/query_modules/","title":"query_modules","text":""},{"location":"reference/gqlalchemy/graph_algorithms/query_modules/#querymodule-objects","title":"QueryModule Objects","text":"<pre><code>class QueryModule()\n</code></pre> <p>Class representing a single MAGE query module.</p>"},{"location":"reference/gqlalchemy/graph_algorithms/query_modules/#set_argument_values","title":"set_argument_values","text":"<pre><code>def set_argument_values(**kwargs) -&gt; None\n</code></pre> <p>Set values for QueryModule arguments so the module can be called.</p> <p>Kwargs: Named arguments in self.arguments.</p> <p>Raises:</p> <ul> <li><code>KeyError</code> - Passed an argument not in the self.arguments list.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/query_modules/#get_arguments_for_call","title":"get_arguments_for_call","text":"<pre><code>def get_arguments_for_call() -&gt; str\n</code></pre> <p>return inputs in form \"value1, value2, ...\" for QueryBuilder call() method.</p> <p>Raises:</p> <ul> <li><code>KeyError</code> - Cannot get all values of arguments because one or more is   not set.</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/query_modules/#parse_query_module_signature","title":"parse_query_module_signature","text":"<pre><code>def parse_query_module_signature(\n        signature: str) -&gt; Tuple[List[Dict[str, str]], List[Dict[str, str]]]\n</code></pre> <p>Query Modules signatures received from Memgraph are parsed into a list of dictionaries.</p> <p>One list is for arguments and another for returns. For instance, if a query module signature is: dummy_module.dummy(lst :: LIST OF STRING, num = 3 :: NUMBER) :: (ret :: STRING) the method should return a list of arguments: [{\"name\": \"lst\", \"type\": \"LIST OF STRING\"}, {\"name\": \"num\", \"type\": \"NUMBER\", \"default\": 3}] and a list of returns: [{\"name\": \"ret\", \"type\": \"STRING\"}]</p> <p>Dictionary consists of fields: \"name\" - argument name, \"type\" - data type of argument and \"default\" where default argument value is given</p> <p>Arguments:</p> <ul> <li><code>signature</code> - module signature as returned by Cypher CALL operation</li> </ul>"},{"location":"reference/gqlalchemy/graph_algorithms/query_modules/#parse_field","title":"parse_field","text":"<pre><code>def parse_field(\n        vars_field: str,\n        name_type_delimiter: str = NAME_TYPE_DELIMITER,\n        default_value_delimiter: str = EQUALS_DELIMITER\n) -&gt; List[Dict[str, str]]\n</code></pre> <p>Parse a field of arguments or returns from Query Module signature.</p> <p>Arguments:</p> <ul> <li><code>vars_field</code> - signature field inside parenthesis</li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/","title":"declarative_base","text":""},{"location":"reference/gqlalchemy/query_builders/declarative_base/#whereconditionpartialquery-objects","title":"WhereConditionPartialQuery Objects","text":"<pre><code>class WhereConditionPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Constructs a where partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#nodepartialquery-objects","title":"NodePartialQuery Objects","text":"<pre><code>class NodePartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_1","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Constructs a node partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#relationshippartialquery-objects","title":"RelationshipPartialQuery Objects","text":"<pre><code>class RelationshipPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_2","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Constructs a relationship partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#unwindpartialquery-objects","title":"UnwindPartialQuery Objects","text":"<pre><code>class UnwindPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_3","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Constructs an unwind partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#dict_to_alias_statement","title":"dict_to_alias_statement","text":"<pre><code>def dict_to_alias_statement(alias_dict: Dict[str, str]) -&gt; str\n</code></pre> <p>Creates a string expression of alias statements from a dictionary of expression, variable name dictionary.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#_resultpartialquery-objects","title":"_ResultPartialQuery Objects","text":"<pre><code>class _ResultPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_4","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a RETURN/YIELD/WITH statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#unionpartialquery-objects","title":"UnionPartialQuery Objects","text":"<pre><code>class UnionPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_5","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a UNION statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#deletepartialquery-objects","title":"DeletePartialQuery Objects","text":"<pre><code>class DeletePartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_6","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a DELETE statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#removepartialquery-objects","title":"RemovePartialQuery Objects","text":"<pre><code>class RemovePartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_7","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a REMOVE statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#orderbypartialquery-objects","title":"OrderByPartialQuery Objects","text":"<pre><code>class OrderByPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_8","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a ORDER BY statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#limitpartialquery-objects","title":"LimitPartialQuery Objects","text":"<pre><code>class LimitPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_9","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a LIMIT statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#skippartialquery-objects","title":"SkipPartialQuery Objects","text":"<pre><code>class SkipPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_10","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a SKIP statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#foreachpartialquery-objects","title":"ForeachPartialQuery Objects","text":"<pre><code>class ForeachPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_11","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Creates a FOREACH statement Cypher partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#setpartialquery-objects","title":"SetPartialQuery Objects","text":"<pre><code>class SetPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#construct_query_12","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Constructs a set partial query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#declarativebase-objects","title":"DeclarativeBase Objects","text":"<pre><code>class DeclarativeBase(ABC)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#match","title":"match","text":"<pre><code>def match(optional: bool = False) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Obtain data from the database by matching it to a given pattern.</p> <p>Arguments:</p> <ul> <li><code>optional</code> - A bool indicating if missing parts of the pattern will be   filled with null values.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Get all nodes with a certain label:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Country&amp;#x27;, variable=&amp;#x27;c&amp;#x27;).return_(results=&amp;#x27;c&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (c:Country) RETURN c;</code></li> </ul> <p>Get a relationship of a certain type that connects two nodes with certain label:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Town&amp;#x27;, variable=&amp;#x27;t&amp;#x27;).to(relationship_type=&amp;#x27;BELONGS_TO&amp;#x27;, variable=&amp;#x27;b&amp;#x27;).node(labels=&amp;#x27;Country&amp;#x27;, variable=&amp;#x27;c&amp;#x27;).return_(results=&amp;#x27;b&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (t:Town)-[b:BELONGS_TO]-&amp;gt;(c:Country) RETURN b;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#merge","title":"merge","text":"<pre><code>def merge() -&gt; \"DeclarativeBase\"\n</code></pre> <p>Ensure that a pattern you are looking for exists in the database. This means that if the pattern is not found, it will be created. In a way, this clause is like a combination of MATCH and CREATE.</p> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Merge node with properties:</p> <ul> <li><code>Python</code> - <code>merge().node(variable=&amp;#x27;city&amp;#x27;).where(item=&amp;#x27;city.name&amp;#x27;, operator=Operator.EQUAL, literal=&amp;#x27;London&amp;#x27;).return_(results=&amp;#x27;city&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MERGE (city) WHERE city.name = &amp;#x27;London&amp;#x27; RETURN city;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#create","title":"create","text":"<pre><code>def create() -&gt; \"DeclarativeBase\"\n</code></pre> <p>Create nodes and relationships in a graph.</p> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Create a single node:</p> <ul> <li><code>Python</code> - <code>create().node(labels=&amp;#x27;Person&amp;#x27;, variable=&amp;#x27;p&amp;#x27;).return_(results=&amp;#x27;p&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>CREATE (p:Person) RETURN p;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#call","title":"call","text":"<pre><code>def call(\n    procedure: str,\n    arguments: Optional[Union[str, Tuple[Union[str, int, float]]]] = None\n) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Call a query module procedure.</p> <p>Arguments:</p> <ul> <li><code>procedure</code> - A string representing the name of the procedure in the   format <code>query_module.procedure</code>.</li> <li><code>arguments</code> - A string representing the arguments of the procedure in   text format.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Call procedure with no arguments:</p> <ul> <li><code>Python</code> - <code>call(&amp;#x27;pagerank.get&amp;#x27;).yield_().return_().execute()</code></li> <li><code>Cypher</code> - <code>CALL pagerank.get() YIELD * RETURN *;</code></li> </ul> <p>Call procedure with arguments:</p> <ul> <li><code>Python</code> - `call('json_util.load_from_url', \"'https://some-url.com'\").yield_('objects').return_(results='objects').execute()</li> <li><code>Cypher</code> - <code>CALL json_util.load_from_url(https://some-url.com) YIELD objects RETURN objects;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#node","title":"node","text":"<pre><code>def node(labels: Union[str, List[str], None] = \"\",\n         variable: Optional[str] = None,\n         node: Optional[\"Node\"] = None,\n         **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Add a node pattern to the query.</p> <p>Arguments:</p> <ul> <li><code>labels</code> - A string or list of strings representing the labels of the   node.</li> <li><code>variable</code> - A string representing the name of the variable for storing   results of the node pattern.</li> <li><code>node</code> - A <code>Node</code> object to construct the pattern from.</li> <li><code>**kwargs</code> - Arguments representing the properties of the node.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Create a node and return it:</p> <ul> <li><code>Python</code> - <code>create().node(labels=&amp;#x27;Person&amp;#x27;, variable=&amp;#x27;n&amp;#x27;, first_name=&amp;#x27;Kate&amp;#x27;).return_(results=&amp;#x27;n&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>CREATE (n:Person {first_name: &amp;#x27;Kate&amp;#x27;}) RETURN n;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#to","title":"to","text":"<pre><code>def to(relationship_type: Optional[str] = \"\",\n       directed: Optional[bool] = True,\n       variable: Optional[str] = None,\n       relationship: Optional[\"Relationship\"] = None,\n       algorithm: Optional[IntegratedAlgorithm] = None,\n       **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Add a relationship pattern to the query.</p> <p>Arguments:</p> <ul> <li><code>relationship_type</code> - A string representing the type of the relationship.</li> <li><code>directed</code> - A bool indicating if the relationship is directed.</li> <li><code>variable</code> - A string representing the name of the variable for storing   results of the relationship pattern.</li> <li><code>relationship</code> - A <code>Relationship</code> object to construct the pattern from.</li> <li><code>algorithm</code> - algorithm object to use over graph data.</li> <li><code>**kwargs</code> - Arguments representing the properties of the relationship.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Match and return a relationship:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Town&amp;#x27;, variable=&amp;#x27;t&amp;#x27;).to(relationship_type=&amp;#x27;BELONGS_TO&amp;#x27;, variable=&amp;#x27;b&amp;#x27;).node(labels=&amp;#x27;Country&amp;#x27;, variable=&amp;#x27;c&amp;#x27;).return_(results=&amp;#x27;b&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (t:Town)-[b:BELONGS_TO]-&amp;gt;(c:Country) RETURN b;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#from_","title":"from_","text":"<pre><code>def from_(relationship_type: Optional[str] = \"\",\n          directed: Optional[bool] = True,\n          variable: Optional[str] = None,\n          relationship: Optional[\"Relationship\"] = None,\n          algorithm: Optional[IntegratedAlgorithm] = None,\n          **kwargs) -&gt; \"Match\"\n</code></pre> <p>Add a relationship pattern to the query.</p> <p>Arguments:</p> <ul> <li><code>relationship_type</code> - A string representing the type of the relationship.</li> <li><code>directed</code> - A bool indicating if the relationship is directed.</li> <li><code>variable</code> - A string representing the name of the variable for storing   results of the relationship pattern.</li> <li><code>relationship</code> - A <code>Relationship</code> object to construct the pattern from.</li> <li><code>**kwargs</code> - Arguments representing the properties of the relationship.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Match and return a relationship:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Country&amp;#x27;, variable=&amp;#x27;c&amp;#x27;).from_(relationship_type=&amp;#x27;BELONGS_TO&amp;#x27;, variable=&amp;#x27;b&amp;#x27;).node(labels=&amp;#x27;Town&amp;#x27;, variable=&amp;#x27;t&amp;#x27;).return_(results=&amp;#x27;b&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (c:Country)&amp;lt;-[b:BELONGS_TO]-(t:Town) RETURN b;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#where","title":"where","text":"<pre><code>def where(item: str, operator: Operator, **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates a WHERE statement Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Raises:</p> <ul> <li><code>GQLAlchemyLiteralAndExpressionMissingInWhere</code> - Raises an error when neither literal nor expression keyword arguments were provided.</li> <li><code>GQLAlchemyExtraKeywordArgumentsInWhere</code> - Raises an error when both literal and expression keyword arguments were provided.</li> </ul> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by the equality of <code>name</code> properties of two connected nodes.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).to().node(variable=&amp;#x27;m&amp;#x27;).where(item=&amp;#x27;n.name&amp;#x27;, operator=Operator.EQUAL, expression=&amp;#x27;m.name&amp;#x27;).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n)-[]-&amp;gt;(m) WHERE n.name = m.name RETURN *;</code></li> </ul> <p>Filtering query results by the node label.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User RETURN *;</code></li> </ul> <p>Filtering query results by the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#where_not","title":"where_not","text":"<pre><code>def where_not(item: str, operator: Operator, **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates a WHERE NOT statement Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Raises:</p> <ul> <li><code>GQLAlchemyLiteralAndExpressionMissingInWhere</code> - Raises an error when neither literal nor expression keyword arguments were provided.</li> <li><code>GQLAlchemyExtraKeywordArgumentsInWhere</code> - Raises an error when both literal and expression keyword arguments were provided.</li> </ul> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by the equality of <code>name</code> properties of two connected nodes.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).to().node(variable=&amp;#x27;m&amp;#x27;).where_not(item=&amp;#x27;n.name&amp;#x27;, operator=&amp;#x27;=&amp;#x27;, expression=&amp;#x27;m.name&amp;#x27;).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n)-[]-&amp;gt;(m) WHERE NOT n.name = m.name RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#and_where","title":"and_where","text":"<pre><code>def and_where(item: str, operator: Operator, **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an AND statement as a part of WHERE Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by node label or the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).and_where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User AND n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#and_not_where","title":"and_not_where","text":"<pre><code>def and_not_where(item: str, operator: Operator,\n                  **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an AND NOT statement as a part of WHERE Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by node label or the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).and_not_where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User AND NOT n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#or_where","title":"or_where","text":"<pre><code>def or_where(item: str, operator: Operator, **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an OR statement as a part of WHERE Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by node label or the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).or_where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User OR n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#or_not_where","title":"or_not_where","text":"<pre><code>def or_not_where(item: str, operator: Operator, **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an OR NOT statement as a part of WHERE Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by node label or the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).or_not_where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User OR NOT n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#xor_where","title":"xor_where","text":"<pre><code>def xor_where(item: str, operator: Operator, **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an XOR statement as a part of WHERE Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by node label or the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).xor_where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User XOR n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#xor_not_where","title":"xor_not_where","text":"<pre><code>def xor_not_where(item: str, operator: Operator,\n                  **kwargs) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an XOR NOT statement as a part of WHERE Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - A string representing the operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Filtering query results by node label or the comparison of node property and literal.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;User&amp;#x27;).xor_not_where(item=&amp;#x27;n.age&amp;#x27;, operator=Operator.GREATER_THAN, literal=18).return_()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n:User XOR NOT n.age &amp;gt; 18 RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#unwind","title":"unwind","text":"<pre><code>def unwind(list_expression: str, variable: str) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Unwind a list of values as individual rows.</p> <p>Arguments:</p> <ul> <li><code>list_expression</code> - A list of strings representing the list of values.</li> <li><code>variable</code> - A string representing the variable name for unwinding results.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <ul> <li><code>Python</code> - <code>unwind(list_expression=&amp;quot;[1, 2, 3, null]&amp;quot;, variable=&amp;quot;x&amp;quot;).return_(results=[&amp;quot;x&amp;quot;, (&amp;quot;&amp;#x27;val&amp;#x27;&amp;quot;, &amp;quot;y&amp;quot;)]).execute()</code></li> <li><code>Cypher</code> - <code>UNWIND [1, 2, 3, null] AS x RETURN x, &amp;#x27;val&amp;#x27; AS y;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#with_","title":"with_","text":"<pre><code>def with_(\n    results: Optional[Union[str, Tuple[str, str], Dict[str, str],\n                            List[Union[str, Tuple[str, str]]],\n                            Set[Union[str, Tuple[str, str]]], ]] = None\n) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Chain together parts of a query, piping the results from one to be used as starting points or criteria in the next.</p> <p>Arguments:</p> <ul> <li><code>results</code> - A dictionary mapping variables in the first query with   aliases in the second query.</li> </ul> <p>Raises:</p> <ul> <li><code>GQLAlchemyResultQueryTypeError</code> - Raises an error when the provided argument is of wrong type.</li> <li><code>GQLAlchemyTooLargeTupleInResultQuery</code> - Raises an error when the given tuple has length larger than 2.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Pipe the result from first part of the query for the further use:</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).with(&amp;#x27;n&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - `MATCH (n) WITH n;</li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#union","title":"union","text":"<pre><code>def union(include_duplicates: Optional[bool] = True) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Combine the result of multiple queries.</p> <p>Arguments:</p> <ul> <li><code>include_duplicates</code> - A bool indicating if duplicates should be   included.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Combine queries and retain duplicates:</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;quot;c&amp;quot;, labels=&amp;quot;Country&amp;quot;).return_(results=(&amp;quot;c.name&amp;quot;, &amp;quot;columnName&amp;quot;)).union().match().node(variable=&amp;quot;p&amp;quot;, labels=&amp;quot;Person&amp;quot;).return_(results=(&amp;quot;p.name&amp;quot;, &amp;quot;columnName&amp;quot;)).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (c:Country) RETURN c.name AS columnName UNION ALL MATCH (p:Person) RETURN p.name AS columnName;</code></li> </ul> <p>Combine queries and remove duplicates:</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;quot;c&amp;quot;, labels=&amp;quot;Country&amp;quot;).return_(results=(&amp;quot;c.name&amp;quot;, &amp;quot;columnName&amp;quot;)).union(include_duplicates=False).match().node(variable=&amp;quot;p&amp;quot;, labels=&amp;quot;Person&amp;quot;).return_(results=(&amp;quot;p.name&amp;quot;, &amp;quot;columnName&amp;quot;)).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (c:Country) RETURN c.name AS columnName UNION MATCH (p:Person) RETURN p.name AS columnName;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#delete","title":"delete","text":"<pre><code>def delete(variable_expressions: Union[str, List[str]],\n           detach: Optional[bool] = False) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Delete nodes and relationships from the database.</p> <p>Arguments:</p> <ul> <li><code>variable_expressions</code> - A string or list of strings indicating which node(s)   and/or relationship(s) should be removed.</li> <li><code>detach</code> - A bool indicating if relationships should be deleted along   with a node.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Delete a node:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Node1&amp;#x27;, variable=&amp;#x27;n1&amp;#x27;).delete(variable_expressions=&amp;#x27;n1&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n1:Node1) DELETE n1;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#remove","title":"remove","text":"<pre><code>def remove(items: Union[str, List[str]]) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Remove labels and properties from nodes and relationships.</p> <p>Arguments:</p> <ul> <li><code>items</code> - A string or list of strings indicating which label(s) and/or properties   should be removed.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Remove a property from a node:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Country&amp;#x27;, variable=&amp;#x27;n&amp;#x27;, name=&amp;#x27;United Kingdom&amp;#x27;).remove(items=&amp;#x27;n.name&amp;#x27;).return_(results=&amp;#x27;n&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n:Country {name: &amp;#x27;United Kingdom&amp;#x27;}) REMOVE n.name RETURN n;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#yield_","title":"yield_","text":"<pre><code>def yield_(\n    results: Optional[Union[str, Tuple[str, str], Dict[str, str],\n                            List[Union[str, Tuple[str, str]]],\n                            Set[Union[str, Tuple[str, str]]], ]] = None\n) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Yield data from the query.</p> <p>Arguments:</p> <ul> <li><code>results</code> - A dictionary mapping items that are returned with alias names.</li> </ul> <p>Raises:</p> <ul> <li><code>GQLAlchemyResultQueryTypeError</code> - Raises an error when the provided argument is of wrong type.</li> <li><code>GQLAlchemyTooLargeTupleInResultQuery</code> - Raises an error when the given tuple has length larger than 2.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Yield all data from a query:</p> <ul> <li><code>Python</code> - <code>call(procedure=&amp;#x27;pagerank.get&amp;#x27;).yield_().return_().execute()</code></li> <li><code>Cypher</code> - <code>CALL pagerank.get() YIELD * RETURN *;</code></li> </ul> <p>Yield some data from a query:</p> <ul> <li><code>Python</code> - <code>.call(procedure=&amp;#x27;pagerank.get&amp;#x27;).yield_(results=[&amp;#x27;node&amp;#x27;, &amp;#x27;rank&amp;#x27;]).return_(results=[&amp;#x27;node&amp;#x27;,&amp;#x27;rank&amp;#x27;]).execute()</code></li> <li><code>Cypher</code> - <code>CALL pagerank.get() YIELD node, rank RETURN node, rank;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#return_","title":"return_","text":"<pre><code>def return_(\n    results: Optional[Union[str, Tuple[str, str], Dict[str, str],\n                            List[Union[str, Tuple[str, str]]],\n                            Set[Union[str, Tuple[str, str]]], ]] = None\n) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Return data from the query.</p> <p>Arguments:</p> <ul> <li><code>results</code> - An optional string, tuple or iterable of strings and tuples for alias names.</li> </ul> <p>Raises:</p> <ul> <li><code>GQLAlchemyResultQueryTypeError</code> - Raises an error when the provided argument is of wrong type.</li> <li><code>GQLAlchemyTooLargeTupleInResultQuery</code> - Raises an error when the given tuple has length larger than 2.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Return all variables from a query:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Person&amp;#x27;, variable=&amp;#x27;p&amp;#x27;).return_().execute()</code></li> <li><code>Cypher</code> - <code>MATCH (p:Person) RETURN *;</code></li> </ul> <p>Return specific variables from a query:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Person&amp;#x27;, variable=&amp;#x27;p1&amp;#x27;).to().node(labels=&amp;#x27;Person&amp;#x27;, variable=&amp;#x27;p2&amp;#x27;).return_(results=[(&amp;#x27;p1&amp;#x27;,&amp;#x27;first&amp;#x27;), &amp;#x27;p2&amp;#x27;]).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (p1:Person)-[]-&amp;gt;(p2:Person) RETURN p1 AS first, p2;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#order_by","title":"order_by","text":"<pre><code>def order_by(\n    properties: Union[str, Tuple[str, Order], List[Union[str, Tuple[str,\n                                                                    Order]]]]\n) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Creates an ORDER BY statement Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>properties</code> - Properties and order (DESC/DESCENDING/ASC/ASCENDING) by which the query results will be ordered.</li> </ul> <p>Raises:</p> <ul> <li><code>GQLAlchemyOrderByTypeError</code> - Raises an error when the given ordering is of the wrong type.</li> <li><code>GQLAlchemyMissingOrder</code> - Raises an error when the given property is neither string nor tuple.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Ordering query results by the property <code>n.name</code> in ascending order   and by the property <code>n.last_name</code> in descending order:</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).return_().order_by(properties=[&amp;#x27;n.name&amp;#x27;, (&amp;#x27;n.last_name&amp;#x27;, Order.DESC)]).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n) RETURN * ORDER BY n.name, n.last_name DESC;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#limit","title":"limit","text":"<pre><code>def limit(integer_expression: Union[str, int]) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Limit the number of records when returning results.</p> <p>Arguments:</p> <ul> <li><code>integer_expression</code> - An integer indicating how many records to limit   the results to.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Limit the number of returned results:</p> <ul> <li><code>Python</code> - <code>match().node(labels=&amp;#x27;Person&amp;#x27;, variable=&amp;#x27;p&amp;#x27;).return_().limit(integer_expression=&amp;#x27;10&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (p:Person) RETURN * LIMIT 10;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#skip","title":"skip","text":"<pre><code>def skip(integer_expression: Union[str, int]) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Skip a number of records when returning results.</p> <p>Arguments:</p> <ul> <li><code>integer_expression</code> - An integer indicating how many records to skip   in the results.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>Skip the first result:</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).return_(results=&amp;#x27;n&amp;#x27;).skip(integer_expression=&amp;#x27;1&amp;#x27;).execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n) RETURN n SKIP 1;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#add_custom_cypher","title":"add_custom_cypher","text":"<pre><code>def add_custom_cypher(custom_cypher: str) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Inject custom Cypher code into the query.</p> <p>Arguments:</p> <ul> <li><code>custom_cypher</code> - A string representing the Cypher code to be injected   into the query.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#get_single","title":"get_single","text":"<pre><code>def get_single(retrieve: str) -&gt; Any\n</code></pre> <p>Returns a single result with a <code>retrieve</code> variable name.</p> <p>Arguments:</p> <ul> <li><code>retrieve</code> - A string representing the results variable to be returned.</li> </ul> <p>Returns:</p> <p>An iterator of dictionaries containing the results of the query.</p>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#foreach","title":"foreach","text":"<pre><code>def foreach(\n        variable: str, expression: str,\n        update_clause: Union[str, List[str], Set[str]]) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Iterate over a list of elements and for every iteration run every update clause.</p> <p>Arguments:</p> <ul> <li><code>variable</code> - The variable name that stores each element.</li> <li><code>expression</code> - Any expression that results in a list.</li> <li><code>update_clauses</code> - One or more Cypher update clauses:   SET, REMOVE, CREATE, MERGE, DELETE, FOREACH.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Example:</p> <p>For each number in a list, create a node:</p> <ul> <li><code>Python</code> - <code>update_clause = QueryBuilder().create().node(variable=&amp;quot;n&amp;quot;, id=PropertyVariable(&amp;quot;i&amp;quot;))</code> <code>query_builder = QueryBuilder().foreach(&amp;quot;i&amp;quot;, &amp;quot;[1, 2, 3]&amp;quot;, update_clause.construct_query())</code></li> <li><code>Cypher</code> - <code>FOREACH ( i IN [1, 2, 3] | CREATE (n {id: i}) )</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#set_","title":"set_","text":"<pre><code>def set_(item: str, operator: Operator, **kwargs)\n</code></pre> <p>Creates a SET statement Cypher partial query.</p> <p>Arguments:</p> <ul> <li><code>item</code> - A string representing variable or property.</li> <li><code>operator</code> - An assignment, increment or label filter operator.</li> </ul> <p>Kwargs: - <code>literal</code> - A value that will be converted to Cypher value, such as int, float, string, etc. - <code>expression</code> - A node label or property that won't be converted to Cypher value (no additional quotes will be added).</p> <p>Raises:</p> <ul> <li><code>GQLAlchemyLiteralAndExpressionMissingInWhere</code> - Raises an error when neither literal nor expression keyword arguments were provided.</li> <li><code>GQLAlchemyExtraKeywordArgumentsInWhere</code> - Raises an error when both literal and expression keyword arguments were provided.</li> </ul> <p>Returns:</p> <ul> <li><code>self</code> - A partial Cypher query built from the given parameters.</li> </ul> <p>Examples:</p> <p>Set or update a property.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n.name&amp;#x27;, operator=Operator.EQUAL, literal=&amp;#x27;Germany&amp;#x27;).set_(item=&amp;#x27;n.population&amp;#x27;, operator=Operator.ASSIGNMENT, literal=83000001).return_().execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n.name = &amp;#x27;Germany&amp;#x27; SET n.population = 83000001 RETURN *;</code></li> </ul> <p>Set or update multiple properties.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n.name&amp;#x27;, operator=Operator.EQUAL, literal=&amp;#x27;Germany&amp;#x27;).set_(item=&amp;#x27;n.population&amp;#x27;, operator=Operator.ASSIGNMENT, literal=83000001).set_(item=&amp;#x27;n.capital&amp;#x27;, operator=Operator.ASSIGNMENT, literal=&amp;#x27;Berlin&amp;#x27;).return_().execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n.name = &amp;#x27;Germany&amp;#x27; SET n.population = 83000001 SET n.capital = &amp;#x27;Berlin&amp;#x27; RETURN *;</code></li> </ul> <p>Set node label.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;n&amp;#x27;).where(item=&amp;#x27;n.name&amp;#x27;, operator=Operator.EQUAL, literal=&amp;#x27;Germany&amp;#x27;).set_(item=&amp;#x27;n&amp;#x27;, operator=Operator.LABEL_FILTER, expression=&amp;#x27;Land&amp;#x27;).return_().execute()</code></li> <li><code>Cypher</code> - <code>MATCH (n) WHERE n.name = &amp;#x27;Germany&amp;#x27; SET n:Land RETURN *;</code></li> </ul> <p>Replace all properties using map.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;c&amp;#x27;, labels=&amp;#x27;Country&amp;#x27;).where(item=&amp;#x27;c.name&amp;#x27;, operator=Operator.EQUAL, literal=&amp;#x27;Germany&amp;#x27;).set_(item=&amp;#x27;c&amp;#x27;, operator=Operator.ASSIGNMENT, literal={&amp;#x27;name&amp;#x27;: &amp;#x27;Germany&amp;#x27;, &amp;#x27;population&amp;#x27;: &amp;#x27;85000000&amp;#x27;}).return_().execute()</code></li> <li><code>Cypher</code> - <code>MATCH (c:Country) WHERE c.name = &amp;#x27;Germany&amp;#x27; SET c = {name: &amp;#x27;Germany&amp;#x27;, population: &amp;#x27;85000000&amp;#x27;} RETURN *;</code></li> </ul> <p>Update all properties using map.</p> <ul> <li><code>Python</code> - <code>match().node(variable=&amp;#x27;c&amp;#x27;, labels=&amp;#x27;Country&amp;#x27;).where(item=&amp;#x27;c.name&amp;#x27;, operator=Operator.EQUAL, literal=&amp;#x27;Germany&amp;#x27;).set_(item=&amp;#x27;c&amp;#x27;, operator=Operator.INCREMENT, literal={&amp;#x27;name&amp;#x27;: &amp;#x27;Germany&amp;#x27;, &amp;#x27;population&amp;#x27;: &amp;#x27;85000000&amp;#x27;}).return_().execute()</code></li> <li><code>Cypher</code> - <code>MATCH (c:Country) WHERE c.name = &amp;#x27;Germany&amp;#x27; SET c += {name: &amp;#x27;Germany&amp;#x27;, population: &amp;#x27;85000000&amp;#x27;} RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/declarative_base/#execute","title":"execute","text":"<pre><code>def execute() -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Executes the Cypher query and returns the results.</p> <p>Returns:</p> <p>An iterator of dictionaries containing the results of the query.</p>"},{"location":"reference/gqlalchemy/query_builders/memgraph_query_builder/","title":"memgraph_query_builder","text":""},{"location":"reference/gqlalchemy/query_builders/memgraph_query_builder/#querybuilder-objects","title":"QueryBuilder Objects","text":"<pre><code>class QueryBuilder(DeclarativeBase)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/memgraph_query_builder/#load_csv","title":"load_csv","text":"<pre><code>def load_csv(path: str, header: bool, row: str) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Load data from a CSV file by executing a Cypher query for each row.</p> <p>Arguments:</p> <ul> <li><code>path</code> - A string representing the path to the CSV file.</li> <li><code>header</code> - A bool indicating if the CSV file starts with a header row.</li> <li><code>row</code> - A string representing the name of the variable for iterating   over each row.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <p>Load CSV with header:</p> <ul> <li><code>Python</code> - <code>load_csv(path=&amp;quot;path/to/my/file.csv&amp;quot;, header=True, row=&amp;quot;row&amp;quot;).return_().execute()</code></li> <li><code>Cypher</code> - <code>LOAD CSV FROM &amp;#x27;path/to/my/file.csv&amp;#x27; WITH HEADER AS row RETURN *;</code></li> </ul> <p>Load CSV without header:</p> <ul> <li><code>Python</code> - <code>load_csv(path=&amp;#x27;path/to/my/file.csv&amp;#x27;, header=False, row=&amp;#x27;row&amp;#x27;).return_().execute()</code></li> <li><code>Cypher</code> - <code>LOAD CSV FROM &amp;#x27;path/to/my/file.csv&amp;#x27; NO HEADER AS row RETURN *;</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/memgraph_query_builder/#call","title":"call","text":"<pre><code>def call(procedure: str,\n         arguments: Optional[Union[str, Tuple[Union[str, int, float]]]] = None,\n         node_labels: Optional[Union[str, List[List[str]]]] = None,\n         relationship_types: Optional[Union[str, List[List[str]]]] = None,\n         relationship_directions: Optional[\n             Union[RelationshipDirection,\n                   List[RelationshipDirection]]] = RelationshipDirection.RIGHT,\n         subgraph_path: str = None) -&gt; \"DeclarativeBase\"\n</code></pre> <p>Override of base class method to support Memgraph's subgraph functionality.</p> <p>Method can be called with node labels and relationship types, both being optional, which are used to construct a subgraph, or if neither is provided, a subgraph query is used, which can be passed as a string representing a Cypher query defining the MATCH clause which selects the nodes and relationships to use.</p> <p>Arguments:</p> <ul> <li><code>procedure</code> - A string representing the name of the procedure in the   format <code>query_module.procedure</code>.</li> <li><code>arguments</code> - A string representing the arguments of the procedure in   text format.</li> <li><code>node_labels</code> - Either a string, which is then used as the label for all nodes, or   a list of lists defining all labels for every node</li> <li><code>relationship_types</code> - Types of relationships to be used in the subgraph. Either a   single type or a list of lists defining all types for every relationship</li> <li><code>relationship_directions</code> - Directions of the relationships.</li> <li><code>subgraph_path</code> - Optional way to define the subgraph via a Cypher MATCH clause.</li> </ul> <p>Returns:</p> <p>A <code>DeclarativeBase</code> instance for constructing queries.</p> <p>Examples:</p> <ul> <li><code>Python</code> - `call('export_util.json', '/home/user', \"LABEL\", [\"TYPE1\", \"TYPE2\"]).execute()</li> <li><code>Cypher</code> - <code>MATCH p=(a)-[:TYPE1 | :TYPE2]-&amp;gt;(b) WHERE (a:LABEL) AND (b:LABEL)   WITH project(p) AS graph CALL export_util.json(graph, &amp;#x27;/home/user&amp;#x27;)</code></li> </ul> <p>or</p> <ul> <li><code>Python</code> - `call('export_util.json', '/home/user', subgraph_path=\"(:LABEL)-[:TYPE]-&gt;(:LABEL)\").execute()</li> <li><code>Cypher</code> - <code>MATCH p=(:LABEL)-[:TYPE1]-&amp;gt;(:LABEL) WITH project(p) AS graph   CALL export_util.json(graph, &amp;#x27;/home/user&amp;#x27;)</code></li> </ul>"},{"location":"reference/gqlalchemy/query_builders/memgraph_query_builder/#projectpartialquery-objects","title":"ProjectPartialQuery Objects","text":"<pre><code>class ProjectPartialQuery(PartialQuery)\n</code></pre>"},{"location":"reference/gqlalchemy/query_builders/memgraph_query_builder/#construct_query","title":"construct_query","text":"<pre><code>def construct_query() -&gt; str\n</code></pre> <p>Constructs a Project partial query.</p> <p>Given path part of a query (e.g. (:LABEL)-[:TYPE]-&gt;(:LABEL2)), adds MATCH, a path identifier and appends the WITH clause.</p>"},{"location":"reference/gqlalchemy/transformations/export/graph_transporter/","title":"graph_transporter","text":""},{"location":"reference/gqlalchemy/transformations/export/graph_transporter/#graphtransporter-objects","title":"GraphTransporter Objects","text":"<pre><code>class GraphTransporter(Transporter)\n</code></pre> <p>Here is a possible example for using this module: &gt;&gt;&gt; transporter = GraphTransporter(\"dgl\") graph = transporter.export()</p>"},{"location":"reference/gqlalchemy/transformations/export/graph_transporter/#__init__","title":"__init__","text":"<pre><code>def __init__(graph_type: str,\n             host: str = mg_consts.MG_HOST,\n             port: int = mg_consts.MG_PORT,\n             username: str = mg_consts.MG_USERNAME,\n             password: str = mg_consts.MG_PASSWORD,\n             encrypted: bool = mg_consts.MG_ENCRYPTED,\n             client_name: str = mg_consts.MG_CLIENT_NAME,\n             lazy: bool = mg_consts.MG_LAZY) -&gt; None\n</code></pre> <p>Initializes GraphTransporter. It is used for converting Memgraph graph to the specific graph type offered by some Python package (PyG, DGL, NX...) Here is a possible example for using this module: &gt;&gt;&gt; transporter = GraphTransporter(\"dgl\") graph = transporter.export()</p> <p>Arguments:</p> <ul> <li><code>graph_type</code> - dgl, pyg or nx</li> </ul>"},{"location":"reference/gqlalchemy/transformations/export/graph_transporter/#export","title":"export","text":"<pre><code>def export()\n</code></pre> <p>Creates graph instance for the wanted export option.</p>"},{"location":"reference/gqlalchemy/transformations/export/transporter/","title":"transporter","text":""},{"location":"reference/gqlalchemy/transformations/export/transporter/#transporter-objects","title":"Transporter Objects","text":"<pre><code>class Transporter(ABC)\n</code></pre>"},{"location":"reference/gqlalchemy/transformations/export/transporter/#export","title":"export","text":"<pre><code>@abstractmethod\ndef export(query_results)\n</code></pre> <p>Abstract method that will be overridden by subclasses that will know which correct graph type to create.</p> <p>Raises:</p> <ul> <li><code>NotImplementedError</code> - The method must be override by a specific translator.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/graph_importer/","title":"graph_importer","text":""},{"location":"reference/gqlalchemy/transformations/importing/graph_importer/#graphimporter-objects","title":"GraphImporter Objects","text":"<pre><code>class GraphImporter(Importer)\n</code></pre> <p>Imports dgl, pyg or networkx graph representations to Memgraph. The following code will suffice for importing queries. &gt;&gt;&gt; importer = GraphImporter(\"dgl\") graph = DGLGraph(...) importer.translate(graph)  # queries are inserted in this step</p> <p>Arguments:</p> <ul> <li><code>graph_type</code> - The type of the graph.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/graph_importer/#translate","title":"translate","text":"<pre><code>def translate(graph) -&gt; None\n</code></pre> <p>Gets cypher queries using the underlying translator and then inserts all queries to Memgraph DB.</p> <p>Arguments:</p> <ul> <li><code>graph</code> - dgl, pytorch geometric or nx graph instance.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/","title":"loaders","text":""},{"location":"reference/gqlalchemy/transformations/importing/loaders/#foreignkeymapping-objects","title":"ForeignKeyMapping Objects","text":"<pre><code>@dataclass(frozen=True)\nclass ForeignKeyMapping()\n</code></pre> <p>Class that contains the full description of a single foreign key in a table.</p> <p>Attributes:</p> <ul> <li><code>column_name</code> - Column name that holds the foreign key.</li> <li><code>reference_table</code> - Name of a table from which the foreign key is taken.</li> <li><code>reference_key</code> - Column name in the referenced table from which the foreign key is taken.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#onetomanymapping-objects","title":"OneToManyMapping Objects","text":"<pre><code>@dataclass(frozen=True)\nclass OneToManyMapping()\n</code></pre> <p>Class that holds the full description of a single one to many mapping in a table.</p> <p>Attributes:</p> <ul> <li><code>foreign_key</code> - Foreign key used for mapping.</li> <li><code>label</code> - Label which will be applied to the relationship created from this object.</li> <li><code>from_entity</code> - Direction of the relationship created from the mapping object.</li> <li><code>parameters</code> - Parameters that will be added to the relationship created from this object (Optional).</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#manytomanymapping-objects","title":"ManyToManyMapping Objects","text":"<pre><code>@dataclass(frozen=True)\nclass ManyToManyMapping()\n</code></pre> <p>Class that holds the full description of a single many to many mapping in a table. Many to many mapping is intended to be used in case of associative tables.</p> <p>Attributes:</p> <ul> <li><code>foreign_key_from</code> - Describes the source of the relationship.</li> <li><code>foreign_key_to</code> - Describes the destination of the relationship.</li> <li><code>label</code> - Label to be applied to the newly created relationship.</li> <li><code>parameters</code> - Parameters that will be added to the relationship created from this object (Optional).</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#tablemapping-objects","title":"TableMapping Objects","text":"<pre><code>@dataclass\nclass TableMapping()\n</code></pre> <p>Class that holds the full description of all of the mappings for a single table.</p> <p>Attributes:</p> <ul> <li><code>table_name</code> - Name of the table.</li> <li><code>mapping</code> - All of the mappings in the table (Optional).</li> <li><code>indices</code> - List of the indices to be created for this table (Optional).</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#namemappings-objects","title":"NameMappings Objects","text":"<pre><code>@dataclass(frozen=True)\nclass NameMappings()\n</code></pre> <p>Class that contains new label name and all of the column name mappings for a single table.</p> <p>Attributes:</p> <ul> <li><code>label</code> - New label (Optional).</li> <li><code>column_names_mapping</code> - Dictionary containing key-value pairs in form (\"column name\", \"property name\") (Optional).</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#namemapper-objects","title":"NameMapper Objects","text":"<pre><code>class NameMapper()\n</code></pre> <p>Class that holds all name mappings for all of the collections.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#get_label","title":"get_label","text":"<pre><code>def get_label(collection_name: str) -&gt; str\n</code></pre> <p>Returns label for given collection.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Original collection name.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#get_property_name","title":"get_property_name","text":"<pre><code>def get_property_name(collection_name: str, column_name: str) -&gt; str\n</code></pre> <p>Returns property name for column from collection.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Original collection name.</li> <li><code>column_name</code> - Original column name.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#filesystemhandler-objects","title":"FileSystemHandler Objects","text":"<pre><code>class FileSystemHandler(ABC)\n</code></pre> <p>Abstract class for defining FileSystemHandler.</p> <p>Inherit this class, define a custom data source and initialize the connection.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#get_path","title":"get_path","text":"<pre><code>@abstractmethod\ndef get_path(collection_name: str) -&gt; str\n</code></pre> <p>Returns complete path in specific file system. Used to read the file system for a specific file.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#s3filesystemhandler-objects","title":"S3FileSystemHandler Objects","text":"<pre><code>class S3FileSystemHandler(FileSystemHandler)\n</code></pre> <p>Handles connection to Amazon S3 service via PyArrow.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init__","title":"__init__","text":"<pre><code>def __init__(bucket_name: str, **kwargs)\n</code></pre> <p>Initializes connection and data bucket.</p> <p>Arguments:</p> <ul> <li><code>bucket_name</code> - Name of the bucket on S3 from which to read the data</li> </ul> <p>Kwargs: - <code>access_key</code> - S3 access key. - <code>secret_key</code> - S3 secret key. - <code>region</code> - S3 region. - <code>session_token</code> - S3 session token (Optional).</p> <p>Raises:</p> <ul> <li><code>KeyError</code> - kwargs doesn't contain necessary fields.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#get_path_1","title":"get_path","text":"<pre><code>def get_path(collection_name: str) -&gt; str\n</code></pre> <p>Get file path in file system.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Name of the file to read.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#azureblobfilesystemhandler-objects","title":"AzureBlobFileSystemHandler Objects","text":"<pre><code>class AzureBlobFileSystemHandler(FileSystemHandler)\n</code></pre> <p>Handles connection to Azure Blob service via adlfs package.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___1","title":"__init__","text":"<pre><code>def __init__(container_name: str, **kwargs) -&gt; None\n</code></pre> <p>Initializes connection and data container.</p> <p>Arguments:</p> <ul> <li><code>container_name</code> - Name of the Blob container storing data.</li> </ul> <p>Kwargs: - <code>account_name</code> - Account name from Azure Blob. - <code>account_key</code> - Account key for Azure Blob (Optional - if using sas_token). - <code>sas_token</code> - Shared access signature token for authentication (Optional).</p> <p>Raises:</p> <ul> <li><code>KeyError</code> - kwargs doesn't contain necessary fields.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#get_path_2","title":"get_path","text":"<pre><code>def get_path(collection_name: str) -&gt; str\n</code></pre> <p>Get file path in file system.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Name of the file to read.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#localfilesystemhandler-objects","title":"LocalFileSystemHandler Objects","text":"<pre><code>class LocalFileSystemHandler(FileSystemHandler)\n</code></pre> <p>Handles a local filesystem.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___2","title":"__init__","text":"<pre><code>def __init__(path: str) -&gt; None\n</code></pre> <p>Initializes an fsspec local file system and sets path to data.</p> <p>Arguments:</p> <ul> <li><code>path</code> - path to the local storage location.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#get_path_3","title":"get_path","text":"<pre><code>def get_path(collection_name: str) -&gt; str\n</code></pre> <p>Get file path in the local file system.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Name of the file to read.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#dataloader-objects","title":"DataLoader Objects","text":"<pre><code>class DataLoader(ABC)\n</code></pre> <p>Implements loading of a data type from file system service to TableToGraphImporter.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___3","title":"__init__","text":"<pre><code>def __init__(file_extension: str,\n             file_system_handler: FileSystemHandler) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>file_extension</code> - File format to be read.</li> <li><code>file_system_handler</code> - Object for handling of the file system service.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#load_data","title":"load_data","text":"<pre><code>@abstractmethod\ndef load_data(collection_name: str, is_cross_table: bool = False) -&gt; None\n</code></pre> <p>Override this method in the derived class. Intended to be used for reading data from data format.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Name of the file to read.</li> <li><code>is_cross_table</code> - Indicate whether or not the collection contains associative table (default=False).</li> </ul> <p>Raises:</p> <ul> <li><code>NotImplementedError</code> - The method is not implemented in the extended class.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#pyarrowfiletypeenum-objects","title":"PyArrowFileTypeEnum Objects","text":"<pre><code>class PyArrowFileTypeEnum(Enum)\n</code></pre> <p>Enumerates file types supported by PyArrow</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#pyarrowdataloader-objects","title":"PyArrowDataLoader Objects","text":"<pre><code>class PyArrowDataLoader(DataLoader)\n</code></pre> <p>Loads data using PyArrow.</p> <p>PyArrow currently supports \"parquet\", \"ipc\"/\"arrow\"/\"feather\", \"csv\", and \"orc\", see pyarrow.dataset.dataset for up-to-date info. ds.dataset in load_data accepts any fsspec subclass, making this DataLoader compatible with fsspec-compatible filesystems.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___4","title":"__init__","text":"<pre><code>def __init__(file_extension_enum: PyArrowFileTypeEnum,\n             file_system_handler: FileSystemHandler) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>file_extension_enum</code> - The file format to be read.</li> <li><code>file_system_handler</code> - Object for handling of the file system service.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#load_data_1","title":"load_data","text":"<pre><code>def load_data(collection_name: str,\n              is_cross_table: bool = False,\n              columns: Optional[List[str]] = None) -&gt; None\n</code></pre> <p>Generator for loading data.</p> <p>Arguments:</p> <ul> <li><code>collection_name</code> - Name of the file to read.</li> <li><code>is_cross_table</code> - Flag signifying whether it is a cross table.</li> <li><code>columns</code> - Table columns to read.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#tabletographimporter-objects","title":"TableToGraphImporter Objects","text":"<pre><code>class TableToGraphImporter(Importer)\n</code></pre> <p>Implements translation of table data to graph data, and imports it to Memgraph.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___5","title":"__init__","text":"<pre><code>def __init__(data_loader: DataLoader,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>data_loader</code> - Object for loading data.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#translate","title":"translate","text":"<pre><code>def translate(drop_database_on_start: bool = True) -&gt; None\n</code></pre> <p>Performs the translations.</p> <p>Arguments:</p> <ul> <li><code>drop_database_on_start</code> - Indicate whether or not the database should be dropped prior to the start of the translations.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#pyarrowimporter-objects","title":"PyArrowImporter Objects","text":"<pre><code>class PyArrowImporter(TableToGraphImporter)\n</code></pre> <p>TableToGraphImporter wrapper for use with PyArrow for reading data.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___6","title":"__init__","text":"<pre><code>def __init__(file_system_handler: str,\n             file_extension_enum: PyArrowFileTypeEnum,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>file_system_handler</code> - File system to read from.</li> <li><code>file_extension_enum</code> - File format to be read.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code> - PyArrow doesn't support ORC on Windows.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#pyarrows3importer-objects","title":"PyArrowS3Importer Objects","text":"<pre><code>class PyArrowS3Importer(PyArrowImporter)\n</code></pre> <p>PyArrowImporter wrapper for use with the Amazon S3 File System.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___7","title":"__init__","text":"<pre><code>def __init__(bucket_name: str,\n             file_extension_enum: PyArrowFileTypeEnum,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>bucket_name</code> - Name of the bucket in S3 to read from.</li> <li><code>file_extension_enum</code> - File format to be read.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for S3FileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#pyarrowazureblobimporter-objects","title":"PyArrowAzureBlobImporter Objects","text":"<pre><code>class PyArrowAzureBlobImporter(PyArrowImporter)\n</code></pre> <p>PyArrowImporter wrapper for use with the Azure Blob File System.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___8","title":"__init__","text":"<pre><code>def __init__(container_name: str,\n             file_extension_enum: PyArrowFileTypeEnum,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>container_name</code> - Name of the container in Azure Blob to read from.</li> <li><code>file_extension_enum</code> - File format to be read.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for AzureBlobFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#pyarrowlocalfilesystemimporter-objects","title":"PyArrowLocalFileSystemImporter Objects","text":"<pre><code>class PyArrowLocalFileSystemImporter(PyArrowImporter)\n</code></pre> <p>PyArrowImporter wrapper for use with the Local File System.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___9","title":"__init__","text":"<pre><code>def __init__(path: str,\n             file_extension_enum: PyArrowFileTypeEnum,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>path</code> - Full path to the directory to read from.</li> <li><code>file_extension_enum</code> - File format to be read.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#parquets3filesystemimporter-objects","title":"ParquetS3FileSystemImporter Objects","text":"<pre><code>class ParquetS3FileSystemImporter(PyArrowS3Importer)\n</code></pre> <p>PyArrowS3Importer wrapper for use with the S3 file system and the parquet file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___10","title":"__init__","text":"<pre><code>def __init__(bucket_name: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>bucket_name</code> - Name of the bucket in S3 to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for S3FileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#csvs3filesystemimporter-objects","title":"CSVS3FileSystemImporter Objects","text":"<pre><code>class CSVS3FileSystemImporter(PyArrowS3Importer)\n</code></pre> <p>PyArrowS3Importer wrapper for use with the S3 file system and the CSV file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___11","title":"__init__","text":"<pre><code>def __init__(bucket_name: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>bucket_name</code> - Name of the bucket in S3 to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for S3FileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#orcs3filesystemimporter-objects","title":"ORCS3FileSystemImporter Objects","text":"<pre><code>class ORCS3FileSystemImporter(PyArrowS3Importer)\n</code></pre> <p>PyArrowS3Importer wrapper for use with the S3 file system and the ORC file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___12","title":"__init__","text":"<pre><code>def __init__(bucket_name: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>bucket_name</code> - Name of the bucket in S3 to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for S3FileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#feathers3filesystemimporter-objects","title":"FeatherS3FileSystemImporter Objects","text":"<pre><code>class FeatherS3FileSystemImporter(PyArrowS3Importer)\n</code></pre> <p>PyArrowS3Importer wrapper for use with the S3 file system and the feather file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___13","title":"__init__","text":"<pre><code>def __init__(bucket_name: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>bucket_name</code> - Name of the bucket in S3 to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for S3FileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#parquetazureblobfilesystemimporter-objects","title":"ParquetAzureBlobFileSystemImporter Objects","text":"<pre><code>class ParquetAzureBlobFileSystemImporter(PyArrowAzureBlobImporter)\n</code></pre> <p>PyArrowAzureBlobImporter wrapper for use with the Azure Blob file system and the parquet file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___14","title":"__init__","text":"<pre><code>def __init__(container_name: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>container_name</code> - Name of the container in Azure Blob storage to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for AzureBlobFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#csvazureblobfilesystemimporter-objects","title":"CSVAzureBlobFileSystemImporter Objects","text":"<pre><code>class CSVAzureBlobFileSystemImporter(PyArrowAzureBlobImporter)\n</code></pre> <p>PyArrowAzureBlobImporter wrapper for use with the Azure Blob file system and the CSV file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___15","title":"__init__","text":"<pre><code>def __init__(container_name: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>container_name</code> - Name of the container in Azure Blob storage to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for AzureBlobFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#orcazureblobfilesystemimporter-objects","title":"ORCAzureBlobFileSystemImporter Objects","text":"<pre><code>class ORCAzureBlobFileSystemImporter(PyArrowAzureBlobImporter)\n</code></pre> <p>PyArrowAzureBlobImporter wrapper for use with the Azure Blob file system and the CSV file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___16","title":"__init__","text":"<pre><code>def __init__(container_name,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>container_name</code> - Name of the container in Blob storage to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for AzureBlobFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#featherazureblobfilesystemimporter-objects","title":"FeatherAzureBlobFileSystemImporter Objects","text":"<pre><code>class FeatherAzureBlobFileSystemImporter(PyArrowAzureBlobImporter)\n</code></pre> <p>PyArrowAzureBlobImporter wrapper for use with the Azure Blob file system and the Feather file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___17","title":"__init__","text":"<pre><code>def __init__(container_name,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None,\n             **kwargs) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>container_name</code> - Name of the container in Blob storage to read from.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for AzureBlobFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#parquetlocalfilesystemimporter-objects","title":"ParquetLocalFileSystemImporter Objects","text":"<pre><code>class ParquetLocalFileSystemImporter(PyArrowLocalFileSystemImporter)\n</code></pre> <p>PyArrowLocalFileSystemImporter wrapper for use with the local file system and the parquet file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___18","title":"__init__","text":"<pre><code>def __init__(path: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>path</code> - Full path to directory.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for LocalFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#csvlocalfilesystemimporter-objects","title":"CSVLocalFileSystemImporter Objects","text":"<pre><code>class CSVLocalFileSystemImporter(PyArrowLocalFileSystemImporter)\n</code></pre> <p>PyArrowLocalFileSystemImporter wrapper for use with the local file system and the CSV file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___19","title":"__init__","text":"<pre><code>def __init__(path: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>path</code> - Full path to directory.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for LocalFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#orclocalfilesystemimporter-objects","title":"ORCLocalFileSystemImporter Objects","text":"<pre><code>class ORCLocalFileSystemImporter(PyArrowLocalFileSystemImporter)\n</code></pre> <p>PyArrowLocalFileSystemImporter wrapper for use with the local file system and the ORC file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___20","title":"__init__","text":"<pre><code>def __init__(path: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>path</code> - Full path to directory.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for LocalFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#featherlocalfilesystemimporter-objects","title":"FeatherLocalFileSystemImporter Objects","text":"<pre><code>class FeatherLocalFileSystemImporter(PyArrowLocalFileSystemImporter)\n</code></pre> <p>PyArrowLocalFileSystemImporter wrapper for use with the local file system and the Feather/IPC/Arrow file type.</p>"},{"location":"reference/gqlalchemy/transformations/importing/loaders/#__init___21","title":"__init__","text":"<pre><code>def __init__(path: str,\n             data_configuration: Dict[str, Any],\n             memgraph: Optional[Memgraph] = None) -&gt; None\n</code></pre> <p>Arguments:</p> <ul> <li><code>path</code> - Full path to directory.</li> <li><code>data_configuration</code> - Configuration for the translations.</li> <li><code>memgraph</code> - Connection to Memgraph (Optional).</li> <li><code>**kwargs</code> - Specified for LocalFileSystem.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/translators/dgl_translator/","title":"dgl_translator","text":""},{"location":"reference/gqlalchemy/transformations/translators/dgl_translator/#dgltranslator-objects","title":"DGLTranslator Objects","text":"<pre><code>class DGLTranslator(Translator)\n</code></pre> <p>Performs conversion from cypher queries to the DGL graph representation. DGL assigns to each edge a unique integer, called the edge ID, based on the order in which it was added to the graph. In DGL, all the edges are directed, and an edge (u,v) indicates that the direction goes from node u to node v. Only features of numerical types (e.g., float, double, and int) are allowed. They can be scalars, vectors or multi-dimensional tensors (DGL requirement). Each node feature has a unique name and each edge feature has a unique name. The features of nodes and edges can have the same name. A feature is created via tensor assignment, which assigns a feature to each node/edge in the graph. The leading dimension of that tensor must be equal to the number of nodes/edges in the graph. You cannot assign a feature to a subset of the nodes/edges in the graph. Features of the same name must have the same dimensionality and data type.</p>"},{"location":"reference/gqlalchemy/transformations/translators/dgl_translator/#to_cypher_queries","title":"to_cypher_queries","text":"<pre><code>def to_cypher_queries(graph: Union[dgl.DGLGraph, dgl.DGLHeteroGraph])\n</code></pre> <p>Produce cypher queries for data saved as part of the DGL graph. The method handles both homogeneous and heterogeneous graph. If the graph is homogeneous, a default DGL's labels will be used. _N as a node label and _E as edge label. The method converts 1D as well as multidimensional features. If there are some isolated nodes inside DGL graph, they won't get transferred. Nodes and edges created in Memgraph DB will, for the consistency reasons, have property <code>dgl_id</code> set to the id they have as part of the DGL graph. Note that this method doesn't insert anything inside the database, it just creates cypher queries. To insert queries the following code can be used: &gt;&gt;&gt; memgraph = Memgraph() dgl_graph = DGLGraph(...) for query in DGLTranslator().to_cypher_queries(dgl_graph): memgraph.execute(query)</p> <p>Arguments:</p> <ul> <li><code>graph</code> - A reference to the DGL graph.</li> </ul> <p>Returns:</p> <p>cypher queries.</p>"},{"location":"reference/gqlalchemy/transformations/translators/dgl_translator/#get_instance","title":"get_instance","text":"<pre><code>def get_instance() -&gt; dgl.DGLHeteroGraph\n</code></pre> <p>Create instance of DGL graph from all edges that are inside Memgraph. Currently, isolated nodes are ignored because they don't contribute in message passing neural networks. Only numerical features that are set on all nodes or all edges are transferred to the DGL instance since this is DGL's requirement. That means that any string values properties won't be transferred, as well as numerical properties that aren't set on all nodes. However, features of type list are transferred to the DGL and can be used as any other feature in the DGL graph. Regardless of data residing inside Memgraph database, the created DGL graph is a heterograph instance.</p> <p>Returns:</p> <p>DGL heterograph instance.</p>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/","title":"nx_translator","text":""},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#networkxcypherbuilder-objects","title":"NetworkXCypherBuilder Objects","text":"<pre><code>class NetworkXCypherBuilder()\n</code></pre>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#yield_queries","title":"yield_queries","text":"<pre><code>def yield_queries(graph: nx.Graph) -&gt; Iterator[str]\n</code></pre> <p>Generates Cypher queries for creating a graph.</p>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#yield_query_groups","title":"yield_query_groups","text":"<pre><code>def yield_query_groups(graph: nx.Graph) -&gt; List[Iterator[str]]\n</code></pre> <p>Generates Cypher queries for creating a graph by query groups.</p>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#nxtranslator-objects","title":"NxTranslator Objects","text":"<pre><code>class NxTranslator(Translator)\n</code></pre> <p>Uses original ids from Memgraph. Labels are encoded as properties. Since NetworkX allows that nodes have properties of different dimensionality, this modules makes use of it and stores properties as dictionary entries. All properties are saved to NetworkX data structure.</p>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#to_cypher_queries","title":"to_cypher_queries","text":"<pre><code>def to_cypher_queries(graph: nx.Graph,\n                      config: NetworkXCypherConfig = None) -&gt; Iterator[str]\n</code></pre> <p>Generates a Cypher query for creating a graph.</p>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#nx_graph_to_memgraph_parallel","title":"nx_graph_to_memgraph_parallel","text":"<pre><code>def nx_graph_to_memgraph_parallel(graph: nx.Graph,\n                                  config: NetworkXCypherConfig = None) -&gt; None\n</code></pre> <p>Generates Cypher queries and inserts data into Memgraph in parallel.</p>"},{"location":"reference/gqlalchemy/transformations/translators/nx_translator/#get_instance","title":"get_instance","text":"<pre><code>def get_instance()\n</code></pre> <p>Creates NetworkX instance of the graph from the data residing inside Memgraph. Since NetworkX doesn't support labels in a way Memgraph does, labels are encoded as a node and edge properties.</p>"},{"location":"reference/gqlalchemy/transformations/translators/pyg_translator/","title":"pyg_translator","text":""},{"location":"reference/gqlalchemy/transformations/translators/pyg_translator/#pygtranslator-objects","title":"PyGTranslator Objects","text":"<pre><code>class PyGTranslator(Translator)\n</code></pre>"},{"location":"reference/gqlalchemy/transformations/translators/pyg_translator/#get_node_properties","title":"get_node_properties","text":"<pre><code>@classmethod\ndef get_node_properties(cls, graph, node_label: str, node_id: int)\n</code></pre> <p>Extracts node properties from heterogeneous graph based on the node_label.</p> <p>Arguments:</p> <ul> <li><code>graph</code> - A reference to the PyG graph.</li> <li><code>node_label</code> - Node label</li> <li><code>node_id</code> - Node_id</li> </ul>"},{"location":"reference/gqlalchemy/transformations/translators/pyg_translator/#extract_node_edge_properties_from_homogeneous_graph","title":"extract_node_edge_properties_from_homogeneous_graph","text":"<pre><code>@classmethod\ndef extract_node_edge_properties_from_homogeneous_graph(cls, graph)\n</code></pre> <p>Homogenous graph don't have node and etype properties so it is hard to extract node and edge attributes.</p> <p>Arguments:</p> <ul> <li><code>graph</code> - Data = reference to the PyG graph.</li> </ul> <p>Returns:</p> <p>node and edge attributes as dictionaries</p>"},{"location":"reference/gqlalchemy/transformations/translators/pyg_translator/#to_cypher_queries","title":"to_cypher_queries","text":"<pre><code>def to_cypher_queries(graph)\n</code></pre> <p>Produce cypher queries for data saved as part of thePyG graph. The method handles both homogeneous and heterogeneous graph. The method converts 1D as well as multidimensional features. If there are some isolated nodes inside the graph, they won't get transferred. Nodes and edges created in Memgraph DB will, for the consistency reasons, have property <code>pyg_id</code> set to the id they have as part of the PyG graph. Note that this method doesn't insert anything inside the database, it just creates cypher queries. To insert queries the following code can be used: &gt;&gt;&gt; memgraph = Memgraph() pyg_graph = HeteroData(...) for query in PyGTranslator().to_cypher_queries(pyg_graph): memgraph.execute(query)</p> <p>Arguments:</p> <ul> <li><code>graph</code> - A reference to the PyG graph.</li> </ul> <p>Returns:</p> <p>cypher queries.</p>"},{"location":"reference/gqlalchemy/transformations/translators/pyg_translator/#get_instance","title":"get_instance","text":"<pre><code>def get_instance()\n</code></pre> <p>Create instance of PyG graph from all edges that are inside Memgraph. Currently, isolated nodes are ignored because they don't contribute in message passing neural networks. Only numerical features that are set on all nodes or all edges are transferred to the PyG instance since this is PyG's requirement. That means that any string values properties won't be transferred, as well as numerical properties that aren't set on all nodes. However, features that are of type list are transferred to the PyG instance and can be used as any other feature in the PyG graph. Regardless of data residing inside Memgraph database, the created PyG graph is a heterograph instance.</p> <p>Returns:</p> <p>PyG heterograph instance.</p>"},{"location":"reference/gqlalchemy/transformations/translators/translator/","title":"translator","text":""},{"location":"reference/gqlalchemy/transformations/translators/translator/#translator-objects","title":"Translator Objects","text":"<pre><code>class Translator(ABC)\n</code></pre>"},{"location":"reference/gqlalchemy/transformations/translators/translator/#to_cypher_queries","title":"to_cypher_queries","text":"<pre><code>@abstractmethod\ndef to_cypher_queries(graph)\n</code></pre> <p>Abstract method which doesn't know how to produce cypher queries for a specific graph type and thus needs to be overridden.</p> <p>Arguments:</p> <ul> <li><code>graph</code> - Can be of any type supported by the derived Translator object.</li> </ul> <p>Raises:</p> <ul> <li><code>NotImplementedError</code> - The method must be override by a specific translator.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/translators/translator/#get_instance","title":"get_instance","text":"<pre><code>@abstractmethod\ndef get_instance()\n</code></pre> <p>Abstract method which doesn't know how to create the concrete instance so it needs to be overridden.</p> <p>Raises:</p> <ul> <li><code>NotImplementedError</code> - The method must be override by a specific translator.</li> </ul>"},{"location":"reference/gqlalchemy/transformations/translators/translator/#validate_features","title":"validate_features","text":"<pre><code>@classmethod\ndef validate_features(cls, features: List, expected_num: int)\n</code></pre> <p>Return true if features are okay to be set on all nodes/features.</p> <p>Arguments:</p> <ul> <li><code>features</code> - To be set on all nodes. It can be anything that can be converted to torch tensor.</li> <li><code>expected_num</code> - This can be number of nodes or number of edges depending on whether features will be set on nodes or edges.</li> </ul> <p>Returns:</p> <p>None if features cannot be set or tensor of same features.</p>"},{"location":"reference/gqlalchemy/transformations/translators/translator/#get_all_edges_from_db","title":"get_all_edges_from_db","text":"<pre><code>def get_all_edges_from_db()\n</code></pre> <p>Returns all edges from the database.</p> <p>Returns:</p> <p>Query results when finding all edges.</p>"},{"location":"reference/gqlalchemy/transformations/translators/translator/#get_all_isolated_nodes_from_db","title":"get_all_isolated_nodes_from_db","text":"<pre><code>def get_all_isolated_nodes_from_db()\n</code></pre> <p>Returns all isolated nodes from the database.</p> <p>Returns:</p> <p>Query results for finding all isolated nodes.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/","title":"database_client","text":""},{"location":"reference/gqlalchemy/vendors/database_client/#databaseclient-objects","title":"DatabaseClient Objects","text":"<pre><code>class DatabaseClient(ABC)\n</code></pre>"},{"location":"reference/gqlalchemy/vendors/database_client/#execute_and_fetch","title":"execute_and_fetch","text":"<pre><code>def execute_and_fetch(\n        query: str,\n        parameters: Dict[str, Any] = {},\n        connection: Connection = None) -&gt; Iterator[Dict[str, Any]]\n</code></pre> <p>Executes Cypher query and returns iterator of results.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#execute","title":"execute","text":"<pre><code>def execute(query: str,\n            parameters: Dict[str, Any] = {},\n            connection: Connection = None) -&gt; None\n</code></pre> <p>Executes Cypher query without returning any results.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#create_index","title":"create_index","text":"<pre><code>def create_index(index: Index) -&gt; None\n</code></pre> <p>Creates an index (label or label-property type) in the database.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#drop_index","title":"drop_index","text":"<pre><code>def drop_index(index: Index) -&gt; None\n</code></pre> <p>Drops an index (label or label-property type) in the database.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#get_indexes","title":"get_indexes","text":"<pre><code>@abstractmethod\ndef get_indexes() -&gt; List[Index]\n</code></pre> <p>Returns a list of all database indexes (label and label-property types).</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#ensure_indexes","title":"ensure_indexes","text":"<pre><code>@abstractmethod\ndef ensure_indexes(indexes: List[Index]) -&gt; None\n</code></pre> <p>Ensures that database indexes match input indexes.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#drop_indexes","title":"drop_indexes","text":"<pre><code>def drop_indexes() -&gt; None\n</code></pre> <p>Drops all indexes in the database</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#create_constraint","title":"create_constraint","text":"<pre><code>def create_constraint(index: Constraint) -&gt; None\n</code></pre> <p>Creates a constraint (label or label-property type) in the database.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#drop_constraint","title":"drop_constraint","text":"<pre><code>def drop_constraint(index: Constraint) -&gt; None\n</code></pre> <p>Drops a constraint (label or label-property type) in the database.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#get_constraints","title":"get_constraints","text":"<pre><code>@abstractmethod\ndef get_constraints() -&gt; List[Constraint]\n</code></pre> <p>Returns a list of all database constraints (label and label-property types).</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#ensure_constraints","title":"ensure_constraints","text":"<pre><code>def ensure_constraints(constraints: List[Constraint]) -&gt; None\n</code></pre> <p>Ensures that database constraints match input constraints.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#drop_database","title":"drop_database","text":"<pre><code>def drop_database()\n</code></pre> <p>Drops database by removing all nodes and edges.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#new_connection","title":"new_connection","text":"<pre><code>@abstractmethod\ndef new_connection() -&gt; Connection\n</code></pre> <p>Creates new database connection.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#get_variable_assume_one","title":"get_variable_assume_one","text":"<pre><code>def get_variable_assume_one(query_result: Iterator[Dict[str, Any]],\n                            variable_name: str) -&gt; Any\n</code></pre> <p>Returns a single result from the query_result (usually gotten from the execute_and_fetch function). If there is more than one result, raises a GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#create_node","title":"create_node","text":"<pre><code>def create_node(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Creates a node in database from the <code>node</code> object.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#save_node","title":"save_node","text":"<pre><code>@abstractmethod\ndef save_node(node: Node) -&gt; Node\n</code></pre> <p>Saves node to database. If the node._id is not None, it fetches the node with the same id from the database and updates it's fields. If the node has unique fields it fetches the nodes with the same unique fields from the database and updates it's fields. Otherwise it creates a new node with the same properties. Null properties are ignored.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#save_nodes","title":"save_nodes","text":"<pre><code>def save_nodes(nodes: List[Node]) -&gt; None\n</code></pre> <p>Saves a list of nodes to the database.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#save_node_with_id","title":"save_node_with_id","text":"<pre><code>def save_node_with_id(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Saves a node to the database using the internal id.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#load_node","title":"load_node","text":"<pre><code>@abstractmethod\ndef load_node(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Loads a node from the database. If the node._id is not None, it fetches the node from the database with that internal id. If the node has unique fields it fetches the node from the database with those unique fields set. Otherwise it tries to find any node in the database that has all properties set to exactly the same values. If no node is found or no properties are set it raises a GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#load_node_with_all_properties","title":"load_node_with_all_properties","text":"<pre><code>def load_node_with_all_properties(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Loads a node from the database with all equal property values.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#load_node_with_id","title":"load_node_with_id","text":"<pre><code>def load_node_with_id(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Loads a node with the same internal database id.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#load_relationship","title":"load_relationship","text":"<pre><code>@abstractmethod\ndef load_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Returns a relationship loaded from the database. If the relationship._id is not None, it fetches the relationship from the database that has the same internal id. Otherwise it returns the relationship whose relationship._start_node_id and relationship._end_node_id and all relationship properties that are not None match the relationship in the database. If there is no relationship like that in database, or if there are multiple relationships like that in database, throws GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#load_relationship_with_id","title":"load_relationship_with_id","text":"<pre><code>def load_relationship_with_id(\n        relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Loads a relationship from the database using the internal id.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#load_relationship_with_start_node_id_and_end_node_id","title":"load_relationship_with_start_node_id_and_end_node_id","text":"<pre><code>def load_relationship_with_start_node_id_and_end_node_id(\n        relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Loads a relationship from the database using start node and end node id for which all properties of the relationship that are not None match.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#save_relationship","title":"save_relationship","text":"<pre><code>@abstractmethod\ndef save_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Saves a relationship to the database. If relationship._id is not None it finds the relationship in the database and updates it's properties with the values in <code>relationship</code>. If relationship._id is None, it creates a new relationship. If you want to set a relationship._id instead of creating a new relationship, use <code>load_relationship</code> first.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#save_relationships","title":"save_relationships","text":"<pre><code>def save_relationships(relationships: List[Relationship]) -&gt; None\n</code></pre> <p>Saves a list of relationships to the database.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#save_relationship_with_id","title":"save_relationship_with_id","text":"<pre><code>def save_relationship_with_id(\n        relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Saves a relationship to the database using the relationship._id.</p>"},{"location":"reference/gqlalchemy/vendors/database_client/#create_relationship","title":"create_relationship","text":"<pre><code>def create_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Creates a new relationship in the database.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/","title":"memgraph","text":""},{"location":"reference/gqlalchemy/vendors/memgraph/#memgraph-objects","title":"Memgraph Objects","text":"<pre><code>class Memgraph(DatabaseClient)\n</code></pre>"},{"location":"reference/gqlalchemy/vendors/memgraph/#get_indexes","title":"get_indexes","text":"<pre><code>def get_indexes() -&gt; List[MemgraphIndex]\n</code></pre> <p>Returns a list of all database indexes (label and label-property types).</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#ensure_indexes","title":"ensure_indexes","text":"<pre><code>def ensure_indexes(indexes: List[MemgraphIndex]) -&gt; None\n</code></pre> <p>Ensures that database indexes match input indexes.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#get_constraints","title":"get_constraints","text":"<pre><code>def get_constraints(\n) -&gt; List[Union[MemgraphConstraintExists, MemgraphConstraintUnique]]\n</code></pre> <p>Returns a list of all database constraints (label and label-property types).</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#new_connection","title":"new_connection","text":"<pre><code>def new_connection() -&gt; Connection\n</code></pre> <p>Creates new Memgraph connection.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#create_stream","title":"create_stream","text":"<pre><code>def create_stream(stream: MemgraphStream) -&gt; None\n</code></pre> <p>Create a stream.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#start_stream","title":"start_stream","text":"<pre><code>def start_stream(stream: MemgraphStream) -&gt; None\n</code></pre> <p>Start a stream.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#get_streams","title":"get_streams","text":"<pre><code>def get_streams() -&gt; List[str]\n</code></pre> <p>Returns a list of all streams.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#drop_stream","title":"drop_stream","text":"<pre><code>def drop_stream(stream: MemgraphStream) -&gt; None\n</code></pre> <p>Drop a stream.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#create_trigger","title":"create_trigger","text":"<pre><code>def create_trigger(trigger: MemgraphTrigger) -&gt; None\n</code></pre> <p>Creates a trigger.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#get_triggers","title":"get_triggers","text":"<pre><code>def get_triggers() -&gt; List[MemgraphTrigger]\n</code></pre> <p>Returns a list of all database triggers.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#drop_trigger","title":"drop_trigger","text":"<pre><code>def drop_trigger(trigger: MemgraphTrigger) -&gt; None\n</code></pre> <p>Drop a trigger.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#drop_triggers","title":"drop_triggers","text":"<pre><code>def drop_triggers() -&gt; None\n</code></pre> <p>Drops all triggers in the database.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#init_disk_storage","title":"init_disk_storage","text":"<pre><code>def init_disk_storage(on_disk_db: OnDiskPropertyDatabase) -&gt; None\n</code></pre> <p>Adds and OnDiskPropertyDatabase to the database so that any property that has a Field(on_disk=True) can be stored to and loaded from an OnDiskPropertyDatabase.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#remove_on_disk_storage","title":"remove_on_disk_storage","text":"<pre><code>def remove_on_disk_storage() -&gt; None\n</code></pre> <p>Removes the OnDiskPropertyDatabase from the database.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#save_node","title":"save_node","text":"<pre><code>def save_node(node: Node) -&gt; Node\n</code></pre> <p>Saves node to the database. If the node._id is not None it fetches the node with the same id from the database and updates it's fields. If the node has unique fields it fetches the nodes with the same unique fields from the database and updates it's fields. Otherwise it creates a new node with the same properties. Null properties are ignored.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#load_node","title":"load_node","text":"<pre><code>def load_node(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Loads a node from the database. If the node._id is not None it fetches the node from the database with that internal id. If the node has unique fields it fetches the node from the database with those unique fields set. Otherwise it tries to find any node in the database that has all properties set to exactly the same values. If no node is found or no properties are set it raises a GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#load_relationship","title":"load_relationship","text":"<pre><code>def load_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Returns a relationship loaded from the database. If the relationship._id is not None it fetches the relationship from the database that has the same internal id. Otherwise it returns the relationship whose relationship._start_node_id and relationship._end_node_id and all relationship properties that are not None match the relationship in the database. If there is no relationship like that in the database, or if there are multiple relationships like that in the database, throws GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#save_relationship","title":"save_relationship","text":"<pre><code>def save_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Saves a relationship to the database. If relationship._id is not None it finds the relationship in the database and updates it's properties with the values in <code>relationship</code>. If relationship._id is None, it creates a new relationship. If you want to set a relationship._id instead of creating a new relationship, use <code>load_relationship</code> first.</p>"},{"location":"reference/gqlalchemy/vendors/memgraph/#get_procedures","title":"get_procedures","text":"<pre><code>def get_procedures(starts_with: Optional[str] = None,\n                   update: bool = False) -&gt; List[\"QueryModule\"]\n</code></pre> <p>Return query procedures.</p> <p>Maintains a list of query modules in the Memgraph object. If starts_with is defined then return those modules that start with starts_with string.</p> <p>Arguments:</p> <ul> <li><code>starts_with</code> - Return those modules that start with this string.   (Optional)</li> <li><code>update</code> - Whether to update the list of modules in   self.query_modules. (Optional)</li> </ul>"},{"location":"reference/gqlalchemy/vendors/memgraph/#add_query_module","title":"add_query_module","text":"<pre><code>def add_query_module(file_path: str, module_name: str) -&gt; \"Memgraph\"\n</code></pre> <p>Function for adding a query module in Python written language to Memgraph. Example can be found in the functions below (with_kafka_stream, with_power_bi).</p> <p>The module is synced dynamically then with the database to enable higher processing capabilities.</p> <p>Arguments:</p> <ul> <li><code>file_name</code> str - path to file containing module.</li> <li><code>module_name</code> str - name of the module.</li> </ul> <p>Returns:</p> <ul> <li><code>Memgraph</code> - Memgraph object.</li> </ul>"},{"location":"reference/gqlalchemy/vendors/memgraph/#with_kafka_stream","title":"with_kafka_stream","text":"<pre><code>def with_kafka_stream() -&gt; \"Memgraph\"\n</code></pre> <p>Load kafka stream query module.</p> <p>Returns:</p> <ul> <li><code>Memgraph</code> - Memgraph instance</li> </ul>"},{"location":"reference/gqlalchemy/vendors/memgraph/#with_power_bi","title":"with_power_bi","text":"<pre><code>def with_power_bi() -&gt; \"Memgraph\"\n</code></pre> <p>Load power_bi stream query module.</p> <p>Returns:</p> <ul> <li><code>Memgraph</code> - Memgraph instance</li> </ul>"},{"location":"reference/gqlalchemy/vendors/neo4j/","title":"neo4j","text":""},{"location":"reference/gqlalchemy/vendors/neo4j/#neo4j-objects","title":"Neo4j Objects","text":"<pre><code>class Neo4j(DatabaseClient)\n</code></pre>"},{"location":"reference/gqlalchemy/vendors/neo4j/#get_indexes","title":"get_indexes","text":"<pre><code>def get_indexes() -&gt; List[Neo4jIndex]\n</code></pre> <p>Returns a list of all database indexes (label and label-property types).</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#ensure_indexes","title":"ensure_indexes","text":"<pre><code>def ensure_indexes(indexes: List[Neo4jIndex]) -&gt; None\n</code></pre> <p>Ensures that database indexes match input indexes.</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#get_constraints","title":"get_constraints","text":"<pre><code>def get_constraints(\n) -&gt; List[Union[Neo4jConstraintExists, Neo4jConstraintUnique]]\n</code></pre> <p>Returns a list of all database constraints (label and label-property types).</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#new_connection","title":"new_connection","text":"<pre><code>def new_connection() -&gt; Connection\n</code></pre> <p>Creates new Neo4j connection.</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#save_node","title":"save_node","text":"<pre><code>def save_node(node: Node) -&gt; Node\n</code></pre> <p>Saves node to the database. If the node._id is not None it fetches the node with the same id from the database and updates it's fields. If the node has unique fields it fetches the nodes with the same unique fields from the database and updates it's fields. Otherwise it creates a new node with the same properties. Null properties are ignored.</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#load_node","title":"load_node","text":"<pre><code>def load_node(node: Node) -&gt; Optional[Node]\n</code></pre> <p>Loads a node from the database. If the node._id is not None it fetches the node from the database with that internal id. If the node has unique fields it fetches the node from the database with those unique fields set. Otherwise it tries to find any node in the database that has all properties set to exactly the same values. If no node is found or no properties are set it raises a GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#load_relationship","title":"load_relationship","text":"<pre><code>def load_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Returns a relationship loaded from the database. If the relationship._id is not None it fetches the relationship from the database that has the same internal id. Otherwise it returns the relationship whose relationship._start_node_id and relationship._end_node_id and all relationship properties that are not None match the relationship in the database. If there is no relationship like that in the database, or if there are multiple relationships like that in the database, throws GQLAlchemyError.</p>"},{"location":"reference/gqlalchemy/vendors/neo4j/#save_relationship","title":"save_relationship","text":"<pre><code>def save_relationship(relationship: Relationship) -&gt; Optional[Relationship]\n</code></pre> <p>Saves a relationship to the database. If relationship._id is not None it finds the relationship in the database and updates it's properties with the values in <code>relationship</code>. If relationship._id is None, it creates a new relationship. If you want to set a relationship._id instead of creating a new relationship, use <code>load_relationship</code> first.</p>"},{"location":"under-the-hood/overview/","title":"Overview","text":"<p>Look under the hood and have a glimpse at the inner workings of GQLAlchemy. If you are advanced GQLAlchemy user or graph database enthusiast we hope you will enjoy reading about the following topics:</p> <ul> <li>Python graph translators</li> </ul>"},{"location":"under-the-hood/python-graph-translators/","title":"Python graph translators","text":"<p>In this under the hood content you can learn more about GQLAlchemy Python graph translators. </p> <p> </p> <p>Within the code, translators are divided into the following parts, depending on the Python graph type you want to translate:</p> <ul> <li>NetworkX graph translator</li> <li>PyG graph translator</li> <li>DGL graph translator</li> </ul>"},{"location":"under-the-hood/python-graph-translators/#networkx-graph-translator","title":"NetworkX graph translator","text":"<p>The <code>NxTranslator</code> class implements the NetworkX graph translator and inherits from the <code>Translator</code> class. The <code>NxTranslator</code> class can be imported from the <code>gqlalchemy.transformations.translators.nx_translator</code> module. </p> <p></p> <p>Translating the graph means that you can import NetworkX graph into Memgraph as well as export data from Memgraph into NetworkX graph in your Python code. The <code>NxTranslator</code> defines three important methods:</p> <ul> <li><code>to_cypher_queries()</code> - The method which generates Cypher queries to create a graph in Memgraph.</li> <li><code>nx_graph_to_memgraph_parallel()</code> - The method which generates Cypher queries to insert data into Memgraph in parallel.</li> <li><code>get_instance()</code> - The method which creates NetworkX instance from the graph stored in Memgraph. </li> </ul>"},{"location":"under-the-hood/python-graph-translators/#to_cypher_queries-method","title":"<code>to_cypher_queries()</code> method","text":"<p>The <code>to_cypher_queries()</code> method yields queries from the <code>NetworkXCypherBuilder</code> object. These queries are creating nodes (with indexes) and relationships. To create nodes with indexes, <code>create_index</code> in <code>config</code> must be set to <code>True</code>. In that case, label-property indexes will be created on <code>id</code> property of each node. With or without indexes, node creation follows the same set or rules. The value of the <code>labels</code> key in NetworkX node will be translated into Memgraph node labels. Other properties will be translated into the same key-value pairs in Memgraph. Every node will have <code>id</code> property matching its NetworkX identification number. After Cypher queries for the node creation are generated, then Cypher queries for relationship creation are being generated. Those Cypher queries will match nodes by their label and property <code>id</code> and create a relationship between them. The value of the <code>TYPE</code> key in NetworkX edge will be translated into relationship type in Memgraph. Any other property in NetworkX edge will be translated into the same key-value pair in Memgraph. To run the generated queries, following code can be used:</p> <pre><code>for query in NxTranslator().to_cypher_queries(nx_graph):\n    memgraph.execute(query)\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#nx_graph_to_memgraph_parallel-method","title":"<code>nx_graph_to_memgraph_parallel()</code> method","text":"<p>The <code>nx_graph_to_memgraph_parallel()</code> method is similar to the <code>to_cypher_queries()</code> method. It creates a graph inside Memgraph following the same set of rules, but it writes in parallel. To do that, it splits generated queries into query groups and opens up a new connection to Memgraph in order to run queries. It will warn you if you did not set <code>create_index</code> in <code>config</code> to <code>True</code>, because otherwise, the write process might take longer than expected. To run the generated queries, the following code can be used:</p> <pre><code>for query in NxTranslator().nx_graph_to_memgraph_parallel(nx_graph):\n    memgraph.execute(query)\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#get_instance-method","title":"<code>get_instance()</code> method","text":"<p>The <code>get_instance()</code> method translates data stored inside Memgraph into NetworkX graph. It traverses the graph and it stores node and relationship objects along with their properties in a NetworkX DiGraph object. Since NetworkX doesn't support node labels and relationship type in a way Memgraph does, they are encoded as node and edge properties, as values of <code>label</code> and <code>type</code> key. To create NetworkX graph from data stored in Memgraph, following code can be run:</p> <pre><code>graph =  NxTranslator().get_instance()\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#pyg-graph-translator","title":"PyG graph translator","text":"<p>The <code>PyGTranslator</code> class implements the PyG graph translator and inherits from the <code>Translator</code> class. The <code>PyGTranslator</code> class can be imported from the <code>gqlalchemy.transformations.translators.pyg_translator</code> module. </p> <p></p> <p>Translating the graph means that you can import PyG graph into Memgraph as well as export data from Memgraph into PyG graph in your Python code. The <code>PyGTranslator</code> defines two important methods:</p> <ul> <li><code>to_cypher_queries()</code> - The method which generates Cypher queries to create a graph in Memgraph.</li> <li><code>get_instance()</code> - The method which creates PyG instance from the graph stored in Memgraph. </li> </ul>"},{"location":"under-the-hood/python-graph-translators/#to_cypher_queries-method_1","title":"<code>to_cypher_queries()</code> method","text":"<p>The <code>to_cypher_queries()</code> method produces Cypher queries to create graph objects in Memgraph for both homogeneous and heterogeneous graph. This method can translate one-dimensional as well as multidimensional features to Memgraph properties. Isolated nodes in the graph won't get translated into Memgraph. Nodes and relationships will have property <code>pyg_id</code> set to the id they have as part of the PyG graph for the consistency reasons. To run the generated queries, following code can be used:</p> <pre><code>for query in PyGTranslator().to_cypher_queries(pyg_graph):\n    memgraph.execute(query)\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#get_instance-method_1","title":"<code>get_instance()</code> method","text":"<p>The <code>get_instance()</code> method returns an instance of PyG heterograph from all relationships stored in Memgraph. Isolated nodes are ignored because they don't contribute to message passing neural networks. Only numerical properties that are set on all nodes and relationships are translated to the PyG instance since that is PyG requirement. Hence, any string properties, as well as numerical properties that aren't set on all nodes or relationships, won't be translated to the PyG instance. However, properties of type list will be translated to the PyG instance as a feature. Regardless of how data is connected in Memgraph, the returned PyG graph will be a heterograph instance. To create PyG graph from data stored in Memgraph, the following code can be run:</p> <pre><code>graph =  PyGTranslator().get_instance()\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#dgl-graph-translator","title":"DGL graph translator","text":"<p>The <code>DGLTranslator</code> class implements the DGL graph translator and inherits from the <code>Translator</code> class. The <code>DGLTranslator</code> class can be imported from the <code>gqlalchemy.transformations.translators.dgl_translator</code> module. </p> <p></p> <p>Translating the graph means that you can import DGL graph into Memgraph as well as export data from Memgraph into DGL graph in your Python code. The <code>DGLTranslator</code> defines two important methods:</p> <ul> <li><code>to_cypher_queries()</code> - The method which generates Cypher queries to create a graph in Memgraph.</li> <li><code>get_instance()</code> - The method which creates PyG instance from the graph stored in Memgraph. </li> </ul>"},{"location":"under-the-hood/python-graph-translators/#to_cypher_queries-method_2","title":"<code>to_cypher_queries()</code> method","text":"<p>The <code>to_cypher_queries()</code> method produces Cypher queries to create graph objects in Memgraph for both homogeneous and heterogeneous graph. If the graph is homogeneous, the default <code>_N</code> as a node label and <code>_E</code> as a relationship label will be used. This method can translate one-dimensional as well as multidimensional features to Memgraph properties. Isolated nodes in the graph won't get translated into Memgraph. Nodes and relationships will have property <code>dgl_id</code> set to the ID they have as part of the DGL graph for the consistency reasons. To run the generated queries, the following code can be used:</p> <pre><code>for query in DGLTranslator().to_cypher_queries(dgl_graph):\n    memgraph.execute(query)\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#get_instance-method_2","title":"<code>get_instance()</code> method","text":"<p>The <code>get_instance()</code> method returns instance of DGL heterograph from all relationships stored in Memgraph. Isolated nodes are ignored because they don't contribute in message passing neural networks. Only numerical properties that are set on all nodes and relationships are translated to the DGL instance since that is DGL requirement. Hence, any string properties, as well as numerical properties, that aren't set on all nodes or relationships, won't be translated to the DGL instance. However, properties of type list will be translated to the PyG instance as a feature. Regardless of how data is connected in Memgraph, the returned DGL graph will be a heterograph instance. To create DGL graph from data stored in Memgraph, following code can be run:</p> <pre><code>graph =  DGLTranslator().get_instance()\n</code></pre>"},{"location":"under-the-hood/python-graph-translators/#where-to-next","title":"Where to next?","text":"<p>If you want to learn more about using NetworkX with Memgraph with interesting resources and courses, head over to the Memgraph for NetworkX developers website. If you have any questions or want to connect with the Memgraph community, join our Discord server.</p>"}]}